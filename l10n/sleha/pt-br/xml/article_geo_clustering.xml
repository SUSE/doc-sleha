<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
  type="text/xml" 
  title="Profiling step"?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:dm="urn:x-suse:ns:docmanager" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="article_geo_clustering.xml" version="5.0" xml:lang="pt-br" xml:id="article-geo-clustering">
 <title>Inicialização Rápida do Geo Clustering</title>
 <info>
  <productnumber><phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></productnumber><productname><phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase></productname>
  <date><?dbtimestamp ?>
</date>
  <xi:include href="ha_authors.xml"/>
  <abstract>
   <para>
     O Geo Clustering protege as cargas de trabalho nos data centers distribuídos globalmente. Este documento orienta você na configuração básica de um cluster Geo usando os scripts de boot Geo incluídos no crm shell.
   </para>
  </abstract>
  <dm:docmanager>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>

 <sect1 xml:id="sec-ha-geo-quick-concept">
  <title>Visão geral conceitual</title>

  <para>
   Os clusters Geo baseados na <phrase role="roductnamereg"><phrase os="sles">SUSE® Linux Enterprise High Availability Extension</phrase></phrase> podem ser considerados clusters <quote>sobrepostos</quote>, em que cada site do cluster corresponde a um nó em um cluster tradicional. O cluster sobreposto é administrado pelo gerenciador de tickets de cluster de booth (mencionado a seguir como booth). Cada uma das partes envolvidas em um cluster Geo executa um serviço, o <systemitem class="daemon">boothd</systemitem>. Ele se conecta aos daemons de booth executados em outros sites e troca detalhes de conectividade. Para tornar os recursos de cluster altamente disponíveis em todos os sites, o booth usa como base objetos do cluster denominados tickets. Um ticket concede o direito de executar determinados recursos em um site de cluster específico. O booth garante que cada ticket seja concedido a, no máximo, um site por vez.
  </para>
  <para>
   Se a comunicação entre duas instâncias de booth falhar, talvez seja por causa de uma queda na rede entre os sites do cluster <emphasis>ou</emphasis> uma interrupção de um site do cluster. Neste caso, é necessária uma instância adicional (um terceiro site do cluster ou um <literal>arbitrador</literal>) para chegar a um consenso sobre as decisões (por exemplo, o failover de recursos em todos os sites). Arbitradores são máquinas únicas (fora dos clusters) que executam uma instância de booth em um modo especial. Cada cluster Geo pode ter um ou vários arbitradores.
  </para>

  <para>
   <remark>toms 2017-07-04: for the future: maybe also add example IP addresses
    to graphic (node IPs, VIPs for cluster sites)
    </remark>
   <remark>taroth 2017-12-29: FATE#322100 - adjust graphic in case two sites
   *without* arbitrator becomes the default setup? (c#6)
   </remark>
  </para>

  <figure xml:id="fig-ha-geo-quick-example-geosetup">
   <title>Cluster de dois sites — 2x2 nós + arbitrador (opcional)</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ha_geocluster.svg" width="100%" format="SVG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ha_geocluster.png" width="85%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   É possível também executar um cluster Geo de dois sites <emphasis>sem</emphasis> um arbitrador. Nesse caso, um administrador de cluster Geo precisa gerenciar manualmente os tickets. Se for necessário conceder um ticket a mais de um site ao mesmo tempo, o booth exibirá um aviso.
  </para>

  <para>
   Para obter mais detalhes sobre o conceito, os componentes e o gerenciamento de tickets usado para clusters Geo, consulte o <xref linkend="book-administration"/>.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-scenario">
  <title>Cenário de uso</title>

  <para>
   A seguir, configuraremos um cluster Geo básico com dois sites do cluster e um arbitrador:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Vamos supor que os nomes dos sites do cluster são <literal>amsterdam</literal> e <literal>berlin</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Imagine que cada site tenha dois nós. Os nós <literal>alice</literal> e <literal>bob</literal> pertencem ao cluster <literal>amsterdam</literal>. Os nós <literal>charlie</literal> e <literal>doro</literal> pertencem ao cluster <literal>berlin</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     O site <literal>amsterdam</literal> terá o seguinte endereço IP virtual: <literal>192.168.201.100</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     O site <literal>berlin</literal> terá o seguinte endereço IP virtual: <literal>192.168.202.100</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     <remark>taroth 2017-12-29: FATE#322100 - move to Geo Guide? (c#6)</remark>
     Suponha que o arbitrador tenha o seguinte endereço IP: <literal>192.168.203.100</literal>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Antes de prosseguir, verifique se os seguintes requisitos foram atendidos:
  </para>

  <variablelist>
   <title>Requisitos</title>
   <varlistentry>
    <term>Dois clusters existentes</term>
    <listitem>
     <para>
      Você tem pelo menos dois clusters existentes para combinar em um cluster Geo. (Se você primeiro precisa configurar dois clusters, siga as instruções na <xref linkend="article-installation"/>.)
      </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Nomes de cluster significativos</term>
    <listitem>
     <para>
      Cada cluster tem um nome significativo definido em <filename>/etc/corosync/corosync.conf</filename> que reflete seu local.
     </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Arbitrador</term>
    <listitem>
     <para><remark>taroth 2017-12-29: FATE#322100 - move to Geo Guide? (see
     c#6)</remark>
      Você instalou uma terceira máquina que não faz parte de nenhum cluster existente e deve ser usada como arbitrador.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Para obter os requisitos detalhados de cada item, consulte também a <xref linkend="sec-ha-geo-quick-req"/>.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-req">
  <title>Requisitos</title>
   <para>
    Todas as máquinas (nós do cluster e arbitradores) que farão parte do cluster precisam, no mínimo, dos seguintes módulos e extensões:
   </para>

<itemizedlist>
   <listitem>
    <para>Módulo Basesystem <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></para>
   </listitem>
   <listitem>
    <para>Server Applications Module <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></para>
   </listitem>
   <listitem>
    <para><phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase> <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></para>
   </listitem>
  </itemizedlist>
  <para>
   Ao instalar as máquinas, selecione <literal>HA GEO Node</literal> como a <systemitem>system role</systemitem>. Isso leva à instalação de um sistema mínimo em que os pacotes do padrão <literal>Geo Clustering for High Availability (ha_geo)</literal> são instalados por padrão.
  </para>
  <itemizedlist>
   <title>Requisitos de rede</title>
   <listitem>
   <para>
    Os IPs virtuais a serem usados para cada site do cluster devem estar acessíveis no cluster Geo.
   </para>
  </listitem>
   <listitem>
   <para>
     Os sites devem ser acessíveis em uma porta UDP e TCP por instância de booth. Isso significa que qualquer firewall ou túnel IPsec intermediário deve ser configurado adequadamente.
    </para>
   </listitem>
   <listitem>
    <para>
     Outras decisões de configuração podem exigir a abertura de mais portas (por exemplo, para replicação de banco de dados ou do DRBD).
    </para>
   </listitem>
  </itemizedlist>

  <itemizedlist>
  <title>Outros requisitos e recomendações</title>
  <listitem>
   <para>
    Todos os nós do cluster em todos os sites devem ser sincronizados com um servidor NTP fora do cluster. Para obter mais informações, consulte o <link xlink:href="https://documentation.suse.com/sles-15/html/SLES-all/cha-ntp.html"><citetitle>Guia de Administração</citetitle> do SUSE Linux Enterprise Server <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></link>.
   </para>
   <para>
    Se os nós não estiverem sincronizados, será muito difícil de analisar os arquivos de registro e os relatórios do cluster.
   </para>
  </listitem>
  <listitem>
   <para>
    Use um número <emphasis>ímpar</emphasis> de sites no cluster Geo. Em caso de falha na conexão, esse procedimento garante que ainda exista uma maioria dos sites (para evitar um cenário de split brain). Se você tem um número par de sites de cluster, use um arbitrador para gerenciar o failover automático dos tickets. Se você não usar um arbitrador, precisará gerenciar o failover dos tickets manualmente.
   </para>
  </listitem>
  <listitem>
   <para>
    O cluster em cada site tem um nome significativo, por exemplo: <literal>amsterdam</literal> e <literal>berlin</literal>.
   </para>
   <para>
    Os nomes dos clusters de cada site são definidos nos respectivos arquivos <filename>/etc/corosync/corosync.conf</filename>:
   </para>
<screen>totem {
    [...]
    cluster_name: amsterdam
    }
</screen>
   <para>
    Mude o nome com o seguinte comando crmsh:
   </para>
<screen><prompt role="root">root # </prompt><command>crm</command> cluster rename <replaceable>NEW_NAME</replaceable></screen>
   <para>
    Pare e inicie o serviço <systemitem class="service">pacemaker</systemitem> para as mudanças entrarem em vigor:
   </para> <screen><prompt role="root">root # </prompt><command>crm</command> cluster restart</screen>
  </listitem>
 <listitem>
   <para>
     Não há suporte para arquiteturas mistas em um cluster. No entanto, cada membro do cluster Geo pode ter uma arquitetura diferente, seja um site de cluster ou um arbitrador. Por exemplo, você pode executar um cluster Geo com três membros (dois sites de cluster e um arbitrador), em que um site de cluster é executado no IBM Z, o outro site de cluster é executado em x86 e o arbitrador é executado no POWER.
   </para>
 </listitem>
</itemizedlist>

 </sect1>
 <sect1 xml:id="sec-ha-geo-scripts">
  <title>Visão geral dos scripts de boot Geo</title>
  <itemizedlist>
   <listitem>
    <para>
     Com o <command>crm cluster geo_init</command>, transforme um cluster no primeiro site de um cluster Geo. O script usa alguns parâmetros, como os nomes dos clusters, o arbitrador e um ou vários tickets, e cria o arquivo <filename>/etc/booth/booth.conf</filename> com base neles. Ele copia a configuração de booth para todos os nós no site do cluster atual. Ele também configura os recursos de cluster necessários para o booth no site do cluster atual.
    </para>
    <para>
     Para obter os detalhes, consulte a <xref linkend="sec-ha-geo-quick-crm-cluster-geo-init"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Com o <command>crm cluster geo_join</command>, adicione o cluster atual a um cluster Geo existente. O script copia a configuração de booth de um site do cluster existente e grava-a no <filename>/etc/booth/booth.conf</filename> em todos os nós no site do cluster atual. Ele também configura os recursos de cluster necessários para o booth no site do cluster atual.
    </para>
    <para>
     Para obter os detalhes, consulte a <xref linkend="sec-ha-geo-quick-crm-cluster-geo-join"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Com o <command>crm cluster geo_init_arbitrator</command>, transforme a máquina atual em um arbitrador para o cluster Geo. O script copia a configuração de booth de um site do cluster existente e grava-a no <filename>/etc/booth/booth.conf</filename>.
    </para>
    <para>
     Para obter os detalhes, consulte a <xref linkend="sec-ha-geo-quick-crm-cluster-geo-init-arbitrator"/>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Todos os scripts de boot são registrados em <filename>/var/log/crmsh/crmsh.log</filename>. Consulte o arquivo de registro para obter todos os detalhes do processo de boot. Quaisquer opções definidas durante o processo de boot podem ser modificadas posteriormente (modificando configurações de booth, recursos, etc). Para obter detalhes, consulte o <xref linkend="book-administration"/>.
  </para>


 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-inst">
  <title>Instalação</title>

  <para>
   O suporte para uso de clusters de Alta Disponibilidade a distâncias ilimitadas está disponível com a <phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase>.
  </para>
  <para>
   Para configurar um cluster Geo, você precisa dos pacotes incluídos nos seguintes padrões de instalação:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <literal>High Availability</literal> (denominado <literal>sles_ha</literal> na linha de comando)
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>Geo Clustering for High Availability</literal> (denominado <literal>ha_geo</literal> na linha de comando)
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Ambos os padrões estão disponíveis apenas se você registrou seu sistema no SUSE Customer Center (ou em um servidor de registro local) e adicionou os respectivos módulos ou a mídia de instalação como uma extensão. Para obter informações sobre como instalar as extensões, consulte o <link xlink:href="https://documentation.suse.com/sles/html/SLES-all/cha-add-ons.html"><citetitle>Guia de Implantação</citetitle> para SUSE Linux Enterprise <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase></link>.
  </para>
  <para>
     Para instalar os pacotes de ambos os padrões por meio da linha de comando, use o Zypper:
    </para>
<screen><prompt role="root">root # </prompt><command>zypper</command> install -t pattern ha_sles ha_geo</screen>

  <important>
   <title>Instalando pacotes de software em todas as partes</title>
   <para>
    Os pacotes de software necessários para os clusters High Availability e Geo <emphasis>não</emphasis> são copiados automaticamente para os nós do cluster.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Instale o SUSE Linux Enterprise Server <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase> e os padrões <literal>ha_sles</literal> e <literal>ha_geo</literal> em <emphasis>todas</emphasis> as máquinas que farão parte do cluster Geo.
     </para>
    </listitem>
    <listitem>
     <para>
      Em vez de instalar manualmente os pacotes em todas as máquinas que farão parte do cluster, use o AutoYaST para clonar nós existentes. Encontre mais informações no <xref linkend="sec-ha-installation-autoyast"/>.
     </para>
    </listitem>
   </itemizedlist>
  </important>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-crm-cluster-geo-init">
  <title>Configurando o primeiro site de um cluster Geo</title>

  <para>
   Use o comando <command>crm cluster geo_init</command> para transformar um cluster existente no primeiro site de um cluster Geo.
  </para>

  <procedure xml:id="pro-ha-geo-quick-crm-cluster-geo-init">
   <title>Configurando o primeiro site (<systemitem>amsterdam</systemitem>) com <command>crm cluster geo_init</command></title>
   <step>
    <para>
     Defina um IP virtual por site do cluster que pode ser usado para acessar o site. Consideramos que <literal>192.168.201.100</literal> e <literal>192.168.202.100</literal> são usados para esta finalidade. Você ainda não precisa configurar os IPs virtuais como recursos de cluster. Isso será feito pelos scripts de boot.
    </para>
   </step>
   <step>
    <para>
     Defina o nome de pelo menos um ticket que concederá o direito de executar determinados recursos em um site do cluster. Use um nome significativo que corresponda aos recursos que dependem do ticket (por exemplo, <literal>ticket-nfs</literal>). Os scripts de boot precisam apenas do nome do ticket. Você pode definir os detalhes restantes (dependências de ticket dos recursos) posteriormente, conforme descrito na <xref linkend="sec-ha-geo-quick-next"/>.
    </para>
   </step>
   <step>
    <para>
     Efetue login no nó de um cluster existente (por exemplo, no nó <literal>alice</literal> do cluster <literal>amsterdam</literal>).
    </para>
   </step>
   <step xml:id="st-crm-cluster-geo-init">
    <para>
     Execute <command>crm cluster geo_init</command>. Por exemplo, use as seguintes opções:
     <remark>taroth 2017-12-29: FATE#322100 - remove the --arbitrator option?
     (see c#6)</remark>
    </para>
<screen><prompt role="root">root # </prompt><command>crm cluster geo_init</command> \
  --clusters<co xml:id="co-geo-init-clusters"/> "amsterdam=192.168.201.100 berlin=192.168.202.100" \
  --tickets<co xml:id="co-geo-init-ticket"/> ticket-nfs \
  --arbitrator<co xml:id="co-geo-init-arbitrator"/> 192.168.203.100</screen>
    <calloutlist>
     <callout arearefs="co-geo-init-clusters">
       <para>
    Os nomes dos sites do cluster (conforme definido em <filename>/etc/corosync/corosync.conf</filename>) e os endereços IP virtuais que você deseja usar para cada site do cluster. Neste caso, temos dois sites do cluster (<literal>amsterdam</literal> e <literal>berlin</literal>), cada um com um endereço IP virtual.
   </para>
     </callout>
     <callout arearefs="co-geo-init-ticket">
      <para>
       O nome de um ou vários tickets.
      </para>
     </callout>
     <callout arearefs="co-geo-init-arbitrator">
      <para>
       O nome de host ou endereço IP de uma máquina fora dos clusters.
      </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   O script de boot cria o arquivo de configuração de booth e o sincroniza com os sites do cluster. Ele também cria os recursos de cluster básicos necessários para o booth. A <xref linkend="st-crm-cluster-geo-init" xrefstyle="seletc:label"/> do <xref linkend="pro-ha-geo-quick-crm-cluster-geo-init" xrefstyle="select:label"/> resulta na seguinte configuração de booth e recursos de cluster:
   <remark>taroth 2017-12-29: FATE#322100 - remove the arbitrator entry? (c#6)</remark>
  </para>

  <example xml:id="ex-geo-init-booth-conf">
   <title>Configuração de booth criada por <command>crm cluster geo_init</command></title>
<screen># The booth configuration file is "/etc/booth/booth.conf". You need to
# prepare the same booth configuration file on each arbitrator and
# each node in the cluster sites where the booth daemon can be launched.

# "transport" means which transport layer booth daemon will use.
# Currently only "UDP" is supported.
transport="UDP"
port="9929"

arbitrator="192.168.203.100"
site="192.168.201.100"
site="192.168.202.100"
authfile="/etc/booth/authkey"
ticket="ticket-nfs"
expire="600"</screen>
  </example>

  <example xml:id="ex-geo-init-rsc-conf">
   <title>Recursos de cluster criados por <command>crm cluster geo_init</command></title>
<screen>primitive<co xml:id="co-geo-quick-rsc-booth-ip"/> booth-ip IPaddr2 \
  params rule #cluster-name eq amsterdam ip=192.168.201.100 \
  params rule #cluster-name eq berlin ip=192.168.202.100 \
primitive<co xml:id="co-geo-quick-rsc-booth-site"/> booth-site ocf:pacemaker:booth-site \
  meta resource-stickiness=INFINITY \
  params config=booth \
  op monitor interval=10s
group<co xml:id="co-geo-quick-rsc-g-booth"/> g-booth booth-ip booth-site \
meta target-role=Stopped<co xml:id="co-geo-quick-rsc-stopped"/></screen>
   <calloutlist>
    <callout arearefs="co-geo-quick-rsc-booth-ip">
     <para>
      Um endereço IP virtual para cada site do cluster. Os daemons de booth exigem essa informação, pois precisam de um endereço IP persistente em cada site do cluster.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-booth-site">
     <para>
      Um recurso primitivo para o daemon de booth. Ele se comunica com os daemons de booth nos outros sites do cluster. O daemon pode ser iniciado em qualquer nó do site. Para fazer com que o recurso permaneça no mesmo nó, se possível, resource-stickiness foi definido como <literal>INFINITY</literal>.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-g-booth">
     <para>
      Um grupo de recursos de cluster para ambos os primitivos. Com essa configuração, cada daemon de booth está disponível em seu endereço IP individual, independentemente do nó em que o daemon é executado.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-stopped">
     <para>
      O grupo de recursos de cluster não é iniciado por padrão. Depois de verificar a configuração de recursos de cluster (e adicionar os recursos necessários para concluir a configuração), você precisará iniciar o grupo de recursos. Consulte a <xref linkend="vl-ha-geo-quick-next-req"/> para obter os detalhes.
     </para>
    </callout>
   </calloutlist>
  </example>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-crm-cluster-geo-join">
  <title>Adicionando outro site a um cluster Geo</title>

  <para>
   Depois de inicializar o primeiro site do cluster Geo, adicione o segundo cluster com <literal>crm cluster geo_join</literal>, conforme descrito no <xref linkend="pro-ha-geo-quick-crm-cluster-geo-join" xrefstyle="select:label"/>. O script precisa de acesso SSH a um site do cluster já configurado e adicionará o cluster atual ao cluster Geo.
  </para>

  <procedure xml:id="pro-ha-geo-quick-crm-cluster-geo-join">
   <title>Adicionando o segundo site (<literal>berlin</literal>) com <command>crm cluster geo_join</command></title>
   <step>
    <para>
     Efetue login no nó do site do cluster que você deseja adicionar (por exemplo, no nó <literal>charlie</literal> do cluster <literal>berlin</literal>).
    </para>
   </step>
   <step xml:id="st-crm-cluster-geo-join">
    <para>
     Execute o comando <command>crm cluster geo_join</command>. Por exemplo:
    </para>
<screen><prompt role="root">root # </prompt><command>crm cluster geo_join</command> \
  --cluster-node<co xml:id="co-geo-join-cluster-node"/> 192.168.201.100\
  --clusters<co xml:id="co-geo-join-clusters"/> "amsterdam=192.168.201.100 berlin=192.168.202.100"
     </screen>
    <calloutlist>
     <callout arearefs="co-geo-join-cluster-node">
      <para>
       Especifica de onde copiar a configuração de booth. Use o nome de host ou endereço IP de um nó em um site do cluster Geo já configurado. Você também pode usar o endereço IP virtual de um site do cluster existente (como neste exemplo). Como alternativa, use o nome de host ou endereço IP de um arbitrador já configurado para o cluster Geo.
      </para>
     </callout>
     <callout arearefs="co-geo-join-clusters">
       <para>
    Os nomes dos sites do cluster (conforme definido em <filename>/etc/corosync/corosync.conf</filename>) e os endereços IP virtuais que você deseja usar para cada site do cluster. Neste caso, temos dois sites do cluster (<literal>amsterdam</literal> e <literal>berlin</literal>), cada um com um endereço IP virtual.
   </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   O comando <command>crm cluster geo_join</command> copia a configuração de booth de <xref linkend="co-geo-join-cluster-node" xrefstyle="select:label"/>. Consulte <xref linkend="ex-geo-init-booth-conf" xrefstyle="select:label"/>. Além disso, ele cria os recursos de cluster necessários para o booth (consulte o <xref linkend="ex-geo-init-rsc-conf" xrefstyle="select:label"/>).
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-crm-cluster-geo-init-arbitrator">
  <title>Adicionando o arbitrador</title>

  <para>
   <remark>taroth 2017-12-29: FATE#322100 - move this section to Geo Guide? (c#6)</remark>
   Após configurar todos os sites do cluster Geo com <command>crm cluster geo_init</command> e <command>crm cluster geo_join</command>, configure o arbitrador com <command>crm cluster geo_init_arbitrator</command>.
  </para>

  <procedure xml:id="pro-ha-geo-quick-crm-cluster-geo-init-arbitrator">
   <title>Configurando o arbitrador com <command>crm cluster geo_init_arbitrator</command></title>
   <step>
    <para>
     Efetue login na máquina que você deseja usar como arbitrador.
    </para>
   </step>
   <step>
    <para>
     Execute o seguinte comando. Por exemplo:
    </para>
<screen><prompt role="root">root # </prompt><command>crm cluster geo_init_arbitrator</command> --cluster-node<co xml:id="co-geo-init-arbitrator-cluster-node"/> 192.168.201.100</screen>
    <calloutlist>
     <callout arearefs="co-geo-init-arbitrator-cluster-node">
      <para>
       Especifica de onde copiar a configuração de booth. Use o nome de host ou endereço IP de um nó em um site do cluster Geo já configurado. Se preferir, use o endereço IP virtual de um site do cluster existente (como neste exemplo).
      </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   O comando <command>crm cluster geo_init_arbitrator</command> copia a configuração de booth de <xref linkend="co-geo-init-arbitrator-cluster-node"/>. Consulte <xref linkend="ex-geo-init-booth-conf" xrefstyle="select:label"/>. Ele também habilita e inicia o serviço de booth no arbitrador. Dessa forma, o arbitrador está pronto para se comunicar com as instâncias de booth nos sites do cluster quando os serviços de booth também são executados neles.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-monitor">
  <title>Monitorando os sites do cluster</title>

  <para>
   Para ver os dois sites do cluster com os recursos e o ticket que você criou durante o processo de boot, use o Hawk2. A interface da Web do Hawk2 permite monitorar e gerenciar vários clusters (não relacionados) e clusters Geo.
  </para>

  <itemizedlist>
   <title>Pré-requisitos</title>
   <listitem>
    <para>
     Todos os clusters que serão monitorados do <guimenu>Painel</guimenu> do Hawk4 devem executar a <phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase> <phrase role="productnumber"><phrase os="sles">15 SP4</phrase></phrase>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se você ainda não substituiu o certificado autoassinado para o Hawk2 em cada nó do cluster pelo seu próprio certificado (ou um certificado assinado por uma Autoridade de Certificação oficial), faça o seguinte: Efetue login no Hawk2 em <emphasis>cada</emphasis> nó em <emphasis>cada</emphasis> cluster pelo menos uma vez. Verifique o certificado (ou adicione uma exceção ao browser para ignorar o aviso). Do contrário, o Hawk2 não poderá se conectar ao cluster.
    </para>
   </listitem>
  </itemizedlist>

  <procedure xml:id="pro-ha-geo-quick-hawk2-dashboard">
   <title>Usando o painel de controle do Hawk2</title>
   <step>
    <para>
     Inicie um browser da Web e insira o IP virtual do seu primeiro site do cluster, <literal>amsterdam</literal>:
    </para>
<screen>https://192.168.201.100:7630/</screen>
    <para>
     Se preferir, use o nome de host ou endereço IP de <literal>alice</literal> ou <literal>bob</literal>. Se você configurou ambos os nós com os scripts de boot, o serviço <literal>hawk</literal> deve ser executado em ambos os nós.
    </para>
   </step>
   <step>
    <para>
     Efetue login na interface da Web do Hawk2.
    </para>
   </step>
   <step>
    <para>
     Na barra de navegação esquerda, selecione <guimenu>Painel</guimenu>.
    </para>
    <para>
     O Hawk2 mostra uma visão geral dos recursos e nós no site do cluster atual. Além disso, ele mostra quaisquer <guimenu>Tickets</guimenu> que foram configurados para o cluster Geo. Se você precisar de informações sobre os ícones usados nesta tela, clique em <guimenu>Legenda</guimenu>.
    </para>
    <figure>
     <title>Painel de controle do Hawk2 com um site do cluster (<literal>amsterdam</literal>)</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="hawk2-dashboard-site1.png" width="100%" format="PNG"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="hawk2-dashboard-site1.png" width="95%" format="PNG"/>
      </imageobject>
     </mediaobject>
    </figure>
   </step>
   <step>
    <para>
     Para adicionar um painel de controle para o segundo site do cluster, clique em <guimenu>Adicionar Cluster</guimenu>.
    </para>
    <substeps>
     <step>
      <para>
       Insira o <guimenu>Nome do cluster</guimenu> para identificá-lo no <guimenu>Painel</guimenu>. Neste caso, <literal>berlim</literal>.
      </para>
     </step>
     <step>
      <para>
       Insira o nome completo do host de um dos nós do cluster (neste caso, <literal>charlie</literal> ou <literal>doro</literal>).
      </para>
     </step>
     <step>
      <para>
       Clique em <guimenu>Adicionar</guimenu>. O Hawk2 exibirá uma segunda guia para o site do cluster recém-adicionado com uma visão geral de seus nós e recursos.
      </para>
      <figure>
       <title>Painel de controle do Hawk2 com os dois sites do cluster</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="hawk2-dashboard-two-sites.png" width="100%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="hawk2-dashboard-two-sites.png" width="95%" format="PNG"/>
        </imageobject>
       </mediaobject>
      </figure>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Para ver mais detalhes para um site do cluster ou para gerenciá-lo, alterne para a guia do site e clique no ícone de corrente.
    </para>
    <para>
     O Hawk2 abre a tela <guimenu>Status</guimenu> referente a esse site em uma nova janela ou guia do browser. Neste local, você pode administrar esta parte do cluster Geo.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-next">
  <title>Próximas etapas</title>

  <para>
   Os scripts de boot de cluster Geo são um meio rápido para configurar um cluster Geo básico que pode ser usado para fins de teste. No entanto, para mover o cluster Geo resultante para um cluster Geo funcional que pode ser usado em ambientes de produção, mais etapas são necessárias. Consulte <xref linkend="vl-ha-geo-quick-next-req"/>.
  </para>

  <variablelist xml:id="vl-ha-geo-quick-next-req">
   <title>Etapas necessárias para concluir a configuração do cluster Geo</title>
   <varlistentry xml:id="vle-ha-geo-quick-booth-service-sites">
    <term>Iniciando os serviços de booth nos sites do cluster</term>
    <listitem>
     <para>
      Após o processo de boot, o serviço de booth do arbitrador ainda não poderá se comunicar com os serviços de booth nos sites do cluster, porque eles não são iniciados por padrão.
     </para>
     <para>
      O serviço de booth para cada site do cluster é gerenciado pelo grupo de recursos de booth <literal>g-booth</literal> (consulte o <xref linkend="ex-geo-init-rsc-conf"/>). Para iniciar uma instância do serviço de booth por site, inicie o respectivo grupo de recursos de booth em cada site do cluster. Isso permite que todas as instâncias de booth se comuniquem umas com as outras.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Configurando dependências de ticket e restrições de pedidos</term>
    <listitem>
     <para>
      Para tornar os recursos dependentes do ticket que você criou durante o processo de boot do cluster Geo, configure restrições. Para cada restrição, defina uma <literal>loss-policy</literal>, que define o que deverá acontecer com os respectivos recursos se o ticket for revogado de um site do cluster.
     </para>
     <para>
      Para obter os detalhes, consulte a <xref linkend="cha-ha-geo-rsc"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Concedendo inicialmente um ticket a um site</term>
    <listitem>
     <para>
      Antes que o booth possa gerenciar determinado ticket no cluster Geo, você precisa <emphasis>concedê-lo</emphasis> a um site manualmente. Você pode usar a ferramenta de linha de comando do cliente de booth ou o Hawk2 para conceder um ticket.
     </para>
     <para>
      Para obter detalhes, leia <xref linkend="cha-ha-geo-manage"/>&#x002E;</para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Os scripts de boot criam os mesmos recursos de booth em ambos os sites do cluster, e os mesmos arquivos de configuração de booth em todos os sites, incluindo o arbitrador. Se você estender a configuração do cluster Geo (para mover para um ambiente de produção), provavelmente ajustará a configuração de booth e também mudará a configuração dos recursos de cluster relacionados ao booth. Depois disso, será necessário sincronizar as mudanças com os outros sites do cluster Geo para entrarem em vigor.
  </para>

  <note>
   <title>Sincronizando mudanças com todos os sites do cluster</title>
   <itemizedlist>
    <listitem>
     <para>
      Para sincronizar as alterações na configuração de booth com todos os sites do cluster (incluindo o arbitrador), use o Csync2. Encontre mais informações no <xref linkend="cha-ha-geo-sync"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      O CIB (Cluster Information Database) não é sincronizado automaticamente com todos os sites de um cluster Geo. Isso significa que quaisquer mudanças na configuração de recursos necessárias em todos os sites do cluster precisam ser transferidas para os outros sites manualmente. Para isso, marque os respectivos recursos, exporte-os do CIB atual e importe-os para o CIB nos outros sites do cluster. Para obter os detalhes, consulte a <xref linkend="sec-ha-geo-rsc-sync-cib"/>.
      </para>
    </listitem>
   </itemizedlist>
  </note>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-more">
  <title>Para obter mais informações</title>
  <itemizedlist>
   <listitem>
    <para>
     Há mais documentação para este produto disponível em <link xlink:href="https://documentation.suse.com/sle-ha/"/>. Para ver outras tarefas de configuração e de administração, consulte o <link xlink:href="https://documentation.suse.com/sle-ha/html/SLE-HA-all/book-administration.html"><citetitle>Guia de Cluster Geo</citetitle></link> completo.
    </para>
   </listitem>
   <listitem>
    <para>
     Encontre informações sobre replicação de dados nos clusters Geo por DRBD no seguinte documento de <link xlink:href="https://documentation.suse.com/sbp/all/html/SBP-DRBD/index.html"><citetitle>Melhores Práticas da SUSE</citetitle></link>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <xi:include href="common_copyright_quick.xml"/>
 <xi:include href="common_legal.xml"/>
</article>
