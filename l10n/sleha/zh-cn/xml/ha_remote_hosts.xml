<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="ha_remote_hosts.xml" xml:id="sec-ha-config-basics-remote" xml:lang="zh-cn" version="5.1">
 <title>管理远程主机上的服务</title>
 <info>
  <abstract>
   <para>
    在最近几年中，是否能够监控和管理远程主机上的服务已变得越来越重要。SUSE Linux Enterprise High Availability 11 SP3 提供了通过监控插件监控远程主机上的服务的精细功能。最近添加的 <literal>pacemaker_remote</literal> 服务现在可让 SUSE Linux Enterprise High Availability 15 SP7 全面管理并监控远程主机上的资源，就如同这些资源是真实的群集节点一样 - 而您无需在远程计算机上安装群集堆栈。
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>

  <sect1 xml:id="sec-ha-config-basics-remote-nagios">
   <title>使用监控插件监控远程主机上的服务</title>
   <para>
    虚拟机的监控可以通过 VM 代理来完成（只有在超级管理程序中出现 guest 时才可选择 VM 代理），或者通过从 VirtualDomain 或 Xen 代理调用外部脚本来完成。直到现在为止，仍只有通过在虚拟机中对高可用性堆栈进行完全设置才能实现更细化的监控。
   </para>
   <para>
    现在，通过提供对监控插件（以前称为 Nagios 插件）的支持，SUSE Linux Enterprise High Availability 还可让您监控远程主机上的服务。您可以收集 guest 上的外部状态，而无需修改 guest 映像。例如，VM guest 可能会运行需要能够访问的 Web 服务或简单的网络资源。现在，有了 Nagios 资源代理，您就可以监控 guest 上的 Web 服务或网络资源。如果这些服务不再可访问，SUSE Linux Enterprise High Availability 会触发相应 guest 的重启动或迁移。
   </para>
   <para>
    如果您的 guest 依赖于某项服务（例如，guest 要使用 NFS 服务器），则这项服务可以是由群集管理的普通资源，也可以是使用 Nagios 资源进行监控的外部服务。
   </para>
   <para>
    要配置 Nagios 资源，必须在主机上安装以下软件包：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <package>monitoring-plugins</package>
     </para>
    </listitem>
    <listitem>
     <para>
      <package>monitoring-plugins-metadata</package>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    YaST 或 Zypper 会根据需要解决对后续软件包的任何依赖性问题。
   </para>
   <para>
    将监控插件配置为属于资源容器（通常是 VM）的资源便是其中一个典型用例。如果容器的任何资源发生故障，容器会重启动。有关配置示例，请参见<xref linkend="ex-ha-nagios-config"/>。或者，若要使用 Nagios 资源代理通过网络监控主机或服务，也可以将这些代理配置为普通资源。
   </para>
   <example xml:id="ex-ha-nagios-config">
    <title>为监控插件配置资源</title>
<screen>primitive vm1 VirtualDomain \
    params hypervisor="qemu:///system" config="/etc/libvirt/qemu/vm1.xml" \
    op start interval="0" timeout="90" \
    op stop interval="0" timeout="90" \
    op monitor interval="10" timeout="30"
primitive vm1-sshd nagios:check_tcp \
    params hostname="vm1" port="22" \ <co xml:id="co-nagios-hostname"/>
    op start interval="0" timeout="120" \ <co xml:id="co-nagios-startinterval"/>
    op monitor interval="10"
group g-vm1-and-services vm1 vm1-sshd \
    meta container="vm1" <co xml:id="co-nagios-container"/></screen>
    <calloutlist>
     <callout arearefs="co-nagios-hostname">
      <para>
       支持的参数与监控插件的长选项相同。监控插件通过参数 <literal>hostname</literal> 与服务连接。因此属性的值必须是可解析的主机名或 IP 地址。
      </para>
     </callout>
     <callout arearefs="co-nagios-startinterval">
      <para>
       由于需要一段时间才能使 guest 操作系统启动并使其服务运行，因此监控资源的启动超时必须足够长。
      </para>
     </callout>
     <callout arearefs="co-nagios-container">
      <para>
       <literal>ocf:heartbeat:Xen</literal>、<literal>ocf:heartbeat:VirtualDomain</literal> 或 <literal>ocf:heartbeat:lxc</literal> 类型的群集资源容器。可以是 VM 或 Linux 容器。
      </para>
     </callout>
    </calloutlist>
    <para>
     以上示例仅包含一个用于 <literal>check_tcp</literal> 插件的资源，但您可以针对不同的插件类型（例如 <literal>check_http</literal> 或 <literal>check_udp</literal>）配置多个资源。
    </para>
    <para>
     如果服务的主机名相同，还可以为组指定 <literal>hostname</literal> 参数，而无需为各个基元资源一一添加该参数。例如：
    </para>
<screen>group g-vm1-and-services vm1 vm1-sshd vm1-httpd \
     meta container="vm1" \
     params hostname="vm1" </screen>
    <para>
     如果监控插件所监控的任何服务在 VM 中失败，群集会检测到该情况并重启动容器资源（即相应 VM）。可以通过指定服务监控操作的 <literal>on-fail</literal> 属性来配置在这种情况下要执行的操作。其默认值为 <literal>restart-container</literal>.
    </para>
    <para>
     系统在考虑 VM 的 migration-threshold 时，会将服务的失败计数纳入考量。
    </para>
   </example>
  </sect1>

  <sect1 xml:id="sec-ha-config-basics-remote-pace-remote">
   <title>使用 <literal>pacemaker_remote</literal> 管理远程节点上的服务</title>
   <para>
    使用 <literal>pacemaker_remote</literal> 服务可将 High Availability 群集扩展到虚拟节点或远程裸机计算机。这些虚拟节点或远程裸机无需运行群集堆栈就能成为群集的成员。
   </para>
   <para>
    SUSE Linux Enterprise High Availability 现在可以启动虚拟环境（KVM 和 LXC）以及驻留在这些虚拟环境中的资源，而不要求虚拟环境运行 Pacemaker 或 Corosync。
   </para>
   <para>
    对于同时要管理用作群集资源的虚拟机以及 VM 中驻留的资源的用例，您现在可以使用以下设置：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <quote>常规</quote>（裸机）群集节点运行 SUSE Linux Enterprise High Availability。
     </para>
    </listitem>
    <listitem>
     <para>
      虚拟机运行 <literal>pacemaker_remote</literal> 服务（几乎不需要在 VM 端进行任何配置）。
     </para>
    </listitem>
    <listitem>
     <para>
      <quote>常规</quote>群集节点上的群集堆栈会启动 VM 并连接到 VM 上运行的 <literal>pacemaker_remote</literal> 服务，以将 VM 作为远程节点集成到群集中。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    由于远程节点上未安装群集堆栈，因此这意味着：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      远程节点不参与仲裁。
     </para>
    </listitem>
    <listitem>
     <para>
      远程节点无法成为 DC。
     </para>
    </listitem>
    <listitem>
     <para>
      远程节点不受可伸缩性限制（Corosync 将成员数限制为 32 个节点）的约束。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    <literal>remote_pacemaker</literal>中介绍了有关 <xref linkend="article-pacemaker-remote"/> 服务的更多信息，包括多个用例和详细的设置说明。
   </para>
  </sect1>
</chapter>
