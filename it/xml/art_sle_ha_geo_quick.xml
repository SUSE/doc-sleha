<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
  type="text/xml"
  title="Profiling step"?>
<?provo dirname="geo_quick/"?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:dm="urn:x-suse:ns:docmanager" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="art_sle_ha_geo_quick.xml" version="5.0" xml:lang="it" xml:id="art-ha-geo-quick" xmlns:its="http://www.w3.org/2005/11/its">
 <title>Riferimento rapido per Geo Clustering</title>
 <info>
  <productnumber><phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase></productnumber><productname><phrase role="productname"><phrase os="sles">di SUSE Linux Enterprise High Availability Extension</phrase></phrase></productname><date>
<?dbtimestamp ?>

</date>
 <xi:include href="ha_authors.xml"/>
  <abstract>
   <para>
     Con Geo Clustering è possibile unificare più siti, geograficamente distanti, in un unico cluster locale. Il failover tra tali cluster viene coordinato da un'entità di livello superiore: il manager richiesta del cluster di booth. Questo documento guida l'utente attraverso la configurazione di base di un Geo cluster, mediante gli script di bootstrap Geo forniti dal pacchetto <systemitem class="resource">ha-cluster-bootstrap</systemitem>.
   </para>
  </abstract>
  <dm:docmanager>
   <dm:translation>sì</dm:translation>
  </dm:docmanager>
  <meta name="title" its:translate="yes">Riferimento rapido per Geo Clustering</meta>
  <meta name="series" its:translate="no">Products &amp; Solutions</meta>
  <meta name="description" its:translate="yes">How to perform the basic setup of a Geo cluster, using the Geo bootstrap scripts provided by the crm shell</meta>
  <meta name="social-descr" its:translate="yes">Set up a Geo cluster</meta>
  <meta name="task" its:translate="no">
    <phrase>Installation</phrase>
    <phrase>Administration</phrase>
    <phrase>Clustering</phrase>
  </meta>
  <revhistory xml:id="rh-article-geo-clustering">
    <revision>
     <date>2019-12-09</date>
      <revdescription>
        <para>
          Updated for the initial release of SUSE Linux Enterprise High Availability 12 SP5.
        </para>
      </revdescription>
    </revision>
   </revhistory>
 </info>
 <sect1 xml:id="sec-ha-geo-quick-concept">
  <title>Panoramica concettuale</title>

  <para>
   I Geo cluster basati su <phrase role="productnamereg"><phrase os="sles">SUSE® Linux Enterprise High Availability Extension</phrase></phrase> possono essere considerati cluster <quote>overlay</quote> dove ogni sito del cluster corrisponde a un nodo del cluster in un cluster tradizionale. Il cluster overlay è gestito dal manager richiesta del cluster di booth (di seguito denominato booth). Ciascuna delle parti coinvolte in cluster Geo esegue un servizio <systemitem class="daemon">boothd</systemitem> che si collega ai daemon di booth in esecuzione negli altri siti e scambia le informazioni di connettività. Per rendere le risorse del cluster altamente disponibili tra i siti, booth si affida agli oggetti cluster denominati richieste. Una richiesta concede il diritto di eseguire determinate risorse su un sito specifico del cluster. Booth garantisce che a ogni richiesta non sia concessa più di un sito alla volta.
  </para>
  <para>
   Se la comunicazione tra due istanze di booth si interrompe, il motivo può essere un'interruzione di rete tra i siti del cluster <emphasis>o</emphasis> a causa della mancanza di un sito del cluster. In questo caso, occorre un'istanza aggiuntiva (un terzo sito del cluster o un <literal>arbitro</literal>) per ottenere consenso sulle decisioni (ad esempio un failover di risorse tra i siti). Gli arbitri sono singoli computer (esterni ai cluster) che eseguono un'istanza di booth in una modalità speciale. Ciascun cluster Geo può avere uno o più arbitri.
  </para>

  <para>
   <remark>toms 2017-07-04: for the future: maybe also add example IP addresses
    to graphic (node IPs, VIPs for cluster sites)
    </remark>
  </para>

  <figure xml:id="fig-ha-geo-quick-example-geosetup">
   <title>Cluster a due siti (2x2 nodi + arbitro)</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ha_geocluster.svg" width="100%" format="SVG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ha_geocluster.png" width="85%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   Per maggiori dettagli sul concetto, sulla gestione di componenti e ticket utilizzati per i cluster Geo, vedere <xref linkend="cha-ha-geo-concept"/>.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-scenario">
  <title>Scenario di utilizzo</title>

  <para>
   Di seguito, verrà configurato un cluster Geo di base con due siti cluster e un arbitro:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Si suppone che i siti del cluster siano denominati <literal>amsterdam</literal> e <literal>berlin</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Si suppone che ciascun sito consista di due nodi. I nodi <literal>alice</literal> e <literal>bob</literal> appartengono al cluster <literal>amsterdam</literal>. I nodi <literal>charlie</literal> e <literal>doro</literal> appartengono al cluster <literal>berlin</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Il sito <literal>amsterdam</literal> ottiene il seguente indirizzo IP virtuale: <literal>192.168.201.100</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Il sito <literal>berlin</literal> ottiene il seguente indirizzo IP virtuale: <literal>192.168.202.100</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Si suppone che l'arbitro abbia il seguente indirizzo IP: <literal>192.168.203.100</literal>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Prima di continuare, verificare che siano rispettati i seguenti requisiti:
  </para>

  <variablelist>
   <title>Requisiti</title>
   <varlistentry>
    <term>Due cluster esistenti</term>
    <listitem>
     <para>
      Sono presenti almeno due cluster esistenti che si desidera combinare in un cluster Geo. (Se occorre configurare prima due cluster, seguire le istruzioni nella <xref linkend="art-ha-install-quick"/> (in lingua inglese).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Nomi di cluster significativi</term>
    <listitem>
     <para>
      Per ciascun cluster è definito un nome significativo in <filename>/etc/corosync/corosync.conf</filename> che ne riflette l'ubicazione.
     </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Arbitro</term>
    <listitem>
     <para>
      È stato installato un terzo computer che non fa parte di alcun cluster esistente ed è utilizzato come arbitro.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Per i requisiti dettagliati su ciascun elemento, vedere anche <xref linkend="sec-ha-geo-quick-req"/>.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-req">
  <title>Requisiti</title>

  <itemizedlist>
  <title>Requisiti del software</title>
  <listitem>
   <para>
    In tutti i computer (nodi cluster e arbitri) che faranno parte del cluster Geo sarà installato il seguente software:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE® Linux Enterprise Server <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase>
     </para>
    </listitem>
    <listitem>
     <para>
      <phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase> <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase>
     </para>
    </listitem>
    <listitem>
     <para>
      Geo Clustering for SUSE Linux Enterprise High Availability Extension <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase>

     </para>
    </listitem>
   </itemizedlist>
  </listitem>
 </itemizedlist>

  <itemizedlist>
   <title>Requisiti di rete</title>
   <listitem>
   <para>
    Gli IP virtuali da utilizzare per ciascun sito del cluster devono essere accessibili sul cluster Geo.
   </para>
  </listitem>
   <listitem>
   <para>
     I siti devono essere raggiungibili su una porta UDP e TCP per istanza di booth. Questo significa che firewall o tunnel IPsec compresi devono essere configurati di conseguenza.
    </para>
   </listitem>
   <listitem>
    <para>
     Altre decisioni di configurazione possono richiedere di aprire più porte (ad esempio, per replica database o DRBD).
    </para>
   </listitem>
  </itemizedlist>

  <itemizedlist>
  <title>Altri requisiti e raccomandazioni</title>
  <listitem>
   <para>
    Tutti i nodi del cluster su tutti i siti devono sincronizzarsi con un server NTP esterno al cluster. Per altre informazioni, vedere <link xlink:href="https://documentation.suse.com/sles-12/html/SLES-all/cha-netz-xntp.html"/>.
   </para>
   <para>
    Se i nodi non sono sincronizzati, file di log e rapporti del cluster risultano molto difficili da analizzare.
   </para>
  </listitem>
  <listitem>
   <para>
    Utilizzare un numero <emphasis>dispari</emphasis> di membri nel cluster Geo. In caso di interruzione della connessione di rete, ciò garantisce che ci sia sempre una maggioranza di siti (per evitare uno scenario split-brain). Se è presente un numero pari di siti del cluster, utilizzare un arbitro.
   </para>
  </listitem>
  <listitem>
   <para>
    Il cluster in ciascun sito ha un nome significativo, ad esempio: <literal>amsterdam</literal> e <literal>berlin</literal>.
   </para>
   <para>
    I nomi del cluster per tale sito vengono definiti nei rispettivi file <filename>/etc/corosync/corosync.conf</filename>.
   </para>
<screen>totem {
    [...]
    cluster_name: amsterdam
    }
</screen>
   <para>
    Ciò può essere eseguito manualmente (modificando <filename>/etc/corosync/corosync.conf</filename>) o con il modulo cluster YaST (passando alla categoria <guimenu>Canali di comunicazione</guimenu> e definendo un <guimenu>Nome cluster</guimenu>). In seguito, arrestare e avviare il servizio <systemitem class="service">pacemaker</systemitem> per applicare le modifiche:
   </para> <screen><prompt role="root">root # </prompt><command>systemctl</command> stop pacemaker
<prompt role="root">root # </prompt><command>systemctl</command> start pacemaker</screen>
  </listitem>
 </itemizedlist>

 </sect1>
 <sect1 xml:id="sec-ha-geo-scripts">
  <title>Panoramica degli script di bootstrap Geo</title>
  <itemizedlist>
   <listitem>
    <para>
     Con <command>ha-cluster-geo-init</command>, convertire un cluster nel primo sito di un cluster Geo. Lo script preleva alcuni parametri come i nomi dei cluster, l'arbitro e una o più richieste e crea <filename>/etc/booth/booth.conf</filename> da loro. Copia la configurazione di booth in tutti i nodi sul sito del cluster corrente. Configura inoltre le risorse del cluster necessarie per il booth sul sito del cluster corrente.
    </para>
    <para>
     Per informazioni, vedere <xref linkend="sec-ha-geo-quick-ha-cluster-geo-init"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Con <command>ha-cluster-geo-join</command>, aggiungere il cluster corrente a un cluster Geo esistente. Lo script copia la configurazione di booth da un sito del cluster esistente e la scrive in <filename>/etc/booth/booth.conf</filename> su tutti i nodi sul sito del cluster corrente. Configura inoltre le risorse del cluster necessarie per il booth sul sito del cluster corrente.
    </para>
    <para>
     Per informazioni, vedere <xref linkend="sec-ha-geo-quick-ha-cluster-geo-join"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Con <command>ha-cluster-geo-init-arbitrator</command>, convertire il computer corrente in un arbitro per il cluster Geo. Lo script copia la configurazione di booth da un sito del cluster esistente e la scrive in <filename>/etc/booth/booth.conf</filename>.
    </para>
    <para>
     Per informazioni, vedere <xref linkend="sec-ha-geo-quick-ha-cluster-geo-init-arbitrator"/>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Tutti gli script di bootstrap effettuano l'accesso a <filename>/var/log/ha-cluster-bootstrap.log</filename>. Consultare il file di registro per eventuali dettagli sul processo di bootstrap. Ogni opzione impostata durante il processo di bootstrap è modificabile in seguito (modificando le impostazioni di booth, le risorse e così via). Per i dettagli vedere il <xref linkend="book-sleha-geo"/>.
  </para>


 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-inst">
  <title>Installazione di un'estensione</title>

  <para>
   È disponibile un supporto come estensione separata su distanze illimitate per l'utilizzo dei cluster High Availability; tale supporto è denominato Geo Clustering for SUSE Linux Enterprise High Availability Extension.
  </para>
  <para>
   Per configurare un cluster Geo sono necessari i pacchetti inclusi nei seguenti modelli di installazione:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <literal>High Availability</literal>
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>Geo Clustering for SUSE Linux Enterprise High Availability Extension</literal>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Entrambi i modelli sono disponibili solo se il sistema è stato registrato presso SUSE Customer Center (o in un server di registrazione locale) e sono stati aggiunti i rispettivi canali di prodotto o supporti di installazione come estensione. Per informazioni su come installare le estensioni, vedere <citetitle>SUSE Linux Enterprise <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase> Deployment Guide</citetitle> (in lingua inglese): <link xlink:href="https://documentation.suse.com/sles-12/html/SLES-all/cha-add-ons.html"/>.

  </para>

  <procedure xml:id="pro-ha-geo-inst">
   <title>Installazione dei pacchetti</title>
   <step>
    <para>
     Per installare i pacchetti da entrambi i modelli tramite riga di comando, utilizzare Zypper:
    </para>
<screen><prompt role="root">root # </prompt><command>zypper</command> install -t pattern ha_sles ha_geo</screen>
   </step>
   <step xml:id="st-ha-geo-inst-yast">
    <para>
     In alternativa, utilizzare YaST per un'installazione grafica:
    </para>
    <substeps performance="required">
     <step>
      <para>
       Avviare YaST come utente <systemitem class="username">root</systemitem> e selezionare <menuchoice>
       <guimenu>Software</guimenu> <guimenu>Gestione pacchetti</guimenu>
       </menuchoice>.
      </para>
     </step>
     <step>
      <para>
       Fare clic su <menuchoice> <guimenu>Visualizza</guimenu> <guimenu>Modelli</guimenu>
       </menuchoice>  e attivare i seguenti modelli:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <literal>High Availability</literal>
        </para>
       </listitem>
       <listitem>
        <para>
         <literal>Geo Clustering for SUSE Linux Enterprise High Availability Extension</literal>
        </para>
       </listitem>
      </itemizedlist>
     </step>
     <step>
      <para>
       Fare clic su <guimenu>Accetta</guimenu> per avviare l'installazione dei pacchetti.
      </para>
     </step>
    </substeps>
   </step>
  </procedure>

  <important>
   <title>installazione dei pacchetti software su tutte le entità</title>
   <para>
    I pacchetti software necessari SUSE Linux Enterprise High Availability Extension e Geo Clustering for SUSE Linux Enterprise High Availability Extension <emphasis>non</emphasis> vengono copiati automaticamente nei nodi del cluster.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Installare SUSE Linux Enterprise Server <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase> e i modelli <literal>High Availability</literal> e <literal>Geo Clustering for High Availability</literal> su <emphasis>tutti</emphasis> i computer che faranno parte del cluster Geo.
     </para>
    </listitem>
    <listitem>
     <para>
      Invece di installare manualmente i pacchetti su tutti i computer che faranno parte del cluster, utilizzare AutoYaST per clonare i nodi esistenti. Per ulteriori informazioni, vedere <xref linkend="sec-ha-installation-autoyast"/>.
     </para>
     <para>
      <remark>taroth 2017-06-29: @DEV/QA, is the following still true?</remark> Tuttavia, l'estensione del cluster Geo deve essere installata <emphasis>manualmente</emphasis> su tutti i computer che faranno parte del cluster Geo. Il supporto di AutoYaST per Geo Clustering for SUSE Linux Enterprise High Availability Extension non è ancora disponibile.
     </para>
    </listitem>
   </itemizedlist>
  </important>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-ha-cluster-geo-init">
  <title>Impostazione del primo sito di un cluster Geo</title>

  <para>
   Utilizzare lo script <command>ha-cluster-geo-init</command> per convertire un cluster esistente nel primo sito di un cluster Geo.
  </para>

  <procedure xml:id="pro-ha-geo-quick-ha-cluster-geo-init">
   <title>Impostazione del primo sito (<systemitem>amsterdam</systemitem>) con <command>ha-cluster-geo-init</command></title>
   <step>
    <para>
     Definire un IP virtuale per sito del cluster utilizzabile per accedere al sito. Si suppone di utilizzare <literal>192.168.201.100</literal> e <literal>192.168.202.100</literal> per questo scopo. Non è ancora necessario configurare gli IP virtuali come risorse del cluster. Ciò verrà eseguito dagli script bootstrap.
    </para>
   </step>
   <step>
    <para>
     Definire il nome di almeno una richiesta che concederà il diritto di eseguire determinate risorse su un sito del cluster. Utilizzare un nome significativo che rifletta le risorse che dipenderanno dalla richiesta (ad esempio, <literal>ticket-nfs</literal>). Gli script bootstrap richiedono solo il nome della richiesta, è possibile definire i dettagli rimanenti (dipendenze della richiesta delle risorse) in seguito, come descritto nella <xref linkend="sec-ha-geo-quick-next"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire il login a un nodo di un cluster esistente (ad esempio, al nodo <literal>alice</literal> del cluster <literal>amsterdam</literal>).
    </para>
   </step>
   <step xml:id="st-ha-cluster-geo-init">
    <para>
     Eseguire <command>ha-cluster-geo-init</command>. Ad esempio, utilizzare le opzioni seguenti:
    </para>
<screen><prompt role="root">root # </prompt><command>ha-cluster-geo-init</command> \
  --clusters<co xml:id="co-geo-init-clusters"/> "amsterdam=192.168.201.100 berlin=192.168.202.100" \
  --tickets<co xml:id="co-geo-init-ticket"/> ticket-nfs \
  --arbitrator<co xml:id="co-geo-init-arbitrator"/> 192.168.203.100</screen>
    <calloutlist>
     <callout arearefs="co-geo-init-clusters">
       <para>
    I nomi dei siti del cluster (come definito in <filename>/etc/corosync/corosync.conf</filename>) e gli indirizzi IP virtuali da utilizzare per ogni sito del cluster. In questo caso, sono presenti due siti del cluster (<literal>amsterdam</literal> e <literal>berlin</literal>) ciascuno con un indirizzo IP virtuale.
   </para>
     </callout>
     <callout arearefs="co-geo-init-ticket">
      <para>
       Il nome di una o più richieste.
      </para>
     </callout>
     <callout arearefs="co-geo-init-arbitrator">
      <para>
       Il nome host o l'indirizzo IP di un computer all'esterno dei cluster.
      </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   Lo script bootstrap crea il file di configurazione del booth e lo sincronizza tra i siti del cluster. Crea inoltre le risorse di base del cluster necessarie per il booth. Il <xref linkend="st-ha-cluster-geo-init" xrefstyle="seletc:label"/> della <xref linkend="pro-ha-geo-quick-ha-cluster-geo-init" xrefstyle="select:label"/> determinano le seguenti risorse del cluster e configurazione di booth:
  </para>

  <example xml:id="ex-geo-init-booth-conf">
   <title>Configurazione di booth creata da <command>ha-cluster-geo-init</command></title>
<screen># The booth configuration file is "/etc/booth/booth.conf". You need to
# prepare the same booth configuration file on each arbitrator and
# each node in the cluster sites where the booth daemon can be launched.

# "transport" means which transport layer booth daemon will use.
# Currently only "UDP" is supported.
transport="UDP"
port="9929"

arbitrator="192.168.203.100"
site="192.168.201.100"
site="192.168.202.100"
authfile="/etc/booth/authkey"
ticket="ticket-nfs"
expire="600"</screen>
  </example>

  <example xml:id="ex-geo-init-rsc-conf">
   <title>Risorse del cluster create da <command>ha-cluster-geo-init</command></title>
<screen>primitive<co xml:id="co-geo-quick-rsc-booth-ip"/> booth-ip IPaddr2 \
  params rule #cluster-name eq amsterdam ip=192.168.201.100 \
  params rule #cluster-name eq berlin ip=192.168.202.100 \
primitive<co xml:id="co-geo-quick-rsc-booth-site"/> booth-site ocf:pacemaker:booth-site \
  meta resource-stickiness=INFINITY \
  params config=booth \
  op monitor interval=10s
group<co xml:id="co-geo-quick-rsc-g-booth"/> g-booth booth-ip booth-site \
meta target-role=Stopped<co xml:id="co-geo-quick-rsc-stopped"/></screen>
   <calloutlist>
    <callout arearefs="co-geo-quick-rsc-booth-ip">
     <para>
      Un indirizzo IP virtuale per ogni sito del cluster. È richiesto dai daemon del booth per cui è necessario un indirizzo IP persistente sul sito di ciascun cluster.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-booth-site">
     <para>
      Una risorsa primitiva per il daemon del booth. Comunica con i daemon del booth sugli altri siti del cluster. Il daemon può essere avviato su qualsiasi nodo del sito, ma per far rimanere la risorsa sullo stesso nodo, se possibile, la rigidità della risorsa è impostata su <literal>INFINITO</literal>.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-g-booth">
     <para>
      Un gruppo di risorse del cluster per entrambe le primitive. Con questa configurazione, ciascun daemon di booth sarà disponibile ai propri indirizzi IP, indipendente dal nodo su cui il daemon è in esecuzione.
     </para>
    </callout>
    <callout arearefs="co-geo-quick-rsc-stopped">
     <para>
      Il gruppo risorse del cluster non viene avviato per impostazione predefinita. Dopo aver verificato la configurazione delle risorse del cluster (e aggiunto le risorse necessarie per completare la configurazione), occorre avviare il gruppo di risorse. Per ulteriori informazioni, vedere <xref linkend="vl-ha-geo-quick-next-req"/>.
     </para>
    </callout>
   </calloutlist>
  </example>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-ha-cluster-geo-join">
  <title>Aggiunta di un altro sito a un cluster Geo</title>

  <para>
   Dopo aver inizializzato il primo sito del cluster Geo, aggiungere il secondo cluster con <literal>ha-cluster-geo-join</literal>, come descritto nella <xref linkend="pro-ha-geo-quick-ha-cluster-geo-join" xrefstyle="select:label"/>. Lo script richiede accesso SSH a un sito del cluster già configurato e aggiunge il cluster corrente al cluster Geo.
  </para>

  <procedure xml:id="pro-ha-geo-quick-ha-cluster-geo-join">
   <title>Aggiunta del secondo sito (<literal>berlin</literal>) con <command>ha-cluster-geo-join</command></title>
   <step>
    <para>
     Eseguire il login a un nodo del sito del cluster che si desidera aggiungere (ad esempio, sul nodo <literal>charlie</literal> del cluster <literal>berlin</literal>).
    </para>
   </step>
   <step xml:id="st-ha-cluster-geo-join">
    <para>
     Eseguire il comando <command>ha-cluster-geo-join</command>. Ad esempio:
    </para>
<screen><prompt role="root">root # </prompt><command>ha-cluster-geo-join</command> \
  --cluster-node<co xml:id="co-geo-join-cluster-node"/> 192.168.201.100\
  --clusters<co xml:id="co-geo-join-clusters"/> "amsterdam=192.168.201.100 berlin=192.168.202.100"
     </screen>
    <calloutlist>
     <callout arearefs="co-geo-join-cluster-node">
      <para>
       Specifica da dove copiare la configurazione del booth. Utilizzare l'indirizzo IP o il nome host di un nodo in un sito del cluster Geo già configurato. È inoltre possibile utilizzare l'indirizzo IP virtuale di un sito del cluster già esistente (come in questo esempio). In alternativa, utilizzare l'indirizzo IP o il nome host di un arbitro già configurato per il cluster Geo.
      </para>
     </callout>
     <callout arearefs="co-geo-join-clusters">
       <para>
    I nomi dei siti del cluster (come definito in <filename>/etc/corosync/corosync.conf</filename>) e gli indirizzi IP virtuali da utilizzare per ogni sito del cluster. In questo caso, sono presenti due siti del cluster (<literal>amsterdam</literal> e <literal>berlin</literal>) ciascuno con un indirizzo IP virtuale.
   </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   Lo script <command>ha-cluster-geo-join</command> copia la configurazione del booth da <xref linkend="co-geo-join-cluster-node" xrefstyle="select:label"/>, vedere <xref linkend="ex-geo-init-booth-conf" xrefstyle="select:label"/>. Inoltre, crea le risorse del cluster necessarie per il booth (vedere <xref linkend="ex-geo-init-rsc-conf" xrefstyle="select:label"/>).
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-ha-cluster-geo-init-arbitrator">
  <title>Aggiunta dell'arbitro</title>

  <para>
   Dopo aver configurato tutti i siti del cluster Geo con <command>ha-cluster-geo-init</command> e <command>ha-cluster-geo-join</command>, configurare l'arbitro con <command>ha-cluster-geo-init-arbitrator</command>.
  </para>

  <procedure xml:id="pro-ha-geo-quick-ha-cluster-geo-init-arbitrator">
   <title>Configurazione dell'arbitro con <command>ha-cluster-geo-init-arbitrator</command></title>
   <step>
    <para>
     Eseguire il login al computer da utilizzare come arbitro.
    </para>
   </step>
   <step>
    <para>
     Eseguire il comando seguente. Ad esempio:
    </para>
<screen><prompt role="root">root # </prompt><command>ha-cluster-geo-init-arbitrator</command> --cluster-node<co xml:id="co-geo-init-arbitrator-cluster-node"/> 192.168.201.100</screen>
    <calloutlist>
     <callout arearefs="co-geo-init-arbitrator-cluster-node">
      <para>
       Specifica da dove copiare la configurazione del booth. Utilizzare l'indirizzo IP o il nome host di un nodo in un sito del cluster Geo già configurato. In alternativa, è inoltre possibile utilizzare l'indirizzo IP virtuale di un sito del cluster già esistente (come in questo esempio).
      </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>

  <para>
   Lo script <command>ha-cluster-geo-init-arbitrator</command> copia la configurazione del booth da <xref linkend="co-geo-init-arbitrator-cluster-node"/>, vedere <xref linkend="ex-geo-init-booth-conf" xrefstyle="select:label"/>. Attiva e avvia, inoltre, il servizio di booth sull'arbitro. L'arbitro è così pronto per comunicare con le istanze di booth sui siti del cluster non appena i servizi di booth vi vengono eseguiti.
  </para>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-monitor">
  <title>Controllo dei siti del cluster </title>

  <para>
   Per visualizzare entrambi i siti del cluster con le risorse e la richiesta create durante il processo di bootstrap, utilizzare Hawk2. L'interfaccia Web Hawk2 consente di controllare e gestire più cluster e cluster Geo (non in relazione).
  </para>

  <itemizedlist>
   <title>Prerequisiti</title>
   <listitem>
    <para>
     Tutti i cluster monitorati dal <guimenu>dashboard</guimenu> di Hawk2 devono eseguire <phrase role="productname"><phrase os="sles">SUSE Linux Enterprise High Availability Extension</phrase></phrase> <phrase role="productnumber"><phrase os="sles">12 SP5</phrase></phrase>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se non è stato sostituito il certificato autofirmato per Hawk2 su ogni nodo del cluster con il proprio certificato (o con un certificato firmato da una Autorità di certificazione ufficiale), eseguire almeno una volta il login ad Hawk2 sul nodo <emphasis>every</emphasis> nel cluster <emphasis>every</emphasis>. Verificare il certificato (o aggiungere un'eccezione nel browser per ignorare l'avviso). In alternativa, Hawk2 non può collegarsi al cluster.
    </para>
   </listitem>
  </itemizedlist>

  <procedure xml:id="pro-ha-geo-quick-hawk2-dashboard">
   <title>Utilizzo del dashboard Hawk2</title>
   <step>
    <para>
     Avviare un browser Web e immettere l'IP virtuale del primo sito del cluster, <literal>amsterdam</literal>:
    </para>
<screen>https://192.168.201.100:7630/</screen>
    <para>
     In alternativa, utilizzare l'indirizzo IP o il nome host di <literal>alice</literal> o <literal>bob</literal>. Se sono stati configurati entrambi i nodi con gli script di bootstrap, il servizio <literal>hawk</literal> dovrebbe essere in esecuzione su entrambi i nodi.
    </para>
   </step>
   <step>
    <para>
     Eseguire il login all'interfaccia Web Hawk2.
    </para>
   </step>
   <step>
    <para>
     Dalla barra di navigazione sinistra, selezionare <guimenu>Dashboard</guimenu>.
    </para>
    <para>
     Hawk2 mostra una panoramica di risorse e nodi sul sito del cluster corrente. Inoltre, mostra eventuali <guimenu>Richieste</guimenu> configurate per il cluster Geo. Se occorrono informazioni sulle icone utilizzate in questa vista, fare clic su <guimenu>Legend</guimenu>.
    </para>
    <figure>
     <title>Dashboard Hawk2 con un sito del cluster (<literal>amsterdam</literal>)</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="hawk2-dashboard-site1.png" width="100%" format="PNG"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="hawk2-dashboard-site1.png" width="95%" format="PNG"/>
      </imageobject>
     </mediaobject>
    </figure>
   </step>
   <step>
    <para>
     Per aggiungere un dashboard per il secondo sito del cluster, fare clic su <guimenu>Aggiungi cluster</guimenu>.
    </para>
    <substeps>
     <step>
      <para>
       Immettere il <guimenu>Nome cluster</guimenu> con cui identificare il cluster nel <guimenu>dashboard</guimenu>. In questo caso, <literal>berlin</literal>.
      </para>
     </step>
     <step>
      <para>
       Immettere il nome host completamente qualificato di uno dei nodi del cluster (in questo caso, <literal>charlie</literal> o <literal>doro</literal>).
      </para>
     </step>
     <step>
      <para>
       Fare clic su <guimenu>Aggiungi</guimenu>. Hawk2 mostra una seconda scheda per il nuovo sito del cluster aggiunto con una panoramica dei relativi nodi e risorse.
      </para>
      <figure>
       <title>Dashboard Hawk2 con entrambi i siti del cluster</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="hawk2-dashboard-two-sites.png" width="100%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="hawk2-dashboard-two-sites.png" width="95%" format="PNG"/>
        </imageobject>
       </mediaobject>
      </figure>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Per visualizzare maggiori informazioni per un sito del cluster o gestirlo, passare alla scheda del sito e fare clic sull'icona della catena.
    </para>
    <para>
     Hawk2 apre la vista <guimenu>Stato</guimenu> di tale sito in una nuova scheda o finestra del browser, da cui è possibile amministrare questa parte del cluster Geo.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-next">
  <title>Fasi successive</title>

  <para>
   Gli script di bootstrap del cluster Geo forniscono un modo rapido di impostare un cluster Geo di base utilizzabile per scopi di test. Tuttavia, per spostare il cluster Geo risultante in un cluster Geo funzionante utilizzabile negli ambienti di produzione, sono richiesti altri passaggi, vedere <xref linkend="vl-ha-geo-quick-next-req"/>.
  </para>

  <variablelist xml:id="vl-ha-geo-quick-next-req">
   <title>Passaggi richiesti per completare la configurazione del cluster Geo</title>
   <varlistentry xml:id="vle-ha-geo-quick-booth-service-sites">
    <term>Avvio dei servizi booth sui siti del cluster</term>
    <listitem>
     <para>
      Dopo il processo di bootstrap, il servizio di booth dell'arbitro non può ancora comunicare con i servizi di booth sui siti del cluster, in quanto non vengono avviati per impostazione predefinita.
     </para>
     <para>
      Il servizio di booth per ciascun sito del cluster viene gestito dal gruppo risorse di booth <literal>g-booth</literal> (vedere <xref linkend="ex-geo-init-rsc-conf"/>). Per avviare un'istanza del servizio booth per sito, avviare il rispettivo gruppo risorse di booth in ciascun sito del cluster. Ciò consente a tutte le istanze di booth di comunicare tra loro.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Configurazione delle dipendenze della richiesta e di ordinamento dei vincoli</term>
    <listitem>
     <para>
      Affinché le risorse dipendano dalla richiesta creata durante il processo di bootstrap del cluster Geo, configurare i vincoli. Per ogni vincolo, impostare una <literal>policy di perdita</literal> che definisca ciò che deve succedere alle rispettive risorse se la richiesta viene revocata da un sito del cluster.
     </para>
     <para>
      Per informazioni, vedere <xref linkend="cha-ha-geo-rsc"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Concessione iniziale di un ticket a un sito</term>
    <listitem>
     <para>
      Prima che booth sia in grado di gestire una determinata richiesta nel Geo cluster, occorre inizialmente <emphasis>concederla</emphasis> manualmente a un sito. È possibile utilizzare lo strumento della riga di comando del client di booth o Hawk2 per concedere una richiesta.
     </para>
     <para>
      Per informazioni, vedere <xref linkend="cha-ha-geo-manage"/>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Gli script di bootstrap creano le stesse risorse di booth sui siti di entrambi i cluster e gli stessi file di configurazione di booth in tutti i siti, compreso l'arbitro. Se si estende la configurazione del cluster Geo (per passare a un ambiente di produzione), si perfezionerà probabilmente la configurazione di booth e modificherà la configurazione delle risorse del cluster correlate al booth. In seguito, è necessario sincronizzare le modifiche agli altri siti del cluster Geo per applicarle.
  </para>

  <note>
   <title>sincronizzazione delle modifiche tra i siti del cluster</title>
   <itemizedlist>
    <listitem>
     <para>
      Per sincronizzare le modifiche nella configurazione del booth con tutti i siti del cluster (compreso l'arbitro), utilizzare Csync2. Per ulteriori informazioni, vedere <xref linkend="cha-ha-geo-sync"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Il CIB (Cluster Information Database) non viene sincronizzato automaticamente tra i siti di un Geo cluster. Questo significa che eventuali modifiche alla configurazione della risorsa richieste su tutti i siti del cluster devono essere trasferite manualmente agli altri siti. Per questo, selezionare le rispettive risorse, esportarle dal CIB corrente e importarle nel CIB sugli altri siti del cluster. Per informazioni, vedere <xref linkend="sec-ha-geo-rsc-sync-cib"/>.
     </para>
    </listitem>
   </itemizedlist>
  </note>
 </sect1>
 <sect1 xml:id="sec-ha-geo-quick-more">
  <title>Ulteriori informazioni</title>
  <itemizedlist>
   <listitem>
    <para>
     Maggiore documentazione per questo prodotto è disponibile su <link xlink:href="https://documentation.suse.com/sle-ha-12/"/>. La documentazione comprende inoltre una completa <literal>Geo Clustering Guide</literal> (in lingua inglese). utile in caso di ulteriori attività di configurazione e amministrazione.
    </para>
   </listitem>
   <listitem>
    <para>
     Un documento con informazioni dettagliate sulle operazioni con la replica dei dati tramite DRBD tra i cluster Geo è stato pubblicato nelle serie <literal>SUSE Best Practices</literal> (in lingua inglese): <link xlink:href="https://documentation.suse.com/sbp/all/html/SBP-DRBD/index.html"/>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <xi:include href="common_copyright_quick.xml"/>
 <xi:include href="common_legal.xml"/>
</article>
