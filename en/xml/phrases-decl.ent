<!ENTITY def-existing-cluster 
"  The term <quote xmlns='http://docbook.org/ns/docbook'>existing
    cluster</quote> is used to refer to any
    cluster that consists of at least one node. Existing clusters have a basic
    &corosync; configuration that defines the communication channels, but
    they do not necessarily have resource configuration yet.">
    
 <!ENTITY def-multicast
 '  A technology used for a one-to-many communication within a network that
    can be used for cluster communication. &corosync; supports both
    multicast and unicast.'>
   
<!ENTITY def-unicast
'  A technology for sending messages to a single network destination.
    &corosync; supports both multicast and unicast. In &corosync;, unicast
    is implemented as UDP-unicast (UDPU).'>
   
<!ENTITY def-mcastaddr
'  IP address to be used for multicasting by the &corosync; executive. The IP
   address can either be IPv4 or IPv6. '>   
   
<!ENTITY def-mcastport
'  The port to use for cluster communication.'>   

<!ENTITY def-bindnetaddr
'The network address the &corosync; executive should bind to. '>

<!ENTITY def-rrp 
' Allows the  use of multiple redundant local area networks for resilience
   against partial or total network faults. This way, cluster communication can
   still be kept up as long as a single network is operational.
   &corosync; supports the Totem Redundant Ring Protocol.'>
   
 <!ENTITY def-csync2 
 'A synchronization tool that can be used to replicate configuration files
    across all nodes in the cluster, and even across &geo; clusters.'>  
    
<!ENTITY def-conntrack
"Allow interaction with the in-kernel connection tracking system for
    enabling <emphasis
    xmlns='http://docbook.org/ns/docbook'>stateful</emphasis> packet
    inspection for iptables. Used by the &hasi; to synchronize the connection
    status between cluster nodes.">    
    
<!ENTITY def-ay
'&ay; is a system for installing one or more &sle; systems automatically
    and without user intervention. '>    
    

<!ENTITY maint-mode-basics
" <para xmlns='http://docbook.org/ns/docbook'>
   Every now and then, you need to perform testing or maintenance tasks on
   individual cluster components or the whole cluster&mdash;be it changing the
   cluster configuration, updating software packages for individual nodes, or
   upgrading the cluster to a higher product version.
  </para>">
   
   <!ENTITY warning-maint-mode
   "<warning xmlns='http://docbook.org/ns/docbook'>
   <title>Risk of Data Loss</title>
   <para>If you need to execute any testing or maintenance tasks while services are running under
    cluster control, make sure to follow this outline:</para>
   <orderedlist>
    <listitem>
     <para>Before you start, set the individual resource, node or the whole cluster to maintenance
      mode. This helps to avoid unwanted side effects like resources not starting in an orderly
      fashion, the risk of unsynchronized CIBs across the cluster nodes or data loss. </para>
    </listitem>
    <listitem>
     <para>Execute your maintenance task or tests.</para>
    </listitem>
    <listitem>
     <para>After you have finished, remove the maintenance mode to start normal cluster
      operation.</para>
    </listitem>
   </orderedlist>
  </warning>">
  
 <!ENTITY booth-port
 'The port to be used for communication between the booth instances at each
 site.'>
   
 <!ENTITY booth-transport
 'The transport protocol used for communication between the sites. 
   Only UDP is supported, but other transport layers will follow in
   the future.'>
 
 <!ENTITY booth-site
 'The IP address used for the &boothd; on a site. '>
 
 <!ENTITY booth-arbitrator
' The IP address of the machine to use as arbitrator. '>

 <!ENTITY booth-ticket
 'The ticket to be managed by booth.'> 
 
 <!ENTITY booth-auth
 'Enables booth authentication for clients and servers on the basis 
  of a shared key. This parameter specifies the path to the
  key file.'>
  
 <!ENTITY booth-key-req
 "<itemizedlist xmlns='http://docbook.org/ns/docbook'>
      <title>Key Requirements</title>
      <listitem>
       <para>The key can be either binary or text.</para>
       <para>If it is text, the following characters are ignored: leading and trailing white space,
        new lines.</para>
      </listitem>
      <listitem>
       <para>The key must be between 8 and 64 characters long.</para>
      </listitem>
      <listitem>
       <para>The key must be readable only by the file owner.</para>
      </listitem>
     </itemizedlist>">

 <!ENTITY booth-multi-tenancy
 " For setups including multiple &geo; clusters, it is possible to <quote
 xmlns='http://docbook.org/ns/docbook'>share</quote> the same arbitrator (as
 of &productname; 12). By providing several booth configuration files, you can
 start multiple booth instances on the same arbitrator, with each booth
 instance running on a different port. That way, you can use <emphasis
 xmlns='http://docbook.org/ns/docbook'>one</emphasis> machine to serve as
 arbitrator for <emphasis
 xmlns='http://docbook.org/ns/docbook'>different</emphasis> &geo; clusters.">
   
 <!ENTITY ticket-dependency-loss-policy
 "<para xmlns='http://docbook.org/ns/docbook'>
     For &geo; clusters, you can specify which resources depend on a
     certain ticket. Together with this special type of constraint, you can
     set a <literal>loss-policy</literal> that defines what should happen to
     the respective resources if the ticket is revoked. The attribute
     <literal>loss-policy</literal> can have the following values:
    </para>
    <itemizedlist xmlns='http://docbook.org/ns/docbook'>
     <listitem>
      <para>
       <literal>fence</literal>: Fence the nodes that are running the
       relevant resources.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>stop</literal>: Stop the relevant resources.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>freeze</literal>: Do nothing to the relevant resources.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>demote</literal>: Demote relevant resources that are running
       in <literal>master</literal> mode to <literal>slave</literal> mode.
      </para>
     </listitem>
    </itemizedlist>">
    
<!ENTITY boothd-resource-group
"<para xmlns='http://docbook.org/ns/docbook'>
      Each site needs to run one instance of
      <systemitem class='daemon'>boothd</systemitem> that communicates
      with the other booth daemons. The daemon can be started on any node,
      therefore it should be configured as primitive resource. To make the
      <systemitem>boothd</systemitem> resource stay on the same node, if
      possible, add resource stickiness to the configuration. As each daemon
      needs a persistent IP address, configure another primitive with a
      virtual IP address. Group both primitives:</para>">
      
      
<!ENTITY booth-order-constraint     
   "<para xmlns='http://docbook.org/ns/docbook'>
      If a ticket has been granted to a site but all nodes of that site
      should fail to host the <systemitem class='daemon'>boothd</systemitem>
      resource group for any reason, a <quote>split-brain</quote> situation
      among the geographically dispersed sites may occur. In that case, no
      &boothd; instance would be available to safely manage failover of the
      ticket to another site. To avoid a potential concurrency violation of the
      ticket (the ticket is granted to multiple sites simultaneously), add an
      ordering constraint: 
     </para> ">  
     
<!ENTITY failback-nodes
"  <para xmlns='http://docbook.org/ns/docbook'>
    A resource might fail back to its original node when that node is back
    online and in the cluster. If you want to prevent a resource from
    failing back to the node that it was running on, or if you
    want to specify a different node for the resource to fail back to, 
    change its <literal>resource stickiness</literal> value. You can
    either specify resource stickiness when you are creating a resource, or
    afterwards.
   </para>">     
   
<!ENTITY placement-strategy-values
" <variablelist xmlns='http://docbook.org/ns/docbook'>
    <varlistentry>
     <term><literal>default</literal> (default value)</term>
     <listitem>
      <para>
       Utilization values are not considered. Resources are allocated
       according to location scoring. If scores are equal, resources are
       evenly distributed across nodes.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>utilization</literal>
     </term>
     <listitem>
      <para>
       Utilization values are considered when deciding if a node has enough
       free capacity to satisfy a resource&apos;s requirements. However,
       load-balancing is still done based on the number of resources
       allocated to a node.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>minimal</literal>
     </term>
     <listitem>
      <para>
       Utilization values are considered when deciding if a node has enough
       free capacity to satisfy a resource&apos;s requirements. An attempt is
       made to concentrate the resources on as few nodes as possible 
       (to achieve power savings on the remaining nodes).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>balanced</literal>
     </term>
     <listitem>
      <para>
       Utilization values are considered when deciding if a node has enough
       free capacity to satisfy a resource&apos;s requirements. An attempt is
       made to distribute the resources evenly, thus optimizing resource
       performance.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <note xmlns='http://docbook.org/ns/docbook'>
    <title>Configuring Resource Priorities</title>
    <para>
     The available placement strategies are best-effort&mdash;they do not
     yet use complex heuristic solvers to always reach optimum allocation
     results. Ensure that resource priorities are properly set so that
     your most important resources are scheduled first.
    </para>
   </note>">   
   
   <!ENTITY drbd-resource
   " <para xmlns='http://docbook.org/ns/docbook'>
      A resource name that allows some association to the
      respective service (here: NFS). By including the site name too,
      the complete DRBD configuration can be synchronized across
      the sites without causing name conflicts.
     </para>" >
      
 <!ENTITY drbd-disk
   "  <para xmlns='http://docbook.org/ns/docbook'>
       The device that is replicated between the nodes. In our example, LVM
       is used as a storage layer below DRBD, and the volume group name is
       <literal>volgroup</literal>.
      </para>" >   
      
      
 <!ENTITY drbd-device
   "  <para xmlns='http://docbook.org/ns/docbook'>
       The device name for DRBD and its minor number. To differentiate
       between the lower layer DRBD for the local replication and the upper
       layer DRBD for replication between the &geo; cluster sites, the device
       minor numbers <literal>0</literal> and <literal>10</literal> are used.
   </para>" >    
      
<!ENTITY drbd-protocol-c
   "  <para xmlns='http://docbook.org/ns/docbook'>
       DRBD is running in protocol <literal>C</literal>, a synchronous
       replication protocol. Local write operations on the primary node are
       considered completed only after both the local and the remote disk write
       have been confirmed. As a result, loss of a single node is guaranteed not
       to lead to any data loss. Data loss is, of course, inevitable even with
       this replication protocol if both nodes (or their storage subsystems) are
       irreversibly destroyed at the same time.
     </para>" >    
      
<!ENTITY drbd-shared-secret
   "  <para xmlns='http://docbook.org/ns/docbook'>
       A shared-secret is used to validate connection pairs. You need a
       different shared-secret for each connection pair. You can get unique
       values with the <command>uuidgen</command> program.
      </para>" >     
      
<!ENTITY drbd-on
   "  <para xmlns='http://docbook.org/ns/docbook'>
       The <literal>on</literal> section states which host this
       configuration statement applies to.
      </para>" >   
      
<!ENTITY drbd-address
   " <para xmlns='http://docbook.org/ns/docbook'>
      The local IP address and port number of the respective node. Each
      DRBD resource needs an individual port.
     </para>" >         
      
<!ENTITY hawk-versions
" <para xmlns='http://docbook.org/ns/docbook'>
  &productname; 12 SP1 ships two &hawk; versions in
  parallel:</para>
 <itemizedlist xmlns='http://docbook.org/ns/docbook'>
  <listitem >
   <para>&hawk; version <literal>1.0.0</literal> (included in RPM
    package <systemitem class='resource'>hawk</systemitem>). For the
    documentation of this &hawk; version, see the manuals for
    &productname; 12. They are available from 
    <link xmlns:xlink='http://www.w3.org/1999/xlink'
    xlink:href='http://www.suse.com/documentation'/>.</para>
  </listitem>
  <listitem>
   <para>&hawk; version <literal>2</literal> (included in RPM package
    <systemitem class='resource'>hawk2</systemitem>). This version is
    documented in the current chapter.</para>
  </listitem>
 </itemizedlist>
 <para xmlns='http://docbook.org/ns/docbook'>
  The packages <systemitem class='resource'>hawk</systemitem>
  and <systemitem class='resource'>hawk2</systemitem> intentionally
  conflict with each other to prevent your installed version
  from getting accidentally replaced with another version.
 </para>" >         
      
