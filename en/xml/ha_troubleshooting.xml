<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<appendix xml:id="app.ha.troubleshooting" version="5.0"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>Troubleshooting</title>
 <info>
      <abstract>
        <para>
    Strange problems may occur that are not easy to understand, especially
    when starting to experiment with &ha;. However, there are several
    utilities that allow you to take a closer look at the &ha; internal
    processes. This chapter recommends various solutions.
   </para>
      </abstract>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer/>
        <dm:status>editing</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>yes</dm:translation>
        <dm:languages/>
        <dm:release/>
        <dm:repository/>
      </dm:docmanager>
    </info>
    <sect1 xml:id="sec.ha.troubleshooting.install">
  <title>Installation and First Steps</title>

  <para>
   Troubleshooting difficulties when installing the packages or bringing the
   cluster online.
  </para>

  <variablelist>
   <varlistentry>
    <term>Are the HA packages installed?</term>
    <listitem>
     <para>
      The packages needed for configuring and managing a cluster are
      included in the <literal>High Availability</literal> installation
      pattern, available with the &hasi;.
     </para>
     <para>
      Check if &hasi; is installed as an extension to &sls;
      &productnumber; on each of the cluster nodes and if the
      <guimenu>High Availability</guimenu> pattern is installed on each of
      the machines as described in the &instquick;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Is the initial configuration the same for all cluster nodes?</term>
    <listitem>
     <para>
      To communicate with each other, all nodes belonging to the same
      cluster need to use the same <literal>bindnetaddr</literal>,
      <literal>mcastaddr</literal> and <literal>mcastport</literal> as
      described in <xref linkend="cha.ha.setup"/>.
     </para>
     <para>
      Check if the communication channels and options configured in
      <filename>/etc/corosync/corosync.conf</filename> are the same for all
      cluster nodes.
     </para>
     <para>
      In case you use encrypted communication, check if the
      <filename>/etc/corosync/authkey</filename> file is available on all
      cluster nodes.
     </para>
     <para>
      All <filename>corosync.conf</filename> settings except for
      <literal>nodeid</literal> must be the same;
      <filename>authkey</filename> files on all nodes must be identical.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Does the Firewall allow communication via the
            <literal>mcastport</literal>?</term>
    <listitem>
     <para>
      If the mcastport used for communication between the cluster nodes is
      blocked by the firewall, the nodes cannot see each other. When
      configuring the initial setup with &yast; or the bootstrap scripts
      as described in <xref linkend="cha.ha.setup"/> or
      the &instquick;, respectively, the firewall
      settings are usually automatically adjusted.
     </para>
     <para>
      To make sure the mcastport is not blocked by the firewall, check the
      settings in <filename>/etc/sysconfig/SuSEfirewall2</filename> on each
      node. Alternatively, start the &yast; firewall module on each
      cluster node. After clicking <menuchoice> <guimenu>Allowed
      Service</guimenu> <guimenu>Advanced</guimenu> </menuchoice>, add the
      mcastport to the list of allowed <guimenu>UDP Ports</guimenu> and
      confirm your changes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Are &pace; and &corosync; started on each cluster node?</term>
    <listitem>
     <para>
      Usually, starting &pace; also starts the &corosync; service. To
      check if both services are running:
     </para>
<screen>&prompt.root;<command>systemctl</command> status pacemaker corosync</screen>
     <para>
      In case they are not running, start them by executing the following
      command:
     </para>
<screen>&prompt.root;<command>systemctl</command> start pacemaker</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.log">
  <title>Logging</title>

  <variablelist>
   <varlistentry>
    <term>Where to find the log files? </term>
    <listitem>
     <para>
      For the Pacemaker log files, see the settings configured in the
      <literal>logging</literal> section of &corosync.conf;. In case the
      log file specified there should be ignored by Pacemaker, check the
      logging settings in <filename>/etc/sysconfig/pacemaker</filename>,
      Pacemaker's own configuration file. In case
      <literal>PCMK_logfile</literal> is configured there, Pacemaker will
      use the path that is defined by this parameter.
     </para>
     <para>
      If you need a cluster-wide report showing all relevant log files, see
      <xref linkend="vle.ha.crmreport"/> for more information.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>I enabled monitoring but there is no trace of monitoring operations in
          the log files?</term>
    <listitem>
     <para>
      The <systemitem class="daemon">lrmd</systemitem> daemon does not log
      recurring monitor operations unless an error occurred. Logging all
      recurring operations would produce too much noise. Therefore recurring
      monitor operations are logged only once an hour.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>I only get a <literal>failed</literal> message. Is it possible to get more
          information?</term>
    <listitem>
     <para>
      Add the <literal>--verbose</literal> parameter to your commands. If
      you do that multiple times, the debug output becomes quite verbose.
      See the logging data (<command>sudo journalctl -n</command>) for
      useful hints.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How can I get an overview of all my nodes and resources?</term>
    <listitem>
     <para>
      Use the <command>crm_mon</command> command. The following displays the
      resource operation history (option <option>-o</option>) and inactive
      resources (<option>-r</option>):
     </para>
<screen>&prompt.root;<command>crm_mon</command> -o -r</screen>
     <para>
      The display is refreshed when the status changes (to cancel this press
      <keycombo> <keycap function="control"/> <keycap>C</keycap>
      </keycombo>). An example may look like:
     </para>
     <example>
      <title>Stopped Resources</title>
<screen>Last updated: Fri Aug 15 10:42:08 2014
Last change: Fri Aug 15 10:32:19 2014
 Stack: corosync
Current DC: &node2; (175704619) - partition with quorum
Version: 1.1.12-ad083a8
2 Nodes configured
3 Resources configured
       
Online: [ &node1; &node2; ]
       
Full list of resources:
       
my_ipaddress    (ocf::heartbeat:Dummy): Started barett-2
my_filesystem   (ocf::heartbeat:Dummy): Stopped
my_webserver    (ocf::heartbeat:Dummy): Stopped
       
Operations:
* Node &node2;: 
    my_ipaddress: migration-threshold=3
      + (14) start: rc=0 (ok)
      + (15) monitor: interval=10000ms rc=0 (ok)
      * Node &node1;:</screen>
     </example>
     <para>
      The &paceex; PDF, available at <link xlink:href="http://www.clusterlabs.org/doc/"/>, covers three
      different recovery types in the <citetitle>How are OCF Return Codes
      Interpreted?</citetitle> section.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How to view logs?</term>
    <listitem>
     <para>For a more detailed view of what is happening in your
            cluster, use the following command:</para>
      <screen>&prompt.root;<command>crm</command> history log [<replaceable>NODE</replaceable>]</screen>
      <para>Replace <replaceable>NODE</replaceable> with the node you
            want to examine, or leave it empty. See <xref linkend="sec.ha.troubleshooting.history"/> for further
            information.</para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.resource">
  <title>Resources</title>

  <variablelist>
   <varlistentry>
    <term>How can I clean up my resources?</term>
    <listitem>
     <para>
      Use the following commands:
     </para>
<screen>&prompt.root;<command>crm</command> resource list
crm resource cleanup <replaceable>rscid</replaceable> [<replaceable>node</replaceable>]</screen>
     <para>
      If you leave out the node, the resource is cleaned on all nodes. More
      information can be found in
      <xref linkend="sec.ha.manual_config.cleanup"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How can I list my currently known resources?</term>
    <listitem>
     <para>
      Use the command <command>crm resource list</command> to display your
      current resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>I configured a resource, but it always fails. Why?</term>
    <listitem>
     <para>
      To check an OCF script use <command>ocf-tester</command>, for
      instance:
     </para>
<screen>ocf-tester -n ip1 -o ip=<replaceable>YOUR_IP_ADDRESS</replaceable> \
  /usr/lib/ocf/resource.d/heartbeat/IPaddr</screen>
     <para>
      Use <option>-o</option> multiple times for more parameters. The list
      of required and optional parameters can be obtained by running
      <command>crm</command> <option>ra</option> <option>info</option>
      <replaceable>AGENT</replaceable>, for example:
     </para>
<screen>&prompt.root;<command>crm</command> ra info ocf:heartbeat:IPaddr</screen>
     <para>
      Before running ocf-tester, make sure the resource is not managed by
      the cluster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why do resources not fail over and why are there no errors?</term>
    <listitem>
     <para>
      The terminated node might be considered unclean.
      Then it is necessary to fence it. If the &stonith; resource is not
      operational or does not exist, the remaining node will waiting for the
      fencing to happen. The fencing timeouts are typically high, so it may
      take quite a while to see any obvious sign of problems (if ever).
     </para>
     <para>
      Yet another possible explanation is that a resource is simply not
      allowed to run on this node. That may be because of a failure which
      happened in the past and which was not <quote>cleaned</quote>. Or it
      may be because of an earlier administrative action, that is a location
      constraint with a negative score. Such a location constraint is for
      instance inserted by the <command>crm resource migrate</command>
      command.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why can I never tell where my resource will run?</term>
    <listitem>
     <para>
      If there are no location constraints for a resource, its placement is
      subject to an (almost) random node choice. You are well advised to
      always express a preferred node for resources. That does not mean that
      you need to specify location preferences for <emphasis>all</emphasis>
      resources. One preference suffices for a set of related (colocated)
      resources. A node preference looks like this:
     </para>
<screen>location rsc-prefers-&node1; rsc 100: &node1;</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.stonith">
  <title>&stonith; and Fencing</title>

  <variablelist>
   <varlistentry>
    <term>Why does my &stonith; resource not start?</term>
    <listitem>
     <para>
      Start (or enable) operation includes checking the status of the
      device. If the device is not ready, the &stonith; resource will
      fail to start.
     </para>
     <para>
      At the same time the &stonith; plugin will be asked to produce a
      host list. If this list is empty, there is no point in running a
      &stonith; resource which cannot shoot anything. The name of the
      host on which &stonith; is running is filtered from the list, since
      the node cannot shoot itself.
     </para>
     <para>
      If you want to use single-host management devices such as lights-out
      devices, make sure that the &stonith; resource is
      <emphasis>not</emphasis> allowed to run on the node which it is
      supposed to fence. Use an infinitely negative location node preference
      (constraint). The cluster will move the &stonith; resource to
      another place where it can start, but not before informing you.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why does fencing not happen, although I have the &stonith; resource?</term>
    <listitem>
     <para>
      Each &stonith; resource must provide a host list. This list may be
      inserted by hand in the &stonith; resource configuration or
      retrieved from the device itself, for instance from outlet names. That
      depends on the nature of the &stonith; plugin.
      <systemitem>stonithd</systemitem> uses the list to find out which
      &stonith; resource can fence the target node. Only if the node
      appears in the list can the &stonith; resource shoot (fence) the
      node.
     </para>
     <para>
      If <systemitem>stonithd</systemitem> does not find the node in any of
      the host lists provided by running &stonith; resources, it will ask
      <systemitem>stonithd</systemitem> instances on other nodes. If the
      target node does not show up in the host lists of other
      <systemitem>stonithd</systemitem> instances, the fencing request ends
      in a timeout at the originating node.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why does my &stonith; resource fail occasionally?</term>
    <listitem>
     <para>
      Power management devices may give up if there is too much broadcast
      traffic. Space out the monitor operations. Given that fencing is
      necessary only once in a while (and hopefully never), checking the
      device status once a few hours is more than enough.
     </para>
     <para>
      Also, some of these devices may refuse to talk to more than one party
      at the same time. This may be a problem if you keep a terminal or
      browser session open while the cluster tries to test the status.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.history">
   <title>History</title>
   <variablelist>
     <varlistentry>
       <term>How to retrieve status information or a log from a failed resource?</term>
       <listitem>
         <para>Use the <command>history</command> command and its subcommand
         <command>resource</command>:
         </para>
         <screen>&prompt.root;<command>crm</command> history resource <replaceable>NAME1</replaceable></screen>
         <para>This gives you a full transition log for the given resource only.
          However, it is possible to investigate more than one resource. Append
          the resource names after the first.
         </para>
         <para>If you followed some naming conventions (see section <xref linkend="app.naming" xrefstyle="select:number"/>), the
         <command>resource</command> command makes it easier to investigate
          a group of resources. For example, this command investigates all
          primitives starting with <literal>db</literal>:
         </para>
         <screen>&prompt.root;<command>crm</command> history resource db*</screen>
         <para>View the log file in
           <filename>/var/cache/crm/history/live/barett-1/ha-log.txt</filename>.</para>
       </listitem>
     </varlistentry>
     <varlistentry>
       <term>How can I reduce the history output?</term>
       <listitem>
         <para>There are two options for the <command>history</command> command:</para>
         <itemizedlist>
           <listitem>
             <para>Use <command>exclude</command></para>
           </listitem>
           <listitem>
             <para>Use <command>timeframe</command></para>
           </listitem>
         </itemizedlist>

         <para>The <command>exclude</command> command let you set an
            additive regular expression that excludes certain patterns
            from the log. For example, the following command excludes
            all SSH, &systemd;, and kernel messages: </para>
         <screen>&prompt.root;<command>crm</command> history exclude ssh|systemd|kernel.</screen>

         <para>With the <command>timeframe</command> command you limit
            the output to a certain range. For example, the following
            command shows all the events on August 23rd from 12:00 to
            12:30:</para>
         <screen>&prompt.root;<command>crm</command> history timeframe "Aug 23 12:00" "Aug 23 12:30"</screen>
       </listitem>
     </varlistentry>
     <varlistentry>
       <term>How can I store a <quote>session</quote> for later inspection?</term>
       <listitem>
         <para>When you encounter a bug or an event that needs further
            examination, it is useful to store all the current settings.
            This file can be sent to support or viewed with
              <command>bzless</command>. For example:</para>
         <screen>&prompt.crm.hist;<command>timeframe</command> "Oct 13 15:00" "Oct 13 16:00"
&prompt.crm.hist;<command>session</command> save &exampleuser_plain;-test
&prompt.crm.hist;<command>session</command> pack
Report saved in '/root/&exampleuser_plain;-test.tar.bz2'</screen>
       </listitem>
     </varlistentry>
   </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.hawk2">
  <title>&hawk2;</title>
  <variablelist>
   <varlistentry xml:id="vle.trouble.hawk2.cert">
    <term>Replacing the Self-Signed Certificate</term>
    <listitem>
     <para> To avoid the warning about the self-signed certificate on first
      &hawk2; start-up, replace the automatically created certificate with
      your own certificate (or a certificate that was signed by an official
      Certificate Authority, CA):</para>
     <procedure>
      <step>
       <para>Replace <filename>/etc/hawk/hawk.key</filename> with the private
        key.</para>
      </step>
      <step>
       <para>Replace <filename>/etc/hawk/hawk.pem</filename> with the
        certificate that &hawk2; should present.</para>
      </step>
     </procedure>
     <para>
      Change ownership of the files to <literal>root:haclient</literal>
      and make the files accessible to the group:</para>
     <screen>chown root:haclient /etc/hawk/hawk.key /etc/hawk/hawk.pem
chmod 640 /etc/hawk/hawk.key /etc/hawk/hawk.pem</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.misc">
  <title>Miscellaneous</title>

  <variablelist>
   <varlistentry>
<!-- FATE#311413 -->
    <term>How can I run commands on all cluster nodes?</term>
    <listitem>
     <para>
      Use the command <command>pssh</command> for this task. If necessary,
      install <systemitem class="resource">pssh</systemitem>. Create a file
      (for example <filename>hosts.txt</filename>) where you collect all
      your IP addresses or host names you want to visit. Make sure you can
      log in with <command>ssh</command> to each host listed in your
      <filename>hosts.txt</filename> file. If everything is correctly
      prepared, execute <command>pssh</command> and use the
      <filename>hosts.txt</filename> file (option <option>-h</option>) and
      the interactive mode (option <option>-i</option>) as shown in this
      example:
     </para>
<screen>pssh -i -h hosts.txt "ls -l /corosync/*.conf"
[1] 08:28:32 [SUCCESS] root@&wsII;.&exampledomain;
-rw-r--r-- 1 root root 1480 Nov 14 13:37 /etc/corosync/corosync.conf
[2] 08:28:32 [SUCCESS] root@&wsIIIip;
-rw-r--r-- 1 root root 1480 Nov 14 13:37 /etc/corosync/corosync.conf</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>What is the state of my cluster?</term>
    <listitem>
     <para>
      To check the current state of your cluster, use one of the programs
      <literal>crm_mon</literal> or <command>crm</command>
      <option>status</option>. This displays the current DC and all the
      nodes and resources known by the current node.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why can several nodes of my cluster not see each other?</term>
    <listitem>
     <para>
      There could be several reasons:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Look first in the configuration file
        <filename>/etc/corosync/corosync.conf</filename>. Check if the
        multicast or unicast address is the same for every node in the
        cluster (look in the <literal>interface</literal> section with the
        key <literal>mcastaddr</literal>).
       </para>
      </listitem>
      <listitem>
       <para>
        Check your firewall settings.
       </para>
      </listitem>
      <listitem>
       <para>
        Check if your switch supports multicast or unicast addresses.
       </para>
      </listitem>
      <listitem>
       <para>
        Check if the connection between your nodes is broken. Most often,
        this is the result of a badly configured firewall. This also may be
        the reason for a <emphasis>split brain</emphasis> condition, where
        the cluster is partitioned.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why can an OCFS2 device not be mounted?</term>
    <listitem>
     <para>
      Check the log messages (<command>sudo journalctl -n</command>) for the
      following line:
     </para>
<screen>Jan 12 09:58:55 &node1; lrmd: [3487]: info: RA output: [...] 
  ERROR: Could not load ocfs2_stackglue
Jan 12 16:04:22 &node1; modprobe: FATAL: Module ocfs2_stackglue not found.</screen>
     <para>
      In this case the Kernel module <filename>ocfs2_stackglue.ko</filename>
      is missing. Install the package
      <filename>ocfs2-kmp-default</filename>,
      <filename>ocfs2-kmp-pae</filename> or
      <filename>ocfs2-kmp-xen</filename>, depending on the installed Kernel.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="vle.ha.crmreport">
<!-- FATE#310174 -->
    <term>How can I create a report with an analysis of all my cluster nodes?</term>
    <listitem>
     <para> On the &crmshell;, use <command>crm report</command> to
            create a report. This tool compiles: </para>
     <itemizedlist>
      <listitem>
       <para>
        Cluster-wide log files,
       </para>
      </listitem>
      <listitem>
       <para>
        Package states,
       </para>
      </listitem>
      <listitem>
       <para>
        DLM/OCFS2 states,
       </para>
      </listitem>
      <listitem>
       <para>
        System information,
       </para>
      </listitem>
      <listitem>
       <para>
        CIB history,
       </para>
      </listitem>
      <listitem>
       <para>
        Parsing of core dump reports, if a debuginfo package is installed.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Usually run <command>crm report</command> with the following command:
     </para>
<screen>&prompt.root;<command>crm report</command> -f 0:00 -n &node1; -n &node2;</screen>
     <para>
      The command extracts all information since 0am on the hosts &node1;
      and &node2; and creates a <literal>*.tar.bz2</literal> archive named
      <filename>crm_report-<replaceable>DATE</replaceable>.tar.bz2</filename>
      in the current directory, for example,
      <filename>crm_report-Wed-03-Mar-2012</filename>. If you are only
      interested in a specific time frame, add the end time with the
      <option>-t</option> option.
     </para>
     <warning>
      <title>Remove Sensitive Information</title>
      <para>
       The <command>crm report</command> tool tries to remove any sensitive
       information from the CIB and the peinput files, however, it cannot do
       everything. If you have more sensitive information, supply additional
       patterns. The log files and the <command>crm_mon</command>,
       <command>ccm_tool</command>, and <command>crm_verify</command> output
       are <emphasis>not</emphasis> sanitized.
      </para>
      <para>
       Before sharing your data in any way, check the archive and remove all
       information you do not want to expose.
      </para>
     </warning>
     <para>
      Customize the command execution with further options. For example, if
      you have a Pacemaker cluster, you certainly want to add the option
      <option>-A</option>. In case you have another user who has permissions
      to the cluster, use the <option>-u</option> option and specify this
      user (in addition to &rootuser; and
      <systemitem class="username">hacluster</systemitem>). In case you have
      a non-standard SSH port, use the <option>-X</option> option to add the
      port (for example, with the port 3479, use <literal>-X "-p
      3479"</literal>). Further options can be found in the man page of
      <command>crm report</command>.
     </para>
     <para>
      After <command>crm report</command> has analyzed all the relevant log
      files and created the directory (or archive), check the log files for
      an uppercase <literal>ERROR</literal> string. The most important files
      in the top level directory of the report are:
     </para>
     <variablelist>
      <varlistentry>
       <term><filename>analysis.txt</filename>
       </term>
       <listitem>
        <para>
         Compares files that should be identical on all nodes.
        </para>
       </listitem>
      </varlistentry>
       <varlistentry>
         <term><filename>corosync.txt</filename>
         </term>
         <listitem>
           <para>
             Contains a copy of the &corosync; configuration file.
           </para>
         </listitem>
       </varlistentry>
       <varlistentry>
       <term><filename>crm_mon.txt</filename>
       </term>
       <listitem>
        <para>
         Contains the output of the <command>crm_mon</command> command.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term><filename>description.txt</filename>
       </term>
       <listitem>
        <para>
         Contains all cluster package versions on your nodes. There is also
         the <filename>sysinfo.txt</filename> file which is node specific.
         It is linked to the top directory.
        </para>
        <para>This file can be used as a template to describe the issue
        you encountered and post it to <link xlink:href="https://github.com/ClusterLabs/crmsh/issues"/>.</para>
       </listitem>
      </varlistentry>
      <varlistentry>
        <term><filename>members.txt</filename></term>
        <listitem>
          <para>A list of all nodes</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><filename>sysinfo.txt</filename></term>
        <listitem>
          <para>Contains a list of all relevant package names and their
            versions. Additionally, there is also a list of configuration
            files which are different from the original RPM package.</para>
        </listitem>
      </varlistentry>
     </variablelist>
     <para>
      Node-specific files are stored in a subdirectory named by the node's
      name. It contains a copy of the directory <filename>/etc</filename>
      of the respective node.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.troubleshooting.moreinfo">
  <title>For More Information</title>

  <para>
   For additional information about high availability on Linux, including
   configuring cluster resources and managing and customizing a &ha;
   cluster, see
   <link xlink:href="http://clusterlabs.org/wiki/Documentation"/>.
  </para>
 </sect1>
</appendix>