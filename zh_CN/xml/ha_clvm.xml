<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="ha_clvm.xml" version="5.0" xml:id="cha.ha.clvm">
 <title>群集式逻辑卷管理器 (cLVM)</title>
 <info>
      <abstract>
        <para>
    当管理群集上的共享储存区时，所有节点必须收到有关对储存子系统所做更改的通知。Linux 卷管理器 2 (LVM2) 广泛用于管理本地储存，已扩展为支持对整个群集中的卷组进行透明管理。可使用与本地储存相同的命令来管理群集卷组。
   </para>
      </abstract>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer/>
        <dm:status>编辑</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>yes</dm:translation>
        <dm:languages/>
        <dm:release/>
        <dm:repository/>
      </dm:docmanager>
    </info>
    <sect1 xml:id="sec.ha.clvm.overview">
  <title>概念概述</title>



  <para>
   群集 LVM 集成了不同工具：
  </para>

  <variablelist>
   <varlistentry>
    <term>分布式锁管理器（DLM）</term>
    <listitem>
     <para>
      集成了对 cLVM 的磁盘访问。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>逻辑卷管理器 2 (LVM2)</term>
    <listitem>
     <para>
      支持将一个文件系统灵活分布到多个磁盘上。LVM 可提供磁盘空间虚拟池。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>群集式逻辑卷管理器 (cLVM)</term>
    <listitem>
     <para>
      集成了对 LVM2 元数据的访问，以使每个节点都了解相关更改。cLVM 未集成对共享数据本身的访问；要使 cLVM 可执行此操作，必须在 cLVM 管理的储存区上配置 OCFS2 或其他群集感知应用程序。
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ha.clvm.config">
  <title>cLVM 配置</title>

  <para>
   根据具体情况，可使用具有以下层的 cLVM 创建 RAID 1 设备：
  </para>

  <remark>toms 2010-03-12 (DEV): What are the advantages and disadvantages?</remark>

  <itemizedlist>
   <listitem>
    <formalpara>
     <title>LVM</title>
     <para>
      这是非常灵活的解决方案，可用于增大或减小文件系统大小、添加更多物理储存空间或创建文件系统快照。有关此方法的描述，请参见<xref linkend="sec.ha.clvm.scenario.iscsi"/>。
     </para>
    </formalpara>
   </listitem>
   <listitem>
    <formalpara>
     <title>DRBD</title>
     <para>
      此解决方案仅提供 RAID 0（分段）和 RAID 1（镜像）。有关上一方法的描述，请参见<xref linkend="sec.ha.clvm.scenario.drbd"/>。
     </para>
    </formalpara>
   </listitem>
    
   
  </itemizedlist>
  <para>
   请确保已满足以下先决条件：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     共享储存设备是可用的，如通过光纤通道、FCoE、SCSI、iSCSI SAN 或 DRBD* 提供的共享储存设备。
    </para>
   </listitem>
   <listitem>
    <para>
     如果是 DRBD，那么两个节点都必须是主节点（如以下过程中所述）。
    </para>
   </listitem>
   <listitem>
    <para>
     检查 LVM2 的锁定类型是否为群集感知。<filename>/etc/lvm/lvm.conf</filename> 中的关键字 <literal>locking_type</literal> 必须包含值 <literal>3</literal>（默认值为 <literal>1</literal>）。如果需要，将此配置复制到所有节点。
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>先创建群集资源</title>
   <para>
    首先如<xref linkend="sec.ha.clvm.config.resources"/>中所述创建群集资源，然后创建 LVM 卷。否则，稍后将无法删除卷。
   </para>
  </note>

  <sect2 xml:id="sec.ha.clvm.config.cmirrord">
   <title>配置 Cmirrord</title>

   <para>
    要跟踪群集中的镜像日志信息，可以使用 <systemitem class="daemon">cmirrord</systemitem> 守护程序。如果此守护程序未运行，则无法处理群集镜像。
   </para>
   <para>
    假定 <filename>/dev/sda</filename> 和 <filename>/dev/sdb</filename> 是共享储存设备。必要时请使用您自己的设备名称替换上述名称。按如下所示继续：
   </para>
   <procedure>
    <step>
     <para>
      创建一个至少包含两个节点的群集。
     </para>
    </step>
    <step>
     <para>
      配置群集以运行 <command>dlm</command>、<command>clvmd</command> 和 STONITH：
     </para>
<screen><prompt role="root">root # </prompt><command>crm</command> configure
<prompt role="custom">crm(live)configure# </prompt><command>primitive</command> clvmd ocf:lvm2:clvmd \
        op stop interval="0" timeout="100" \
        op start interval="0" timeout="90" \
        op monitor interval="20" timeout="60"
<prompt role="custom">crm(live)configure# </prompt><command>primitive</command> dlm ocf:pacemaker:controld \
        op start interval="0" timeout="90" \
        op stop interval="0" timeout="100" \
        op monitor interval="60" timeout="60"
<prompt role="custom">crm(live)configure# </prompt><command>primitive</command> sbd_stonith stonith:external/sbd \
        params pcmk_delay_max=30
<prompt role="custom">crm(live)configure# </prompt><command>group</command> base-group dlm clvmd
<prompt role="custom">crm(live)configure# </prompt><command>clone</command> base-clone base-group \
        meta interleave="true"</screen>
    </step>
    <step>
     <para>
      使用 <command>exit</command> 退出 crmsh 并提交更改。
     </para>
    </step>
    <step>
     <para>
      创建群集卷组 (VG)：

     </para>
<screen><prompt role="root">root # </prompt><command>pvcreate</command> /dev/sda /dev/sdb
<prompt role="root">root # </prompt><command>vgcreate</command> -cy vg /dev/sda /dev/sdb</screen>
    </step>
    <step>
     <para>
      在群集中创建镜像日志逻辑卷 (LV)：
     </para>
<screen><prompt role="root">root # </prompt><command>lvcreate</command> -nLv -m1 -l10%VG vg --mirrorlog mirrored</screen>
    </step>
    <step>
     <para>
      使用 <command>lvs</command> 显示进度。如果百分数已达到 100%，则表示镜像磁盘已成功同步。
     </para>
    </step>
    <step xml:id="st.ha.clvm.config.cmirrord.test">
     <para>
      要测试群集卷 <filename>/dev/vg/lv</filename>，请执行下列步骤：
     </para>
     <substeps performance="required">
      <step>
       <para>
        读取或写入到 <filename>/dev/vg/lv</filename>。
       </para>
      </step>
      <step>
       <para>
        使用 <command>lvchange</command>
        <option> -an</option> 停用 LV。
       </para>
      </step>
      <step>
       <para>
        使用 <command>lvchange</command>
        <option> -ay</option> 激活 LV。
       </para>
      </step>
      <step>
       <para>
        使用 <command>lvconvert</command> 将镜像日志转换为磁盘日志。
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      在其他群集 VG 中创建镜像日志 LV。此卷组与先前的卷组不同。
     </para>
    </step>
   </procedure>

   <para>
    当前的 cLVM 在每个镜像端只能处理一个物理卷 (PV)。如果一个镜像实际由多个需要连接或拆分的 PV 组成，则 <command>lvcreate</command> 无法了解此情况。因此，<command>lvcreate</command> 和 <systemitem>cmirrord</systemitem> 元数据需要了解 PV 在其中一端的<quote>分组</quote>，以便有效地支持 RAID10。
   </para>
   <para>
    为支持 RAID10 处理 <systemitem class="daemon">cmirrord</systemitem>，请使用以下过程（假定 <filename>/dev/sda</filename> 和 <filename>/dev/sdb</filename> 是共享储存设备）：
   </para>
   <procedure>

    <step>
     <para>
      创建卷组 (VG)：
     </para>
<screen><prompt role="root">root # </prompt><command>pvcreate</command> /dev/sda /dev/sdb
<prompt role="root">root # </prompt><command>vgcreate</command> vg /dev/sda /dev/sdb</screen>
    </step>
    <step>
     <para>
      打开文件 <filename>/etc/lvm/lvm.conf</filename> 并转到 <literal>allocation</literal> 部分。设置下列行并保存文件：
     </para>
<screen>mirror_legs_require_separate_pvs = 1</screen>
    </step>
    <step>
     <para>
      将标记添加到 PV：
     </para>
<screen><prompt role="root">root # </prompt><command>pvchange</command> --addtag @a /dev/sda
<prompt role="root">root # </prompt><command>pvchange</command> --addtag @b /dev/sdb</screen>
     <para>
      标记是无序的关键字或指派给储存对象元数据的术语。使用标记功能可以采用您认为有用的方式将无序的标记列表附加到 LVM 储存对象元数据，从而对储存对象集合进行分类。
     </para>
    </step>
    <step>
     <para>
      列出标记：
     </para>
<screen><prompt role="root">root # </prompt><command>pvs</command> -o pv_name,vg_name,pv_tags /dev/sd{a,b}</screen>
     <para>
      您应收到以下输出结果：
     </para>
<screen>  PV         VG     PV Tags
  /dev/sda vgtest a
  /dev/sdb vgtest b</screen>
    </step>
   </procedure>
   <para>
    如需有关 LVM 的更多信息，请参见《SUSE Linux Enterprise Server <phrase role="productnumber"><phrase os="sles">12 SP2</phrase></phrase> <citetitle> 储存管理指南</citetitle>》中的“<citetitle>LVM 配置</citetitle>”一章，网址：<link xlink:href="http://www.suse.com/documentation/"/>。
   </para>
  </sect2>

  <sect2 xml:id="sec.ha.clvm.config.resources">
   <title>创建群集资源</title>
   <para>
    准备群集以便使用 cLVM 包括以下基本步骤：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <xref linkend="pro.ha.clvm.dlmresource" xrefstyle="select:title"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="pro.ha.clvm.lvmresources" xrefstyle="select:title"/>
     </para>
    </listitem>
   </itemizedlist>
   <procedure xml:id="pro.ha.clvm.dlmresource">
    <title>创建 DLM 资源</title>

    <note>
     <title>cLVM 和 OCFS2 的 DLM 资源</title>
     <para>
      cLVM 和 OCFS2 都需要一个在群集中的所有节点上运行的 DLM 资源，因而通常配置为一个克隆。如果设置既包括 OCFS2 也包括 cLVM，则为 OCFS2 和 cLVM 配置<emphasis>一个</emphasis> DLM 资源就足够了。
     </para>
    </note>
    <step>
     <para>
      以 <systemitem class="username">root</systemitem> 用户身份启动外壳并登录。
     </para>
    </step>
    <step>
     <para>
      运行 <command>crm</command> <option> configure</option>。
     </para>
    </step>
    <step>
     <para>
      使用 <command>show</command> 检查群集资源的当前配置。
     </para>
    </step>
    <step>
     <para>
      如果已经配置 DLM 资源（及相应的基本组和基本克隆），则继续<xref linkend="pro.ha.clvm.lvmresources"/>。
     </para>
     <para>
      否则，如<xref linkend="pro.ocfs2.resources"/>中所述配置 DLM 资源和相应的基本组和基本克隆。
     </para>
    </step>
    <step>
     <para>
      使用 <command>exit</command> 保留 crm 当前配置。
     </para>
    </step>
   </procedure>
   <procedure xml:id="pro.ha.clvm.lvmresources">
    <title>创建 LVM 和 cLVM 资源</title>
    <step>
     <para>
      以 <systemitem class="username">root</systemitem> 用户身份启动外壳并登录。
     </para>
    </step>
    <step>
     <para>
      运行 <command>crm</command> <option> configure</option>。
     </para>
    </step>
    <step>
     <para>
      如下所示配置 cLVM 资源：
     </para>
<screen><prompt role="custom">crm(live)configure# </prompt><command>primitive</command> clvm ocf:lvm2:clvmd \
      params daemon_timeout="30"</screen>


    </step>
    <step>
     <para>
      如下所示为卷组配置 LVM 资源：
     </para>
<screen><prompt role="custom">crm(live)configure# </prompt><command>primitive</command> vg1 ocf:heartbeat:LVM \
      params volgrpname="cluster-vg" \
      op monitor interval="60" timeout="60"</screen>
    </step>
    <step>
     <para>
      如果希望仅在<emphasis>一个</emphasis>节点上激活卷组，则如下所述配置 LVM 资源并忽略<xref linkend="step.ha.clvm.lvmresources.group"/>：
     </para>
<screen><prompt role="custom">crm(live)configure# </prompt><command>primitive</command> vg1 ocf:heartbeat:LVM \
      params volgrpname="cluster-vg" exclusive="yes" \
      op monitor interval="60" timeout="60"</screen>
     <para>
      在这种情况下，cLVM 将保护 VG 内的所有逻辑卷，防止它们在多个节点上激活，这也是非群集应用程序的一种附加保护措施。
     </para>
    </step>
    <step xml:id="step.ha.clvm.lvmresources.group">
     <para>
      要确保在群集范围内激活 cLVM 和 LVM 资源，请向在<xref linkend="pro.ocfs2.resources"/>中创建的基本组添加这两个原始资源：
     </para>
     <substeps performance="required">
      <step>
       <para>
        输入
       </para>
<screen><prompt role="custom">crm(live)configure# </prompt><command>edit</command> base-group</screen>
      </step>
      <step>
       <para>
        在打开的 vi 编辑器中，如下所示修改组并保存更改：
       </para>
<screen><prompt role="custom">crm(live)configure# </prompt><command>group</command> base-group dlm clvm vg1 ocfs2-1</screen>
       <important>
        <title>无 OCFS2 的设置</title>
        <para>
         如果设置不包括 OCFS2，则忽略基本组中的 <literal>ocfs2-1</literal> 原始资源。
        </para>
       </important>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      使用 <command>show</command> 复查更改。

     </para>
    </step>
    <step>
     <para>
      如果全部都正确，则使用 <command>commit</command> 提交更改，并使用 <command>exit</command> 退出 crm 当前配置。
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.ha.clvm.scenario.iscsi">
   <title>方案：iSCSI 在 SAN 上的 cLVM</title>
   <para>
    以下方案使用两个 SAN 盒，将其 iSCSI 目标导出到多个客户端。大致想法如<xref linkend="fig.ha.clvm.scenario.iscsi"/>所示。
   </para>
   <figure xml:id="fig.ha.clvm.scenario.iscsi">
    <title>设置使用 cLVM 的 iSCSI</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="ha_clvm.svg" width="80%"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="ha_clvm.png" width="45%"/>
     </imageobject>
    </mediaobject>
   </figure>
   <warning>
    <title>数据丢失</title>
    <para>
     以下过程将损坏磁盘上的所有数据！
    </para>
   </warning>
   <para>
    首先只配置一个 SAN 盒。每个 SAN Box 都需要导出自己的 iSCSI 目标。按如下所示继续：
   </para>

   <procedure xml:id="pro.ha.clvm.scenario.iscsi.targets">
    <title>配置 iSCSI 目标 (SAN)</title>
    <step>
     <para>
      运行 YaST，然后单击<menuchoice> <guimenu> 网络服务</guimenu> <guimenu> iSCSI LIO 目标</guimenu> </menuchoice> 启动 iSCSI 服务器模块。
     </para>
    </step>
    <step>
     <para>
      如果要在计算机引导时启动 iSCSI 目标，请选择<guimenu>引导时</guimenu>，否则请选择<guimenu>手动</guimenu>。
     </para>
    </step>
    <step>
     <para>
      如果正在运行防火墙，请启用<guimenu>打开防火墙中的端口</guimenu>。
     </para>
    </step>
    <step>
     <para>
      切换到<guimenu>全局</guimenu>选项卡。如果需要身份验证，请启用进来的和/或出去的身份验证。在本例中，我们选择<guimenu>无身份验证</guimenu>。
     </para>
    </step>
    <step>
     <para>
      添加新的 iSCSI 目标：
     </para>
     <substeps performance="required">
      <step>
       <para>
        切换到<guimenu>目标</guimenu>选项卡。
       </para>
      </step>
      <step>
       <para>
        单击<guimenu>添加</guimenu>。
       </para>
      </step>
      <step xml:id="st.ha.clvm.iscsi.iqn">
       <para>
        输入目标名称。名称需要采用如下所示的格式：
       </para>
<screen>iqn.<replaceable>DATE</replaceable>.<replaceable>DOMAIN</replaceable></screen>
       <para>
        有关格式的更多信息，请参见 <citetitle>3.2.6.3.1. Type "iqn." (iSCSI Qualified Name)</citetitle>（3.2.6.3.1.“iqn.”（iSCSI 限定名称）类型）一节，网址：<link xlink:href="http://www.ietf.org/rfc/rfc3720.txt"/>。
       </para>
      </step>
      <step>
       <para>
        如果需要描述性更强的名称，可以进行更改，但要确保不同目标之间的标识符是唯一的。
       </para>
      </step>
      <step>
       <para>
        单击<guimenu>添加</guimenu>。
       </para>
      </step>
      <step>
       <para>
        在<guimenu>路径</guimenu>中输入设备名，并使用 <guimenu>Scsiid</guimenu>。
       </para>
      </step>
      <step>
       <para>
        单击<guimenu>下一步</guimenu>两次。
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      出现警告框时单击<guimenu>是</guimenu>进行确认。
     </para>
    </step>
    <step>
     <para>
      打开配置文件 <filename>/etc/iscsi/iscsid.conf</filename>，将参数 <literal>node.startup</literal> 更改为 <literal>automatic</literal>。
     </para>
    </step>
   </procedure>
   <para>
    现在按如下方式设置 iSCSI 发起程序：
   </para>
   <procedure xml:id="pro.ha.clvm.scenarios.iscsi.initiator">
    <title>配置 iSCSI 发起程序</title>
    <step>
     <para>
      运行 YaST，然后单击<menuchoice> <guimenu> 网络服务</guimenu> <guimenu> iSCSI 发起程序</guimenu> </menuchoice> 。
     </para>
    </step>
    <step>
     <para>
      如果要在计算机引导时启动 iSCSI 发起程序，请选择<guimenu>引导时</guimenu>，否则请将其设置为<guimenu>手动</guimenu>。
     </para>
    </step>
    <step>
     <para>
      切换到<guimenu>发现</guimenu>选项卡并单击<guimenu>发现</guimenu>按钮。
     </para>
    </step>
    <step>
     <para>
      添加 iSCSI 目标的 IP 地址和端口（请参见<xref linkend="pro.ha.clvm.scenario.iscsi.targets"/>）。通常，可以保留端口并使用其默认值。
     </para>
    </step>
    <step>
     <para>
      如果使用身份验证，请插入进来的和出去的用户名和口令，否则请激活<guimenu>无身份验证</guimenu>。
     </para>
    </step>
    <step>
     <para>
      选择<guimenu>下一步</guimenu>。找到的连接随即显示在列表中。
     </para>
    </step>
    <step>
     <para>
      按<guimenu>完成</guimenu>继续。
     </para>
    </step>
    <step>
     <para>
      打开外壳，并以 <systemitem class="username">root</systemitem> 用户身份登录。
     </para>
    </step>
    <step>
     <para>
      测试 iSCSI 发起程序是否已成功启动：
     </para>
<screen><prompt role="root">root # </prompt><command>iscsiadm</command> -m discovery -t st -p 192.168.3.100
192.168.3.100:3260,1 iqn.2010-03.de.jupiter:san1</screen>
    </step>
    <step>
     <para>
      建立会话：
     </para>
<screen><prompt role="root">root # </prompt><command>iscsiadm</command> -m node -l -p 192.168.3.100 -T iqn.2010-03.de.jupiter:san1
Logging in to [iface: default, target: iqn.2010-03.de.jupiter:san1, portal: 192.168.3.100,3260]
Login to [iface: default, target: iqn.2010-03.de.jupiter:san1, portal: 192.168.3.100,3260]: successful</screen>
     <para>
      使用 <command>lsscsi</command> 查看设备名：
     </para>
<screen>...
[4:0:0:2]    disk    IET      ...     0     /dev/sdd
[5:0:0:1]    disk    IET      ...     0     /dev/sde</screen>
     <para>
      查找第三列中有 <literal>IET</literal> 的项。在本例中，设备为 <filename>/dev/sdd</filename> 和 <filename>/dev/sde</filename>。
     </para>
    </step>
   </procedure>
   <procedure xml:id="pro.ha.clvm.scenarios.iscsi.lvm">
    <title>创建 LVM 卷组</title>
    <step>
     <para>
      打开已按<xref linkend="pro.ha.clvm.scenarios.iscsi.initiator"/>运行 iSCSI 发起程序的一个节点上的 <systemitem class="username">root</systemitem> 外壳。
     </para>
    </step>
    <step>
     <para>
      使用命令 <command>pvcreate</command> 在磁盘 <filename>/dev/sdd</filename> 和 <filename>/dev/sde</filename> 上准备 LVM 的物理卷：
     </para>
<screen><prompt role="root">root # </prompt><command>pvcreate</command> /dev/sdd
<prompt role="root">root # </prompt><command>pvcreate</command> /dev/sde</screen>
    </step>
    <step>
     <para>
      在这两个磁盘上创建群集感知卷组：
     </para>
<screen><prompt role="root">root # </prompt><command>vgcreate</command> --clustered y clustervg /dev/sdd /dev/sde</screen>
    </step>
    <step>
     <para>
      根据需要创建逻辑卷：
     </para>
<screen><prompt role="root">root # </prompt><command>lvcreate</command> --name clusterlv --size 500M clustervg</screen>
    </step>
    <step>
     <para>
      使用 <command>pvdisplay</command> 检查物理卷：
     </para>
<screen>  --- Physical volume ---
      PV Name               /dev/sdd
      VG Name               clustervg
      PV Size               509,88 MB / not usable 1,88 MB
      Allocatable           yes
      PE Size (KByte)       4096
      Total PE              127
      Free PE               127
      Allocated PE          0
      PV UUID               52okH4-nv3z-2AUL-GhAN-8DAZ-GMtU-Xrn9Kh
      
      --- Physical volume ---
      PV Name               /dev/sde
      VG Name               clustervg
      PV Size               509,84 MB / not usable 1,84 MB
      Allocatable           yes
      PE Size (KByte)       4096
      Total PE              127
      Free PE               127
      Allocated PE          0
      PV UUID               Ouj3Xm-AI58-lxB1-mWm2-xn51-agM2-0UuHFC</screen>
    </step>
    <step>
     <para>
      使用 <command>vgdisplay</command> 检查卷组：
     </para>
<screen>  --- Volume group ---
      VG Name               clustervg
      System ID
      Format                lvm2
      Metadata Areas        2
      Metadata Sequence No  1
      VG Access             read/write
      VG Status             resizable
      Clustered             yes
      Shared                no
      MAX LV                0
      Cur LV                0
      Open LV               0
      Max PV                0
      Cur PV                2
      Act PV                2
      VG Size               1016,00 MB
      PE Size               4,00 MB
      Total PE              254
      Alloc PE / Size       0 / 0
      Free  PE / Size       254 / 1016,00 MB
      VG UUID               UCyWw8-2jqV-enuT-KH4d-NXQI-JhH3-J24anD</screen>
    </step>
   </procedure>
   <para>
    创建卷并启动资源后，会显示一个名为 <filename>/dev/dm-<replaceable>*</replaceable></filename> 的新设备。建议使用 LVM 资源上的群集文件系统，例如 OCFS。有关详细信息，请参见<xref linkend="cha.ha.ocfs2"/>。
   </para>


  </sect2>



  <sect2 xml:id="sec.ha.clvm.scenario.drbd">
   <title>方案：使用 DRBD 的 cLVM</title>
   <para>
    如果数据中心位于城市、国家/地区或大洲的不同区域，则可使用以下方案。
   </para>
   <procedure xml:id="pro.ha.clvm.withdrbd">
    <title>创建使用 DRBD 的群集感知卷组</title>
    <step>
     <para>
      创建主/主 DRBD 资源：
     </para>
     <substeps performance="required">
      <step>
       <para>
        首先，按<xref linkend="pro.drbd.configure"/>中所述将 DRBD 设备设置为主/从模式。确保两个节点上的磁盘状态均为 <literal>up-to-date</literal>。使用 <command>drbdadm status</command> 确认是否如此。
       </para>
      </step>
      <step>
       <para>
        将以下选项添加到配置文件（通常类似 <filename>/etc/drbd.d/r0.res</filename>）：
       </para>
<screen>resource r0 {
  startup {
    become-primary-on both;
  }

  net {
     allow-two-primaries;
  }
  ...
}</screen>
      </step>
      <step>
       <para>
        将更改的配置文件复制到另一个节点，例如：
       </para>
<screen><prompt role="root">root # </prompt><command>scp</command> /etc/drbd.d/r0.res venus:/etc/drbd.d/</screen>
      </step>
      <step>
       <para>
        在<emphasis>两个</emphasis>节点上运行以下命令：
       </para>
<screen><prompt role="root">root # </prompt><command>drbdadm</command> disconnect r0
<prompt role="root">root # </prompt><command>drbdadm</command> connect r0
<prompt role="root">root # </prompt><command>drbdadm</command> primary r0</screen>
      </step>
      <step>
       <para>
        检查节点的状态：
    </para>
    <screen><prompt role="root">root # </prompt><command>drbdadm</command> status r0</screen>

      </step>
     </substeps>
    </step>
    <step>
     <para>
      将 clvmd 资源作为克隆品包含在 Pacemaker 配置中，并让它依赖于 DLM 克隆资源。有关详细指示信息，请参见<xref linkend="pro.ha.clvm.dlmresource"/>。继续之前，请确认这些资源已在群集上成功启动。可以使用 <command>crm status</command> 或 Web 界面检查正在运行的服务。
     </para>
    </step>
    <step>
     <para>
      使用命令 <command>pvcreate</command> 准备 LVM 的物理卷。例如，在设备 <filename>/dev/drbd_r0</filename> 上，命令应类似于：
     </para>
<screen><prompt role="root">root # </prompt><command>pvcreate</command> /dev/drbd_r0</screen>
    </step>
    <step>
     <para>
      创建群集感知卷组：
     </para>
<screen><prompt role="root">root # </prompt><command>vgcreate</command> --clustered y myclusterfs /dev/drbd_r0</screen>
    </step>
    <step>
     <para>
      根据需要创建逻辑卷。您可能想要更改逻辑卷的大小。例如，使用以下命令创建 4 GB 的逻辑卷：
     </para>
<screen><prompt role="root">root # </prompt><command>lvcreate</command> --name testlv -L 4G myclusterfs</screen>
    </step>


    <step>
     <para>
      <remark role="grammar">taroth 2011-10-24: comment by bwiedemann: as file system
      mounts or raw usage - *as* raw usage passt nicht - for?</remark>现在 VG 内的逻辑卷可作为文件系统装入或原始用法提供。确保使用逻辑卷的服务具备适当的依赖性，以便在激活 VG 后对它们进行共置和排序。
     </para>
    </step>
   </procedure>
   <para>
    完成这些配置步骤后，即可像在任何独立工作站中一样进行 LVM2 配置。
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.ha.clvm.drbd">
  <title>显式配置合格的 LVM2 设备</title>

  <para>
   当若干设备看似共享同一物理卷签名（多路径设备或 DRBD 可能发生这种情况）时，建议显式配置 LVM2 扫描 PV 的设备。
  </para>

  <para>
   例如，如果命令 <command>vgcreate</command> 使用的是物理设备而不是镜像块设备，DRBD 将会感到困惑，并可能导致 DRBD 的裂脑情况。
  </para>

  <para>
   要停用 LVM2 的单个设备，请执行以下操作：
  </para>

  <procedure>
   <step>
    <para>
     编辑文件 <filename>/etc/lvm/lvm.conf</filename> 并搜索以 <literal>filter</literal> 开头的行。
    </para>
   </step>
   <step>
    <para>
     其中的模式作为正则表达式来处理。前面的<quote>a</quote>表示接受扫描的设备模式，前面的<quote>r</quote>表示拒绝遵守该设备模式的设备。
    </para>
   </step>
   <step>
    <para>
     要删除名为 <filename>/dev/sdb1</filename> 的设备，请向过滤规则添加以下表达式：
    </para>
<screen>"r|^/dev/sdb1$|"</screen>
    <para>
     完整的过滤行将显示如下：
    </para>
<screen>filter = [ "r|^/dev/sdb1$|", "r|/dev/.*/by-path/.*|", "r|/dev/.*/by-id/.*|", "a/.*/" ]</screen>
    <para>
     接受 DRBD 和 MPIO 设备但拒绝所有其他设备的过滤行将显示如下：
    </para>
<screen>filter = [ "a|/dev/drbd.*|", "a|/dev/.*/by-id/dm-uuid-mpath-.*|", "r/.*/" ]</screen>
   </step>

   <step>
    <para>
     编写配置文件并将它复制到所有群集节点。
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec.ha.clvm.more">
  <title>更多信息</title>

  <para>
   可从 <link xlink:href="http://www.clusterlabs.org/wiki/Help:Contents"/> 处的 pacemaker 邮件列表中获取完整信息。
  </para>

  <para>
   官方 cLVM 常见问题可在以下网址中找到：<link xlink:href="http://sources.redhat.com/cluster/wiki/FAQ/CLVM"/>。
  </para>
 </sect1>
</chapter>
