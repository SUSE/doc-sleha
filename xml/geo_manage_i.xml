<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-ha-geo-manage">
 <title>Managing &geo; clusters</title>

 <para>
  Before booth can manage a certain ticket within the &geo; cluster, you
  initially need to grant it to a site manually&mdash;either with the booth
  command line client or with &hawk2;.
 </para>
 <sect1 xml:id="sec-ha-geo-manage-cli">
  <title>Managing tickets from command line</title>
  <para> Use the <command>booth</command> command line tool to grant, list, or
   revoke tickets as described in <xref linkend="sec-ha-geo-manage-cli-booth"/>.
  </para>
  <warning>
   <title><command>crm_ticket</command> and
    <command>crm&nbsp;site&nbsp;ticket</command></title>
   <para> If the booth service is not running for any reasons, you can also
    manage tickets fully manually with <command>crm_ticket</command> or
    <command>crm&nbsp;site&nbsp;ticket</command>. Both commands are only
    available on cluster nodes. Use them with great care as they
     <emphasis>cannot</emphasis> verify if the same ticket is already granted
    elsewhere. For more information, read the man pages. </para>
   <para> As long as booth is up and running, only use the
    <command>booth</command> for manual intervention. </para>
  </warning>


<sect2 xml:id="sec-ha-geo-manage-cli-booth">
 <title>Overview of <command>booth</command> commands</title>
  <para>
   The <command>booth</command> commands can be run on any machine in the cluster,
   not only the ones having the &boothd; running. The
   <command>booth</command> commands try to find the <quote>local</quote>
   cluster by looking at the booth configuration file and the locally defined IP
   addresses. If you do not specify a site which <command>booth</command> should
   connect to (using the <option>-s</option> option), it will always connect to
   the local site.
  </para>

  <variablelist>
   <varlistentry>
    <term>Listing all tickets</term>
    <listitem>
     <screen>&prompt.root;<command>booth</command> list
ticket: &ticket1;, leader: none
ticket: &ticket2;, leader: 10.2.12.101, expires: 2014-08-13 10:28:57</screen>
     <para> If you do not specify a certain site with <option>-s</option>, the
      information about the tickets will be requested from the local booth
      instance. </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Granting a ticket to a site</term>
    <listitem>
     <screen>&prompt.root;<command>booth</command> grant -s 192.168.201.100 &ticket1;
booth[27891]: 2014/08/13_10:21:23 info: grant request sent, waiting for the result ...
booth[27891]: 2014/08/13_10:21:23 info: grant succeeded!</screen>
     <para> In this case, <literal>&ticket1;</literal> will be granted to
      the site <literal>192.168.201.100</literal>. Without the
       <option>-s</option> option, booth would automatically connect to the
      current site (the site you are running the booth client on) and would
      request the <command>grant</command> operation. </para>
     <para> Before granting a ticket, the command executes a sanity check. If
      the same ticket is already granted to another site, you are warned about
      that and are prompted to revoke the ticket from the current site first.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Revoking a ticket from a site</term>
    <listitem>
     <screen>&prompt.root;<command>booth</command> revoke &ticket1;
booth[27900]: 2014/08/13_10:21:23 info: revoke succeeded!</screen>
     <para> Booth checks to which site the ticket is currently granted and
      requests the <command>revoke</command> operation for
       <literal>&ticket1;</literal>. The revoke operation will be executed
      immediately. </para>
     <para>The <command>grant</command> and (under certain circumstances),
      <command>revoke</command> operations may take a while to return a definite
      operation's outcome. The client waits for the result up to the ticket's
       <varname>timeout</varname> value before it gives up waiting. If the
       <option>-w</option> option was used, the client will wait indefinitely
      instead. Find the exact status in the log files or with the
      <command>crm_ticket -L</command> command.</para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Forcing a grant operation</term>
    <listitem>
     <screen>&prompt.root;<command>booth</command> grant -F &ticket1;</screen>
     <para>The result of this command depends on whether you use automatic or
      manual tickets.</para>
      <itemizedlist>
       <listitem>
       <formalpara>
        <title>Automatic tickets</title>
        <para>As long as booth can make sure a ticket is granted to one site,
         you cannot grant the same ticket to another site, not even by using
         the <option>-F</option> option. However, in case of a split brain
         situation, booth might not be able to check if an automatic ticket is
         granted somewhere else. In that case, the &geo; cluster
         administrator can override the automatic process and manually grant
         the ticket to the site that is still up and running. In this
         situation, the <option>-F</option> options tells booth
          <emphasis>not</emphasis> to wait for a response from other,
         unreachable sites (so ignoring the parameters
         <parameter>expire</parameter> and <parameter>acquire-after</parameter>,
         if defined for this ticket). Instead, booth will immediately grant the
         ticket to the specified site.</para>
       </formalpara>
      </listitem>
      <listitem>
       <formalpara>
        <title>Manual tickets</title>
        <para>When using <emphasis>manual</emphasis> tickets, <command>booth
         grant -F</command> makes booth grant the ticket immediately to the
         specified site.</para>
       </formalpara>
      </listitem>
     </itemizedlist>
     <warning>
      <title>Potential loss of data</title>
      <para>Before using <command>booth grant -F</command>, make sure that no
       other site (which is online) owns the same ticket. If the same ticket is
       granted to multiple sites, resources depending on the ticket might start
       on several sites in parallel. This results in concurrency violation and
       potential data corruption.</para>
      <para>As &geo; cluster administrator, you need to resolve a conflict
       between tickets once the other site is reachable again.</para>
     </warning>
    </listitem>
   </varlistentry>
  </variablelist>
  <para>In the following sections, find some examples for managing tickets in different
   scenarios.</para>
 </sect2>
 <sect2 xml:id="sec-ha-geo-manage-cli-booth-auto-ticket-move">
  <title>Manually moving an automatic ticket</title>
   <para>
    Assuming that you want to manually move <literal>&ticket1;</literal> from
    site <literal>&cluster1;</literal> (with the virtual IP
    <literal>192.168.201.100</literal>) to site <literal>&cluster2;</literal>
    (with the virtual IP <literal>192.168.202.100</literal>), proceed as
    follows:
   </para>
  <procedure>
   <step>
    <para> Log in to <literal>&cluster1;</literal>.</para>
   </step>
   <step>
    <para>
     Set <literal>&ticket1;</literal> to standby:
    </para>
<screen>&prompt.root;<command>crm_ticket</command> -t &ticket1; -s</screen>
   </step>
   <step>
    <para>
     Wait for any resources that depend on <literal>&ticket1;</literal> to be
     stopped or demoted cleanly.
    </para>
   </step>
   <step>
    <para>
     Revoke <literal>&ticket1;</literal> from site
     <literal>&cluster1;</literal>:
    </para>
<screen>&prompt.root;<command>booth</command> revoke -s 192.168.201.100 &ticket1;</screen>
   </step>
   <step>
    <para>
     After the ticket has been revoked from its original site, grant
     <literal>&ticket1;</literal> to the site <literal>&cluster2;</literal>:
    </para>
<screen>&prompt.root;<command>booth</command> grant -s 192.168.202.100 &ticket1;</screen>
    <para>This enables the resources which depend on this ticket to start on site
    <literal>&cluster2;</literal>.</para>
   </step>
   <step>
    <para>
     Remove the standby mode for <literal>&ticket1;</literal> on site <literal>&cluster1;</literal>:
    </para>
<screen>&prompt.root;<command>crm_ticket</command> -t &ticket1; -a</screen>
     <para>In case <literal>&cluster2;</literal> fails, resources depending on
       <literal>&ticket1;</literal> will automatically fail over to site
       <literal>&cluster1;</literal>.
     </para>
   </step>
  </procedure>
 </sect2>
 <sect2 xml:id="sec-ha-geo-manage-cli-booth-man-ticket-move">
  <title>Moving a manual ticket</title>
   <para>
    Assuming that you want to move the manual ticket <literal>&ticket3;</literal> from
    site <literal>&cluster1;</literal> (with the virtual IP
    <literal>192.168.201.100</literal>) to site <literal>&cluster2;</literal>
    (with the virtual IP <literal>192.168.202.100</literal>), proceed as
    follows:
   </para>
  <procedure>
   <step>
    <para>Log in to <literal>&cluster1;</literal>.</para>
   </step>
   <step>
    <para>
     Set <literal>&ticket3;</literal> to standby:
    </para>
<screen>&prompt.root;<command>crm_ticket</command> -t &ticket3; -s</screen>
   </step>
   <step>
    <para>
     Wait for any resources that depend on <literal>&ticket3;</literal> to be
     stopped or demoted cleanly.
    </para>
   </step>
   <step>
    <para>
     Revoke <literal>&ticket3;</literal> from site <literal>&cluster1;</literal>:
    </para>
<screen>&prompt.root;<command>booth</command> revoke -s 192.168.201.100 &ticket3;</screen>
   </step>
   <step>
    <para>
     After the ticket has been revoked from its original site, grant
     <literal>&ticket3;</literal> to the site <literal>&cluster2;</literal>:
    </para>
<screen>&prompt.root;<command>booth</command> grant -s 192.168.202.100 &ticket3;</screen>
    <para>This enables the resources which depend on this ticket to start on site
     <literal>&cluster2;</literal>.</para>
   </step>
   <step>
    <para>
     If you want to move the resources back to site <literal>&cluster1;</literal> at any point in
     time, remove the standby mode for <literal>&ticket3;</literal> on site <literal>&cluster1;</literal>:
    </para>
<screen>&prompt.root;<command>crm_ticket</command> -t &ticket3; -a</screen>
   </step>
  </procedure>
 </sect2>

 <sect2 xml:id="sec-ha-geo-manage-cli-booth-man-ticket-failover">
  <title>Failing over a manual ticket</title>
   <para> Let us assume that the (manually managed) ticket
     <literal>&ticket3;</literal> had been granted to site
     <literal>&cluster1;</literal> (with the virtual IP
     <literal>192.168.201.100</literal>. This site cannot be reached at the
    moment. Site <literal>&cluster2;</literal> (with the virtual IP
     <literal>192.168.202.100</literal>) is still available. </para>
  <procedure>
   <step>
    <para>
      Try to contact a local administrator on site <literal>&cluster1;</literal> and
      check if the site is down.
    </para>
    <itemizedlist>
     <listitem>
       <para>If yes, proceed with <xref linkend="step-login" xrefstyle="select:label"/>.</para>
     </listitem>
     <listitem>
       <para>If <literal>&cluster1;</literal> cannot be reached because of a
        connectivity problem, but the nodes are still running, ask the local
        cluster administrator to put <literal>&ticket3;</literal> into standby
        mode on site <literal>&cluster1;</literal>:</para>
<screen>&prompt.root;<command>crm_ticket</command> -t &ticket3; -s</screen>
       <para>This will relinquish the resources which depend on <literal>&ticket3;</literal>.
        Now the ticket can safely be granted to the other site.
       </para>
     </listitem>
    </itemizedlist>
   </step>
   <step xml:id="step-login">
    <para> Log in to <literal>&cluster2;</literal>.</para>
   </step>
   <step>
    <para> Grant <literal>&ticket3;</literal>to site
      <literal>&cluster2;</literal> using the <option>-F</option> option: </para>
    <screen>&prompt.root;<command>booth</command> grant -F &ticket3;</screen>
    <para>You will see a warning that the same ticket might be granted to
     another site, but the command will be executed.</para>
   </step>
   <step>
    <para>Check the result with:</para>
    <screen>&prompt.root;<command>booth</command> list</screen>
    <para>It should show <literal>&cluster2;</literal> as ticket owner for
      <literal>&ticket3;</literal> now. All resources that depend on this
     ticket will be started on <literal>&cluster2;</literal>.</para>
   </step>
   <step>
    <para>Before trying to bring back <literal>&cluster1;</literal> into the
     &geo; cluster again, make sure to revoke <literal>&ticket3;</literal>
     on <literal>&cluster1;</literal>:</para>
    <screen>&prompt.root;<command>booth</command> revoke -s 192.168.201.100 &ticket3;</screen>
   </step>
  </procedure>
 </sect2>
</sect1>
 <xi:include href="geo_manage_hawk2_i.xml"/>
</chapter>
