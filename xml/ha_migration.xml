<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<appendix id="app.ha.migration">
 <title>Upgrading Your Cluster and Updating Software Packages</title>
 <abstract>
  <para>This chapter covers two different scenarios: upgrading a cluster to
   another version of &productname; (either a major release or a service
   pack) as opposed to updating individual packages on cluster nodes. </para>
 </abstract>
   
 <sect1 id="sec.ha.migration.terminology">
  <title>Terminology</title>
  <para>In the following, find definitions of the most important terms used in
  this chapter:</para>
  <!--taroth 2014-08-19: CAVE - the following is copied from SLE 12 SVN: sle_update.xml,
   sec.update.terminology-->
  <variablelist>
   <varlistentry>
    <term>Major Release</term>
    <term>General Availability (GA) Version</term>
    <listitem>
     <para> The Major Release of &sle; (or any software product) is a new
      version which brings new features and tools, decommissions previously
      deprecated components and comes with backwards incompatible changes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Service Pack (SP)</term>
    <listitem>
     <para> Combines several patches into a form which is easy to install or
      deploy. Service packs are numbered and usually contain security fixes,
      updates, upgrades, or enhancements of programs. </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Update</term>
    <listitem>
     <para> Installation of a newer <emphasis>minor</emphasis> version of a
      package. </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Upgrade</term>
    <listitem>
     <para> Installation of a newer <emphasis>major</emphasis> version of a
      package or distribution, which brings <emphasis>new features</emphasis>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 
 <sect1 id="sec.ha.migration.upgrade">
  <title>Upgrading your Cluster to the Latest Product Version</title>
  <para>Which upgrade path is supported and how to perform the upgrade depends
   on the current product version your cluster is running on and on the target
   version you want to migrate to. For general information on this, see the
    <citetitle>&sls;&nbsp;12 &deploy;</citetitle>, chapter
    <citetitle>Updating &sle;</citetitle>. It is available at
   &suse-onlinedoc;. </para>
 

  <sect2 id="sec.ha.migration.upgrade.sle12">
   <title>Upgrading from SLE&nbsp;HA&nbsp;11 SP3 to
    SLE&nbsp;HA&nbsp;12</title>

   <para>To successfully upgrade to &productname; 12, your cluster
    needs to run the latest versions of &sls; and &productname;
    (11&nbsp;SP3). If your cluster is still based on an older product
    version, upgrade it to &sls; and &productname; 11&nbsp;SP3
    first. Find information on this in the <citetitle>High Availability
     Guide</citetitle> for &productname; <emphasis>11</emphasis>, chapter
     <citetitle>Upgrading Your Cluster to the Latest Product
    Version</citetitle>. It is available at &suse-onlinedoc;. </para>

   <para>Because of major changes in various components of the &hasi; 12 (for
    example, &corosync.conf;, disk formats of OCFS2), performing a
     <literal>rolling upgrade</literal> is not supported for this scenario. All
    cluster nodes must be offline and the cluster needs to be migrated as a
    whole as described in <xref linkend="pro.ha.migration.sle12"/>. Mixed
    clusters running on &productname; 11/&productname; 12 are not
    supported.</para>


   <procedure id="pro.ha.migration.sle12">
    <title>Upgrading the Cluster to SLE&nbsp;HA&nbsp;12</title>
    <important>
     <title>Required Preparations Before Upgrading</title>
     <itemizedlist>
      <listitem>
       <para>Ensure that your system back-up is up to date and
        restorable.</para>
      </listitem>
      <listitem>
       <para>Test the upgrade procedure on a staging instance of your cluster
        setup first, before performing it in a production environment.</para>
       <para>This gives you an estimation of the time frame required for the
        maintenance window. It also helps to detect and solve any unexpected
        problems that might arise.</para>
      </listitem>
     </itemizedlist>
    </important>
    <para>Execute the following steps for each cluster node:</para>
    <step>
     <para>Log in to each cluster node and stop the cluster stack with:</para>
     <screen>&prompt.root; rcopenais stop</screen>
    </step>
    <step>
     <para>For each cluster node, perform an upgrade from &sls;
      11&nbsp;SP3 to &sls; 12 and from &productname; 11&nbsp;SP3
      to &productname; 12. If you want to make use of &geo; clustering,
      install the respective add-on as described in the <citetitle>&hageo;
       &geoquick;</citetitle>.
      <!--  <remark>taroth 090512:
     need to use hard-coded link here as the target is not included in the same
     set</remark>-->
      For information on how to upgrade your product, see the
       <citetitle>&sls;&nbsp;12 &deploy;</citetitle>, chapter
       <citetitle>Updating &sle;</citetitle>. It is available at
      &suse-onlinedoc;.</para>
    </step>
    <step>
     <para>After the upgrade process has finished, reboot each node with version
      12 of &sls; and &productname;.</para>
    </step>
    <step>
     <para>If you use OCFS2 in your cluster setup, update the on-device
      structure by executing the following command:</para>
     <screen>&prompt.root; tunefs.ocfs2 --update-cluster-stack <replaceable>PATH_TO_DEVICE</replaceable></screen>
     <para>It adds additional parameters to the disk which are needed for the
      updated OCFS2 version that is shipped with &productname; 12.</para>
    </step>
    <step>
     <para>To update &corosync.conf; for &corosync; version 2:</para>
     <substeps>
      <step>
       <para>Log in to one node and start the &yast; cluster module.</para>
      </step>
      <step>
       <para>Switch to the <guimenu>Communication Channels</guimenu> category
        and enter values for the following new parameters: <guimenu>Cluster
         Name</guimenu> and <guimenu>Expected Votes</guimenu>. For details, see
         <xref linkend="pro.ha.installation.setup.channel1"/>.</para>
       <para>If &yast; should detect any other options that are invalid or
        missing according to &corosync; version 2, it will prompt you to change
        them. </para>
       <!--taroth 2014-08-28: feedback by nwang
        (https://mailman.suse.de/mailman/private/ha-devel/2014-August/004170.html): 
        Just follow the suggestion is enough. If some options is missing or invalid, message 
        should pop up and prevent finishing the settings -->
      </step>
      <step>
       <para>Confirm your changes in &yast; to update
        &corosync.conf;.</para>
      </step>
      <step>
       <para>If &csync; is configured for your cluster, use the following
        command to push the updated &corosync; configuration to the other
        cluster nodes:</para>
       <screen>&prompt.root;<command>csync2</command> <option>-xv</option></screen>
       <para>For details on &csync;, see <xref
         linkend="sec.ha.installation.setup.csync2"/>. </para>
       <para>Alternatively, synchronize the updated &corosync; configuration
        by manually copying &corosync.conf; to all cluster nodes.</para>
      </step>
     </substeps>
    </step>
    <step>
     <para>Log in to each node and start the cluster stack with:</para>
     <screen>&prompt.root; systemctl start pacemaker.service</screen>
    </step>
    <step>
     <para> Check the cluster status with <command>crm status</command> or with
      &hawk;.</para>
    </step>
   </procedure>
   
   <para>If you have an existing &geo; cluster setup and want to upgrade it
    to run with &hasi; 12 and &hageo; 12, see the additional
    instructions in the <citetitle>&geoquick;</citetitle> for &hageo;.
    It is available at &suse-onlinedoc;. Refer to the section
     <citetitle>Upgrading from SLE&nbsp;HA&nbsp;11 SP3 to
     SLE&nbsp;HA&nbsp;12</citetitle>. </para>

   <note>
    <title>Reverting after Upgrade</title>
    <para>
     <remark>taroth 2014-08-19: DEVs, do we need this note?</remark> After the
     upgrade process to product version 12, reverting back to product version 11
     is <emphasis>not</emphasis> supported. </para>
   </note>
  </sect2>
 </sect1>


 <sect1 id="sec.ha.update">
  <title>Updating Software Packages on Cluster Nodes</title>

  <para>Before installing any package updates on a node, check the following: </para>
  <itemizedlist>
   <listitem>
    <para>Does the update affect any packages belonging to &productname; or
     he &hageo; add-on? If yes: Stop the cluster stack on the node before
     starting the software update.</para>
    <screen>&prompt.root; systemctl stop pacemaker.service</screen>
   </listitem>
   <listitem>
    <para>Does the package update require a reboot? If yes: Stop the cluster
     stack on the node before starting the software update:</para>
    <screen>&prompt.root; systemctl stop pacemaker.service</screen>
   </listitem>
  </itemizedlist>
  <para>If none of the situations above do apply, you do not need to stop the
   cluster stack. In that case, put the cluster into maintenance mode before
   starting the software update:</para>
  <screen>&prompt.root;<command>crm</command> configure property maintenance-mode=true</screen>
  <para>For more details on maintenance mode, see <xref
    linkend="sec.ha.config.basics.maint.mode"/>.</para>

  <warning>
   <title>Active Cluster Stack During Update</title>
   <para> If the cluster resource manager on a node is active during the
    software update, this can lead to unpredictable results like fencing of
    active nodes. </para>
  </warning>

  <para>After the update has been successfully installed, remove the cluster
   maintenance mode:</para>
  <screen>&prompt.root;<command>crm</command> configure property maintenance-mode=true</screen>
  <para>or restart the cluster stack on the respective node with:</para>
  <screen>&prompt.root; systemctl start pacemaker.service</screen>
</sect1>
 
  <!--<important>
   <title>Time Limit for Rolling Upgrade</title>
   <para>
    The new features shipped with &productname; ??? will only be
    available after <emphasis>all</emphasis> cluster nodes have been
    upgraded to the latest product version. Mixed SP1/SP2 clusters are only
    supported for a short time frame during the rolling upgrade. Complete
    the rolling upgrade within one week.
   </para>
  </important>-->
 <sect1 id="sec.ha.migration.more">
  <title>For More Information</title>

  <para>
   For detailed information about any changes and new features of the
   product you are upgrading to, refer to its release notes. They are
   available from <ulink url="https://www.suse.com/releasenotes/"/>.
  </para>
 </sect1>
</appendix>
