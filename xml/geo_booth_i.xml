<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-ha-geo-booth">
 <title>Setting up the booth services</title>
 <info>
  <abstract>
   <para>
    This chapter describes the setup and configuration options for booth, how
    to synchronize the booth configuration to all sites and arbitrators, how to
    enable and start the booth services, and how to reconfigure booth while its
    services are running.
   </para>
  </abstract>
 </info>
 <sect1 xml:id="sec-ha-geo-booth-basic">
  <title>Booth configuration and setup options</title>

  <para>
   The default booth configuration is &booth.conf;. This file must be the same
   on all sites of your &geo; cluster, including the arbitrator or arbitrators.
   To keep the booth configuration synchronous across all sites and
   arbitrators, use &csync;, as described in
   <xref linkend="sec-ha-geo-booth-sync"/>.
  </para>

  <note xml:id="note-ha-geo-booth-ownership">
   <title>Ownership of <filename class="directory">/etc/booth</filename> and files</title>
   <para>
    The directory <filename class="directory">/etc/booth</filename> and all
    files therein need to belong to the user
    <systemitem
    class="username">hacluster</systemitem> and the group
    <systemitem
     class="groupname">haclient</systemitem>. Whenever you copy
    a new file from this directory, use the option <option>-p</option> for the
    <command>cp</command> command to preserve the ownership. Alternatively,
    when you create a new file, set the user and group afterward with
    <command>chown</command> <option>hacluster:haclient
    <replaceable
    >FILE</replaceable></option>.
   </para>
  </note>

  <para>
   &booth-multi-tenancy; For details on how to configure booth for multiple
   &geo; clusters, refer to <xref linkend="sec-ha-geo-booth-multi"/>.
  </para>

<!--taroth 2015-10-26: fate#318466: Booth should authenticate clients and peers -->

  <para>
   To prevent malicious parties from disrupting the booth service, you can
   configure authentication for talking to booth, based on a shared key. For
   details, see <xref linkend="co-ha-geo-booth-config-auth"/> in
   <xref linkend="ex-ha-booth-conf-default"/>. All hosts that communicate with
   various booth servers need this key. Therefore make sure to include the key
   file in the &csync; configuration or to synchronize it manually across all
   parties.
  </para>
 </sect1>

 <sect1 xml:id="sec-ha-geo-booth-ticket-types">
  <title>Automatic versus manual tickets</title>
  <para>
   A ticket grants the right to run certain resources on a specific
   cluster site. Two types of tickets are supported:</para>
  <itemizedlist>
   <listitem>
    <para>Automatic tickets are controlled by the &boothd; daemon.</para>
   </listitem>
   <listitem>
    <para>Manual tickets are managed by the cluster administrator only.</para>
   </listitem>
  </itemizedlist>

  <para>Automatic and manual tickets have the following properties:</para>
  <itemizedlist>
   <listitem>
    <formalpara>
     <title>Automatic and manual tickets can be defined together</title>
     <para>You can define and use both automatic and manual tickets within the
      same &geo; cluster.</para>
    </formalpara>
   </listitem>
   <listitem>
    <formalpara>
     <title>Manual ticket management remains manual</title>
     <para>The automatic ticket management is not applied to manually controlled
      tickets.
      Manual tickets do not require any quorum elections, cannot fail over
      automatically, and do not have an expiry time.</para>
    </formalpara>
   </listitem>
   <listitem>
    <formalpara>
     <title>Manual tickets will not be moved automatically</title>
     <para>Tickets which were manually granted to a site will remain there
      until they are manually revoked. Even if a site goes offline, the
      ticket will not be moved to another site. This behavior ensures that
      the services that depend on a ticket remain on a particular site and
      are not moved to another site.
     </para>
    </formalpara>
   </listitem>
   <listitem>
    <formalpara>
     <title>Same commands for managing both types of tickets</title>
     <para>The manual tickets are managed by the same commands as automatic
     tickets (<command>grant</command> or <command>revoke</command>, for example).</para>
    </formalpara>
   </listitem>
   <listitem>
    <formalpara>
     <title>Arbitrators are not needed if only manual tickets are used</title>
     <para>
      If you configure only manual tickets in a &geo; cluster, arbitrators are
      not necessary, because manual ticket management does not require quorum
      decisions.</para>
    </formalpara>
   </listitem>
  </itemizedlist>

  <para>
   To configure tickets, use the <filename>/etc/booth/booth.conf</filename>
   configuration file (see <xref linkend="sec-ha-geo-booth-default"/> for
   further information).</para>
 </sect1>

 <sect1 xml:id="sec-ha-geo-booth-default">
  <title>Using the default booth setup</title>

  <para>
   If you have set up your basic &geo; cluster with the
   <systemitem
    xmlns='http://docbook.org/ns/docbook'
    class='resource'>ha-cluster-bootstrap</systemitem>
   scripts as described in the &geoquick;, the scripts have created a default
   booth configuration on all sites with a minimal set of parameters. To extend
   or fine-tune the minimal booth configuration, have a look at
   <xref linkend="ex-ha-booth-conf-default"
   xrefstyle="select:label"/> or at
   the examples in <xref linkend="sec-ha-geo-booth-multi"/>.
  </para>

  <para>
   To add or change parameters needed for booth, either edit the booth
   configuration files manually or use the &yast; <guimenu>Geo
   Cluster</guimenu> module. To access the &yast; module, start it from command
   line with <command>yast2 geo-cluster</command> (or start &yast; and select
   <menuchoice> <guimenu>High Availability</guimenu> <guimenu>Geo
   Cluster</guimenu> </menuchoice>).
  </para>

  <example xml:id="ex-ha-booth-conf-default">
   <title>A booth configuration file</title>
<!--taroth 2014-08-21: not sure if it makes sense that all tickets
      configured here should have similar options and values or if we should
      rather show different options and values for individual tickets - dejan,
      please check! - dejan (bnc#896673): It makes sense for the network parameters 
      to be shared between tickets as the parties communicating are the same 
      (parameters 6-9)-->
<screen><?dbsuse-fo font-size="0.75em"?>transport = UDP <co xml:id="co-ha-geo-booth-config-transport"/>
port = 9929 <co xml:id="co-ha-geo-booth-config-port"/>
arbitrator = 192.168.203.100 <co xml:id="co-ha-geo-booth-config-arbitrator"/>
site =  192.168.201.100 <co xml:id="co-ha-geo-booth-config-site"/>
site =  192.168.202.100 <xref linkend="co-ha-geo-booth-config-site" xrefstyle="select:label nopage"/>
authfile = /etc/booth/authkey <co xml:id="co-ha-geo-booth-config-auth"/>
ticket = "&ticket3;" <co xml:id="co-ha-geo-booth-config-ticket"/>
     mode = MANUAL <co xml:id="co-ha-geo-booth-mode"/>
ticket = "&ticket1;" <xref linkend="co-ha-geo-booth-config-ticket"  xrefstyle="select:label nopage"/>
     expire = 600 <co xml:id="co-ha-geo-booth-config-expiry"/>
     timeout = 10 <co xml:id="co-ha-geo-booth-config-timeout"/>
     retries = 5 <co xml:id="co-ha-geo-booth-config-retries"/>
     renewal-freq = 30 <co xml:id="co-ha-geo-booth-config-renewal"/>
     before-acquire-handler<co xml:id="co-ha-geo-booth-config-handler"/>&nbsp;=&nbsp;/etc/booth/ticket-A<co xml:id="co-ha-geo-booth-config-script"/>&nbsp;db-1 <co xml:id="co-ha-geo-booth-config-rsc" />
     acquire-after = 60 <co xml:id="co-ha-geo-booth-config-acquire-after"/>
ticket = "&ticket2;" <xref linkend="co-ha-geo-booth-config-ticket" xrefstyle="select:label nopage"/>
     expire = 600 <xref linkend="co-ha-geo-booth-config-expiry" xrefstyle="select:label nopage"/>
     timeout = 10 <xref linkend="co-ha-geo-booth-config-timeout" xrefstyle="select:label nopage"/>
     retries = 5 <xref linkend="co-ha-geo-booth-config-retries" xrefstyle="select:label nopage"/>
     renewal-freq = 30 <xref linkend="co-ha-geo-booth-config-renewal" xrefstyle="select:label nopage"/>
     before-acquire-handler<xref linkend="co-ha-geo-booth-config-handler" xrefstyle="select:label nopage"/>&nbsp;=&nbsp;/etc/booth/ticket-B<xref linkend="co-ha-geo-booth-config-script" xrefstyle="select:label nopage"/>&nbsp;db-8 <xref linkend="co-ha-geo-booth-config-rsc" xrefstyle="select:label nopage"/>
     acquire-after = 60 <xref linkend="co-ha-geo-booth-config-acquire-after" xrefstyle="select:label nopage"/>
    </screen>
   <calloutlist>
    <callout arearefs="co-ha-geo-booth-config-transport">
     <para>
      &booth-transport; Currently, this parameter can therefore be omitted.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-port">
     <para>
      &booth-port; When not using the default port (<literal>9929</literal>),
      choose a port that is not already used for different services. Make sure
      to open the port in the nodes&apos; and arbitrators&apos; firewalls. The
      booth clients use TCP to communicate with the &boothd;. Booth will always
      bind and listen to both UDP and TCP ports.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-arbitrator">
     <para>
      &booth-arbitrator; Add an entry for each arbitrator you use in your &geo;
      cluster setup.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-site">
     <para>
      &booth-site; Add an entry for each site you use in your &geo; cluster
      setup. Make sure to insert the correct virtual IP addresses
      (<systemitem>IPaddr2</systemitem>) for each site, otherwise the booth
      mechanism will not work correctly. Booth works with both IPv4 and IPv6
      addresses.
     </para>
     <para>
      If you have set up booth with the
      <systemitem xmlns='http://docbook.org/ns/docbook'
       class='resource'>ha-cluster-bootstrap</systemitem>
      scripts, the virtual IPs you have specified during setup have been
      written to the booth configuration already (and have been added to the
      cluster configuration, too). To set up the cluster resources manually,
      see <xref linkend="sec-ha-geo-rsc-boothd"/>.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-auth">
     <para>
      Optional parameter. &booth-auth;
     </para>
     &booth-key-req;
    </callout>
    <callout arearefs="co-ha-geo-booth-config-ticket">
     <para>
      &booth-ticket; For each ticket, add a <literal>ticket</literal> entry.
      For example, the ticket <literal>&ticket3;</literal> specified here can
      be used for failover of NFS and DRBD as explained in
      <link
       xlink:href="https://documentation.suse.com/sbp/all/html/SBP-DRBD/index.html"/>.
     </para>
    </callout>
   <callout arearefs="co-ha-geo-booth-mode">
     <para>Optional parameter. Defines the ticket mode. By default, all
      tickets are managed by booth. To define tickets which are managed by
      the administrator (<emphasis>manual tickets</emphasis>), set the
      <parameter>mode</parameter> parameter to
      <literal>MANUAL</literal> or <literal>manual</literal>.
     </para>
     <para>Manual tickets do not have <parameter>expire</parameter>,
      <parameter>renewal-freq</parameter>, and <parameter>retries</parameter>
      parameters.</para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-expiry">
     <para>
      Optional parameter. Defines the ticket&apos;s expiry time in seconds. A
      site that has been granted a ticket will renew the ticket regularly. If
      booth does not receive any information about renewal of the ticket within
      the defined expiry time, the ticket will be revoked and granted to
      another site. If no expiry time is specified, the ticket will expire
      after <literal>600</literal> seconds by default. The parameter should not
      be set to a value less than 120 seconds. The default value set by the
      <systemitem>crm cluster init</systemitem> scripts is
      <literal>600</literal>.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-timeout">
     <para>
      Optional parameter. Defines a timeout period in seconds. After that time,
      booth will resend packets if it did not receive a reply within this
      period. The timeout defined should be long enough to allow packets to
      reach other booth members (all arbitrators and sites).
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-retries">
     <para>
      Optional parameter. Defines how many times booth retries sending packets
      before giving up waiting for confirmation by other sites. Values smaller
      than <literal>3</literal> are invalid and will prevent booth from
      starting.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-renewal">
     <para>
      Optional parameter. Sets the ticket renewal frequency period. Ticket
      renewal occurs every half expiry time by default. If the network
      reliability is often reduced over prolonged periods, it is advisable to
      renew more often. Before every renewal the
      <literal>before-acquire-handler</literal> is run.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-handler">
     <para>
      Optional parameter. It supports one or more scripts. To use more than one
      script, each script can be responsible for different checks, like cluster
      state, data center connectivity, environment health sensors, and more.
      Store all scripts in the directory
      <filename>/etc/booth.d/<replaceable>TICKET_NAME</replaceable></filename>
      and make sure they have the correct ownership (user
      <systemitem
       class="username">hacluster</systemitem> and group
      <systemitem
        class="groupname">haclient</systemitem>). Assign the
      directory name as a value to the parameter
      <parameter>before-acquire-handler</parameter>.
     </para>
     <para>
      The scripts in this directory are executed in alphabetical order. All
      scripts will be called before &boothd; tries to acquire or renew a
      ticket. For the ticket to be granted or renewed, <emphasis>all</emphasis>
      scripts must succeed. The semantics are the same as for a single script:
      On exit code other than <literal>0</literal>, &boothd; relinquishes the
      ticket.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-script">
     <para>
      The <filename>/usr/share/booth/service-runnable</filename> script is
      included in the product as an example. To use it, link it into the
      respective <quote>ticket</quote> directory:
     </para>
<screen>&prompt.root;<command
>ln</command> -s /usr/share/booth/service-runnable /etc/booth.d/<replaceable
 >TICKET_NAME</replaceable></screen>
     <para>
      Assume that the
      <filename>/etc/booth.d<replaceable
       >TICKET_NAME</replaceable></filename>
      directory contains the <command>service-runnable</command> script. This
      simple script is based on <command>crm_simulate</command>. It can be used
      to test whether a particular cluster resource <emphasis>can</emphasis> be
      run on the current cluster site. That means, it checks if the cluster is
      healthy enough to run the resource (all resource dependencies are
      fulfilled, the cluster partition has quorum, no dirty nodes, etc.). For
      example, if a service in the dependency-chain has a failcount of
      <literal>INFINITY</literal> on all available nodes, the service cannot be
      run on that site. In that case, it is of no use to claim the ticket.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-rsc">
     <para>
      The resource to be tested by the
      <literal>before-acquire-handler</literal> (in this case, by the
      <filename>service-runnable</filename> script). You need to reference the
      resource that is protected by the respective ticket. In this example,
      resource <literal>db-1</literal> is protected by
      <literal>&ticket1;</literal> whereas <literal>db-8</literal> is protected
      by <literal>&ticket2;</literal>. The resource for DRBD
      (<literal>ms_drbd_nfs</literal>) is protected by the ticket
      <literal>&ticket3;</literal>.
     </para>
    </callout>
    <callout arearefs="co-ha-geo-booth-config-acquire-after">
     <para>
      Optional parameter. After a ticket is lost, booth will wait this time in
      addition before acquiring the ticket. This is to allow for the site that
      lost the ticket to relinquish the resources, by either stopping them or
      fencing a node. A typical delay might be <literal>60</literal> seconds,
      but ultimately it depends on the protected resources and the fencing
      configuration. The default value is <literal>0</literal>.
     </para>
     <para>
      If you are unsure how long stopping or demoting the resources or fencing
      a node may take (depending on the <literal>loss-policy</literal>), use
      this parameter to prevent resources from running on two sites at the same
      time.
     </para>
    </callout>
   </calloutlist>
  </example>

  <sect2 xml:id="pro-ha-geo-setup-booth-config-edit">
   <title>Manually editing the booth configuration file</title>
   <procedure>
    <step>
     <para>
      Log in to a cluster node as &rootuser; or equivalent.
     </para>
    </step>
    <step>
     <para>
      If &booth.conf; does not exist yet, copy the example booth configuration
      file <filename>/etc/booth/booth.conf.example</filename> to &booth.conf;:
     </para>
<!--toms 2016-08-09: "cp -p" is needed, see
    https://bugzilla.suse.com/show_bug.cgi?id=968865#c14-->
<screen>&prompt.root;<command>cp</command> -p /etc/booth/booth.conf.example /etc/booth/booth.conf</screen>
    </step>
    <step>
     <para>
      Edit &booth.conf; according to
      <xref linkend="ex-ha-booth-conf-default"/>.
     </para>
    </step>
    <step>
     <para>
      Verify your changes and save the file.
     </para>
    </step>
    <step>
     <para>
      On all cluster nodes and arbitrators, open the port in the firewall that
      you have configured for booth. See
      <xref linkend="ex-ha-booth-conf-default"/>, position
      <xref linkend="co-ha-geo-booth-config-port"/>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="pro-ha-geo-setup-booth-yast">
   <title>Setting up booth with &yast;</title>
   <procedure>
    <step>
     <para>
      Log in to a cluster node as &rootuser; or equivalent.
     </para>
    </step>
    <step>
     <para>
      Start the &yast; <guimenu>Geo Cluster</guimenu> module.
     </para>
    </step>
    <step>
     <para>
      Choose to <guimenu>Edit</guimenu> an existing booth configuration file or
      click <guimenu>Add</guimenu> to create a new booth configuration file:
     </para>
     <substeps performance="required">
      <step xml:id="step-ha-booth-conf-params">
       <para>
        In the screen that appears configure the following parameters:
       </para>
       <itemizedlist>
        <listitem>
         <formalpara>
          <title>Configuration file</title>
          <para>
           A name for the booth configuration file. &yast; suggests
           <literal>booth</literal> by default. This results in the booth
           configuration being written to &booth.conf;. Only change this value
           if you need to set up multiple booth instances for different &geo;
           clusters as described in <xref linkend="sec-ha-geo-booth-multi"/>.
          </para>
         </formalpara>
        </listitem>
        <listitem>
         <formalpara>
          <title>Transport</title>
          <para>
           &booth-transport; See also
           <xref linkend="ex-ha-booth-conf-default"/>, position
           <xref linkend="co-ha-geo-booth-config-transport"/>.
          </para>
         </formalpara>
        </listitem>
        <listitem>
         <formalpara>
          <title>Port</title>
          <para>
           &booth-port; See also <xref linkend="ex-ha-booth-conf-default"/>,
           position <xref linkend="co-ha-geo-booth-config-port"/>.
          </para>
         </formalpara>
        </listitem>
        <listitem>
         <formalpara>
          <title>Arbitrator</title>
          <para>
           &booth-arbitrator; See also
           <xref linkend="ex-ha-booth-conf-default"/>, position
           <xref linkend="co-ha-geo-booth-config-arbitrator"/>.
          </para>
         </formalpara>
         <para>
          To specify an <guimenu>Arbitrator</guimenu>, click
          <guimenu>Add</guimenu>. In the dialog that opens, enter the IP
          address of your arbitrator and click <guimenu>OK</guimenu>.
         </para>
        </listitem>
        <listitem>
         <formalpara>
          <title>Site</title>
          <para>
           &booth-site; See also <xref linkend="ex-ha-booth-conf-default"/>,
           position <xref linkend="co-ha-geo-booth-config-site"/>.
          </para>
         </formalpara>
         <para>
          To specify a <guimenu>Site</guimenu> of your &geo; cluster, click
          <guimenu>Add</guimenu>. In the dialog that opens, enter the IP
          address of one site and click <guimenu>OK</guimenu>.
         </para>
        </listitem>
        <listitem>
         <formalpara>
          <title>Ticket</title>
          <para>
           &booth-ticket; See also <xref linkend="ex-ha-booth-conf-default"/>,
           position <xref linkend="co-ha-geo-booth-config-ticket"/>.
          </para>
         </formalpara>
         <para>
          To specify a <guimenu>Ticket</guimenu>, click <guimenu>Add</guimenu>.
          In the dialog that opens, enter a unique <guimenu>Ticket</guimenu>
          name. If you need to define multiple tickets with the same parameters
          and values, save configuration effort by creating a <quote>ticket
          template</quote> that specifies the default parameters and values for
          all tickets. To do so, use <literal>__default__</literal> as
          <guimenu>Ticket</guimenu> name.
         </para>
        </listitem>
        <listitem>
<!--taroth 2015-10-26:fate#319318: yast2 geo: configure booth authentification-->
         <formalpara>
          <title>Authentication</title>
          <para>
           To enable authentication for booth, click
           <guimenu>Authentication</guimenu> and in the dialog that opens,
           activate <guimenu>Enable Security Auth</guimenu>. If you already
           have an existing key, specify the path and file name in
           <guimenu>Authentication file</guimenu>. To generate a key file for a
           new &geo; cluster, click <guimenu>Generate Authentication Key
           File</guimenu>. The key will be created and written to the location
           specified in <guimenu>Authentication file</guimenu>.
          </para>
         </formalpara>
         <para>
          Additionally, you can specify optional parameters for your ticket.
          For an overview, see <xref linkend="ex-ha-booth-conf-default"/>,
          positions <xref linkend="co-ha-geo-booth-mode"/> to
          <xref linkend="co-ha-geo-booth-config-acquire-after"/>.
         </para>
         <para>
          Click <guimenu>OK</guimenu> to confirm your changes.
         </para>
        </listitem>
       </itemizedlist>
       <figure xml:id="fig-yast-ha-geo-booth">
        <title>Example ticket dependency</title>
        <mediaobject>
         <imageobject role="fo">
          <imagedata fileref="yast_geo_cluster_booth.png" width="80%" format="PNG"/>
         </imageobject>
         <imageobject role="html">
          <imagedata fileref="yast_geo_cluster_booth.png" width="50%" format="PNG"/>
         </imageobject>
        </mediaobject>
       </figure>
      </step>
      <step>
       <para>
        Click <guimenu>OK</guimenu> to close the current booth configuration
        screen. &yast; shows the name of the booth configuration file that you
        have defined.
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Before closing the &yast; module, switch to the <guimenu>Firewall
      Configuration</guimenu> category.
     </para>
    </step>
    <step>
     <para>
      To open the port you have configured for booth, enable <guimenu>Open Port
      in Firewall</guimenu>.
     </para>
     <important>
      <title>Firewall setting for local machine only</title>
      <para>
       The firewall setting is only applied to the current machine. It will
       open the UDP/TCP ports for all ports that have been specified in
       &booth.conf; or any other booth configuration files (see
       <xref linkend="sec-ha-geo-booth-multi"/>).
      </para>
      <para>
       Make sure to open the respective ports on all other cluster nodes and
       arbitrators of your &geo; cluster setup, too. Do so either manually or
       by synchronizing the following files with &csync;:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <filename>/usr/lib/firewalld</filename>
        </para>
       </listitem>
       <listitem>
        <para>
         <filename>/usr/lib/firewalld/services/booth.xml</filename>
        </para>
       </listitem>
      </itemizedlist>
     </important>
    </step>
    <step>
     <para>
      Click <guimenu>Finish</guimenu> to confirm all settings and close the
      &yast; module. Depending on the <replaceable>NAME</replaceable> of the
      <guimenu>Configuration File </guimenu> specified in
      <xref linkend="step-ha-booth-conf-params"/>, the configuration is written
      to <filename>/etc/booth/<replaceable>NAME</replaceable>.conf</filename>.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-ha-geo-booth-multi">
  <title>Using a multi-tenant booth setup</title>

<!--taroth 2014-08-07:  https://fate.suse.com/316123:
    Multi-tenancy for booth (prio: important)-->

  <para>
   &booth-multi-tenancy;
  </para>

  <para>
   Let us assume you have two &geo; clusters, one in EMEA (Europe, the Middle
   East and Africa), and one in the Asia-Pacific region (APAC).
  </para>

  <para>
   To use the same arbitrator for both &geo; clusters, create two configuration
   files in the <filename>/etc/booth</filename> directory:
   <filename>/etc/booth/emea.conf</filename> and
   <filename>/etc/booth/apac.conf</filename>. Both must minimally differ in the
   following parameters:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     The port used for the communication of the booth instances.
    </para>
   </listitem>
   <listitem>
    <para>
     The sites belonging to the different &geo; clusters that the arbitrator is
     used for.
    </para>
   </listitem>
  </itemizedlist>

  <example xml:id="ex-ha-conf-booth-multi-1">
   <title><filename>/etc/booth/apac.conf</filename></title>
<screen><?dbsuse-fo font-size="0.75em"?>transport = UDP <xref linkend="co-ha-geo-booth-config-transport" xrefstyle="select:label nopage"/>
port = 9133 <xref linkend="co-ha-geo-booth-config-port" xrefstyle="select:label nopage"/>
arbitrator = 192.168.203.100 <xref linkend="co-ha-geo-booth-config-arbitrator" xrefstyle="select:label nopage"/>
site = &slpip; <xref linkend="co-ha-geo-booth-config-site" xrefstyle="select:label nopage"/>
site = &proxyip; <xref linkend="co-ha-geo-booth-config-site" xrefstyle="select:label nopage"/>
authfile = /etc/booth/authkey-apac <xref linkend="co-ha-geo-booth-config-auth" xrefstyle="select:label nopage"/>
ticket ="tkt-db-apac-intern" <xref linkend="co-ha-geo-booth-config-ticket"/>
     timeout = 10 
     retries = 5 
     renewal-freq = 60 
     before-acquire-handler<xref linkend="co-ha-geo-booth-config-handler" xrefstyle="select:label nopage"/>&nbsp;=&nbsp;/usr/share/booth/service-runnable<xref linkend="co-ha-geo-booth-config-script" xrefstyle="select:label nopage"/>&nbsp;db-apac-intern <xref linkend="co-ha-geo-booth-config-rsc" xrefstyle="select:label nopage"/> 
ticket = "tkt-db-apac-cust" <xref linkend="co-ha-geo-booth-config-ticket" xrefstyle="select:label nopage"/>
     timeout = 10 
     retries = 5 
     renewal-freq = 60 
     before-acquire-handler&nbsp;=&nbsp;/usr/share/booth/service-runnable&nbsp;db-apac-cust</screen>
  </example>

  <example xml:id="ex-ha-conf-booth-multi-2">
   <title><filename>/etc/booth/emea.conf</filename></title>
<screen><?dbsuse-fo font-size="0.75em"?>transport = UDP <xref linkend="co-ha-geo-booth-config-transport" xrefstyle="select:label nopage"/>
port = 9150 <xref linkend="co-ha-geo-booth-config-port" xrefstyle="select:label nopage"/>
arbitrator = 192.168.203.100 <xref linkend="co-ha-geo-booth-config-arbitrator" xrefstyle="select:label nopage"/>
site = 192.168.201.100 <xref linkend="co-ha-geo-booth-config-site" xrefstyle="select:label nopage"/>
site = 192.168.202.100 <xref linkend="co-ha-geo-booth-config-site" xrefstyle="select:label nopage"/>
authfile = /etc/booth/authkey-emea <xref linkend="co-ha-geo-booth-config-auth" xrefstyle="select:label nopage"/>
ticket = "tkt-sap-crm" <xref linkend="co-ha-geo-booth-config-ticket"/>
     expire = 900 
     renewal-freq = 60 
     before-acquire-handler<xref linkend="co-ha-geo-booth-config-handler" xrefstyle="select:label nopage"/>&nbsp;=&nbsp;/usr/share/booth/service-runnable<xref linkend="co-ha-geo-booth-config-script" xrefstyle="select:label nopage"/>&nbsp;sap-crm <xref linkend="co-ha-geo-booth-config-rsc" xrefstyle="select:label nopage"/>
ticket = "tkt-sap-prod" <xref linkend="co-ha-geo-booth-config-ticket" xrefstyle="select:label nopage"/>
     expire = 600 
     renewal-freq = 60 
     before-acquire-handler&nbsp;=&nbsp;/usr/share/booth/service-runnable&nbsp;sap-prod</screen>
  </example>

  <calloutlist>
   <callout arearefs="co-ha-geo-booth-config-transport">
    <para>
     &booth-transport; Currently, this parameter can therefore be omitted.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-port">
    <para>
     &booth-port; The configuration files use different ports to allow for
     start of multiple booth instances on the same arbitrator.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-arbitrator">
    <para>
     &booth-arbitrator; In the examples above, we use the same arbitrator for
     different &geo; clusters.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-site">
    <para>
     &booth-site; The sites defined in both booth configuration files are
     different, because they belong to two different &geo; clusters.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-auth">
    <para>
     Optional parameter. &booth-auth; Use different key files for different
     tenants.
    </para>
    &booth-key-req;
   </callout>
   <callout arearefs="co-ha-geo-booth-config-ticket">
    <para>
     &booth-ticket; Theoretically the same ticket names can be defined in
     different booth configuration files&mdash;the tickets will not interfere
     because they are part of different &geo; clusters that are managed by
     different booth instances. However, (for better overview) we advise to use
     distinct ticket names for each &geo; cluster as shown in the examples
     above.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-handler">
    <para>
     Optional parameter. If set, the specified command will be called before
     &boothd; tries to acquire or renew a ticket. On exit code other than
     <literal>0</literal>, &boothd; relinquishes the ticket.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-script">
    <para>
     The <filename>service-runnable</filename> script referenced here is
     included in the product as an example. It is a simple script based on
     <command>crm_simulate</command>. It can be used to test whether a
     particular cluster resource <emphasis>can</emphasis> be run on the current
     cluster site. That means, it checks if the cluster is healthy enough to
     run the resource (all resource dependencies are fulfilled, the cluster
     partition has quorum, no dirty nodes, etc.). For example, if a service in
     the dependency-chain has a failcount of <literal>INFINITY</literal> on all
     available nodes, the service cannot be run on that site. In that case, it
     is of no use to claim the ticket.
    </para>
   </callout>
   <callout arearefs="co-ha-geo-booth-config-rsc">
    <para>
     The resource to be tested by the <literal>before-acquire-handler</literal>
     (in this case, by the <filename>service-runnable</filename> script). You
     need to reference the resource that is protected by the respective ticket.
    </para>
   </callout>
  </calloutlist>

  <procedure>
   <title>Using the same arbitrator for different &geo; clusters</title>
   <step>
    <para>
     Create different booth configuration files in
     <filename>/etc/booth</filename> as shown in
     <xref linkend="ex-ha-conf-booth-multi-1"/> and
     <xref linkend="ex-ha-conf-booth-multi-2"/>. Do so either manually or with
     &yast;, as outlined in <xref linkend="pro-ha-geo-setup-booth-yast"/>.
    </para>
   </step>
   <step>
    <para>
     On the arbitrator, open the ports that are defined in any of the booth
     configuration files in <filename>/etc/booth</filename>.
    </para>
   </step>
   <step>
    <para>
     On the nodes belonging to the individual &geo; clusters that the
     arbitrator is used for, open the port that is used for the respective
     booth instance.
    </para>
   </step>
   <step>
    <para>
     Synchronize the respective booth configuration files across all cluster
     nodes and arbitrators that use the same booth configuration. For details,
     see <xref linkend="sec-ha-geo-booth-sync"/>.
    </para>
   </step>
   <step>
    <para>
     On the arbitrator, start the individual booth instances as described in
     <xref linkend="vle-ha-geo-setup-booth-service-arbitrator"/> for
     multi-tenancy setups.
    </para>
   </step>
   <step>
    <para>
     On the individual &geo; clusters, start the booth service as described in
     <xref linkend="vle-ha-geo-setup-booth-service-sites"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec-ha-geo-booth-sync">
  <title>Synchronizing the booth configuration to all sites and arbitrators</title>

  <note>
   <title>Use the same booth configuration on all sites and arbitrators</title>
   <para>
    To make booth work correctly, all cluster nodes and arbitrators within one
    &geo; cluster must use the same booth configuration.
   </para>
   <para>
    You can use &csync; to synchronize the booth configuration. For details,
    see <xref linkend="sec-ha-geo-booth-sync-csync2-setup"/> and
    <xref linkend="sec-ha-geo-booth-sync-csync2-start"/>.
   </para>
   <para>
    In case of any booth configuration changes, make sure to update the
    configuration files accordingly on all parties and to restart the booth
    services as described in <xref linkend="sec-ha-geo-setup-booth-reconfig"/>.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="sec-ha-geo-setup-booth-service">
  <title>Enabling and starting the booth services</title>

  <variablelist>
   <varlistentry xml:id="vle-ha-geo-setup-booth-service-sites">
    <term>Starting the booth services on cluster sites</term>
    <listitem>
     <para>
      The booth service for each cluster site is managed by the booth resource
      group (that has either been configured automatically if you used the
      <systemitem>crm cluster init</systemitem> scripts for &geo; cluster setup,
      or manually as described in <xref linkend="sec-ha-geo-rsc-boothd"/>). To
      start one instance of the booth service per site, start the respective
      booth resource group on each cluster site.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="vle-ha-geo-setup-booth-service-arbitrator">
    <term>Starting the booth services on arbitrators</term>
<!--taroth 2014-08-11: https://bugzilla.novell.com/show_bug.cgi?id=877817: [Test
      Case 1378526] [316123] booth - Configuring startup 'complicated'-->
    <listitem>
     <para>
      Starting with &sle; 12, booth arbitrators are managed with systemd. The
      unit file is named <filename>booth@.service</filename>. The
      <literal>@</literal> denotes the possibility to run the service with a
      parameter, which is in this case the name of the configuration file.
     </para>
     <para>
      To <emphasis>enable</emphasis> the booth service on an arbitrator, use
      the following command:
     </para>
<screen>&prompt.root;<command>systemctl</command> enable booth@booth</screen>
     <para>
      After the service has been enabled from command line, &yast;
      &ycc_runlevel; can be used to manage the service (as long as the service
      is not disabled). In that case, it will disappear from the service list
      in &yast; the next time systemd is restarted.
     </para>
     <para>
      The command to <emphasis>start</emphasis> the booth service depends on
      your booth setup:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        If you are using the default setup as described in
        <xref linkend="sec-ha-geo-booth-default" xrefstyle="select:label"/>,
        only <filename>/etc/booth/booth.conf</filename> is configured. In that
        case, log in to each arbitrator and use the following command:
       </para>
<screen>&prompt.root;<command>systemctl</command> start booth@booth</screen>
      </listitem>
      <listitem>
       <para>
        If you are running booth in multi-tenancy mode as described in
        <xref linkend="sec-ha-geo-booth-multi" xrefstyle="select:label"/>, you
        have configured multiple booth configuration files in
        <filename>/etc/booth</filename>. To start the services for the
        individual booth instances, use
        <command>systemctl&nbsp;start&nbsp;booth@</command>
        <replaceable>NAME</replaceable>, where <replaceable>NAME</replaceable>
        stands for the name of the respective configuration file
        <filename>/etc/booth/<replaceable>NAME</replaceable>.conf</filename>.
       </para>
       <para>
        For example, if you have the booth configuration files
        <filename>/etc/booth/emea.conf</filename> and
        <filename>/etc/booth/apac.conf</filename>, log in to your arbitrator
        and execute the following commands:
       </para>
<screen>&prompt.root;<command>systemctl</command> start booth@emea
&prompt.root;<command>systemctl</command> start booth@apac</screen>
       <para>
<!-- taroth 2014-08-25: is it also possible to start the two
          services in one go when using the "@" syntax? if yes, how is the exact
          command? - dejan 2014-09-15: No, don't think so.-->
       </para>
      </listitem>
     </itemizedlist>
     <para>
      This starts the booth service in arbitrator mode. It can communicate with
      all other booth daemons but in contrast to the booth daemons running on
      the cluster sites, it cannot be granted a ticket. Booth arbitrators take
      part in elections only. Otherwise, they are dormant.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-ha-geo-setup-booth-reconfig">
  <title>Reconfiguring booth while running</title>

<!--taroth 2014-08-26: https://fate.suse.com/316126: 
    reconfiguration of boothd while running (prio: important)-->

  <para>
   In case you need to change the booth configuration while the booth services
   are already running, proceed as follows:
  </para>

  <procedure>
   <step>
    <para>
     Adjust the booth configuration files as desired.
    </para>
   </step>
   <step>
    <para>
     Synchronize the updated booth configuration files to all cluster nodes and
     arbitrators that are part of your &geo; cluster. For details, see
     <xref linkend="cha-ha-geo-sync"/>.
    </para>
   </step>
   <step>
<!--taroth 2014-08-26: https://bugzilla.novell.com/show_bug.cgi?id=891399-->
    <para>
     Restart the booth services on the arbitrators and cluster sites as
     described in <xref linkend="sec-ha-geo-setup-booth-service"/>. This does
     not have any effect on tickets that have already been granted to sites.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
