<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter version="5.0" xml:id="cha-ha-requirements"
  xmlns="http://docbook.org/ns/docbook" 
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:dm="urn:x-suse:ns:docmanager" 
  xmlns:xlink="http://www.w3.org/1999/xlink">
  <?dbfo-need height="10em"?>
  <title>System Requirements and Recommendations</title>
 <info>
      <dm:docmanager>
        <dm:bugtracker>
          <dm:assignee>taroth@suse.com</dm:assignee>
        </dm:bugtracker>
        <dm:translation>yes</dm:translation>
      </dm:docmanager>
      <abstract>
        <para>
    The following section informs you about system requirements, and some
    prerequisites for &productnamereg;. It also includes recommendations
    for cluster setup.
   </para>
      </abstract>
    </info>
    <sect1 xml:id="sec-ha-requirements-hw">
  <title>Hardware Requirements</title>

  <para>
   The following list specifies hardware requirements for a cluster based on
   &productnamereg;. These requirements represent the minimum hardware
   configuration. Additional hardware might be necessary, depending on how
   you intend to use your cluster.
  </para>

  <variablelist>
   <varlistentry>
    <term>Servers</term>
    <listitem>
     <para> 1 to 32 Linux servers with software as specified in <xref
       linkend="sec-ha-requirements-sw"/>. </para>
     &sys-req-hw-nodes;
     <para> Using <literal>pacemaker_remote</literal>, the cluster can be
      extended to include additional Linux servers beyond the 32-node limit.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Communication Channels</term>
    <listitem>
      &sys-req-hw-comm-channels;
     <para>For details, refer to <xref linkend="cha-ha-netbonding"/> and <xref
       linkend="pro-ha-installation-setup-channel2"/>, respectively.
      <!--bmwiedemann 2015-01-12: are there alternatives to Ethernet? WLAN?
     taroth 2015-01-12: checked this with the developers, the answer was:
     cable connections are more robust-->
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Node Fencing/&stonith;</term>
    <listitem>
     &sys-req-hw-stonith;
     <para>Unless SBD is used, each node in the &ha; cluster must have at least
      one &stonith; device. We strongly recommend multiple
      &stonith; devices per node.</para>
     &important-stonith;
    </listitem>
  </varlistentry>
  </variablelist>
 </sect1>
<?dbfo-need height="10em"?>
 <sect1 xml:id="sec-ha-requirements-sw">
  <title>Software Requirements</title>

  <para>
   On all nodes that will be part of the cluster the following software
   must be installed.
  </para>

  <itemizedlist>
   <listitem>
    &sys-req-sw-sles;
   </listitem>
   <listitem>
    &sys-req-sw-sleha;
   </listitem>
   <listitem>
    <para>
     (Optional) For &geo; clusters: &hageo; &productnumber;
     (with all available online updates)
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sec-ha-requirements-disk">
  <title>Storage Requirements</title>

  <para>
   Some services require shared storage. If using an external NFS share, it must
   be reliably accessible from all cluster nodes via redundant communication
   paths.</para>
  <para>To make data highly available, a shared disk system (Storage Area
   Network, or SAN) is recommended for your cluster. If a shared disk
   subsystem is used, ensure the following:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     The shared disk system is properly set up and functional according to
     the manufacturer&rsquo;s instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     The disks contained in the shared disk system should be configured to
     use mirroring or RAID to add fault tolerance to the shared disk system.
    </para>
   </listitem>
   <listitem>
    <para>
     If you are using iSCSI for shared disk system access, ensure that you
     have properly configured iSCSI initiators and targets.
    </para>
   </listitem>
   <listitem>
    <para>
     When using DRBD* to implement a mirroring RAID system that distributes
     data across two machines, make sure to only access the device provided
     by DRBD&mdash;never the backing device. Use bonded NICs. To leverage the
     redundancy it is possible to use the same NICs as the rest of the cluster.
    </para>
   </listitem>
  </itemizedlist>
  <para>
   When using SBD as &stonith; mechanism, additional requirements apply
   for the shared storage. For details, see <xref
    linkend="sec-ha-storage-protect-req"/>.
   </para>
 </sect1>
 <sect1 xml:id="sec-ha-requirements-other">
  <title>Other Requirements and Recommendations</title>

  <para>
   For a supported and useful &ha; setup, consider the following
   recommendations:
  </para>

  <variablelist>
   <varlistentry xml:id="vle-ha-req-nodes">
    <term>Number of Cluster Nodes</term>
    <listitem>
     <para>For clusters with more than two nodes, it is strongly recommended to use
       an odd number of cluster nodes to have quorum. For more information
       about quorum, see <xref linkend="sec-ha-config-basics-global"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Time Synchronization</term>
    &sys-req-other-ntp;
   </varlistentry>
   <varlistentry>
    <term>Network Interface Card (NIC) Names</term>
    <listitem>
     <para>
      Must be identical on all nodes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Host Name and IP Address</term>
    <listitem>
     <itemizedlist>
      <listitem>
       <para>
        Use static IP addresses.
       </para>
      </listitem>
      <listitem>
       &sys-req-other-etc-hosts;
       <para>
        For details on how Pacemaker gets the node names, see also
        <link xlink:href="http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html/Pacemaker_Explained/s-node-name.html"/>.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="vle-ha-req-ssh">
    <term>SSH</term>
    <listitem>
     &sys-req-other-ssh;
     <note>
      <title>Regulatory Requirements</title>
      <para>
       If passwordless SSH access does not comply with regulatory
       requirements, you can use the work-around described in
       <xref linkend="app-crmreport-nonroot"/> for running 
       <command>crm report</command>.
      </para>
      <para>
       For the <guimenu>History Explorer</guimenu> there is currently no
       alternative for passwordless login.
      </para>
     </note>
    </listitem>
   </varlistentry>

  </variablelist>
 </sect1>
</chapter>
