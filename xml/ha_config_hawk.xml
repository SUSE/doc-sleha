<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<!--taroth 2013-11-07: open issues to complete transfer for fate#316120 and #316121
 - remove geocluster chapter from HA Guide
 - add link to new QS in HA Guide
 - fix Hawk chapter with regards to any remaining GEO stuff
 - check overview chapter and fix link
-->
<!--taroth 2012-01-11: todo for next revision: how to define constraints via
rule editor-->
<!--taroth 2013-03-25: for SLE 12 at the latest, split sec.ha.config.hawk.intro in two separate
 sections and briefly explain main Hawk screens/tools, also split into smaller XIncludes-->
<chapter id="cha.ha.config.hawk">
 <title>Configuring and Managing Cluster Resources (Web Interface)</title>
 <abstract>
  <para>
   To configure and manage cluster resources, either use 
   &haweb; (&hawk;), a Web-based user interface, or 
   the &crmshell; (&crmsh;) command line utility.</para>
  
  <para>&hawk; allows you to monitor and
   administer your Linux cluster from non-Linux machines as well.
   Furthermore, it is the ideal solution in case your system only provides a
   minimal graphical user interface.
  </para>

  <para>
   This chapter introduces &hawk; and covers basic tasks for configuring and
   managing cluster resources: modifying global cluster options, creating
   basic and advanced types of resources (groups and clones), configuring
   constraints, specifying failover nodes and failback nodes, configuring
   resource monitoring, starting, cleaning up or removing resources, and
   migrating resources manually. For detailed analysis of the cluster
   status, &hawk; generates a cluster report (<literal>crm_report</literal>).
   You can view the cluster history or explore potential failure scenarios
   with the simulator.
  </para>
</abstract>
  

 <sect1 id="sec.ha.config.hawk.intro">
  <title>&hawk;&mdash;Overview</title>
  <para>&hawk;'s Web interface allows you to monitor and administer your Linux cluster from
   non-Linux machines as well. Furthermore, it is the ideal solution in case your system only
   provides a minimal graphical user interface. </para>
  
  <sect2 id="sec.ha.config.hawk.intro.connect">
   <title>Starting &hawk; and Logging In</title>
   
   <para>The Web interface is included in the <systemitem class="resource">hawk</systemitem>
    package. It must be installed on all cluster nodes you want to connect to with &hawk;. On
    the machine from which you want to access a cluster node using &hawk;, you only need a
    (graphical) Web browser with JavaScript and cookies enabled to establish the connection.
   </para>
    
   <para>
    To use &hawk;, the respective Web service must be started on the node
    that you want to connect to via the Web interface. 
   </para>
   <para>If you have set up your cluster with the scripts from the <systemitem class="resource"
    >ha-cluster-bootstrap</systemitem> package, the &hawk; service is already started. In that
    case, skip <xref linkend="pro.ha.hawk.service"/> and proceed with <xref linkend="pro.ha.hawk.login"/>.</para>
   
   <procedure id="pro.ha.hawk.service">
    <title>Starting &hawk; Services</title>
    <step>
     <para>
      On the node you want to connect to, open a shell and log in as
      &rootuser;.
     </para>
    </step>
    <step>
     <para>
      Check the status of the service by entering
     </para>
<screen>&prompt.root;<command>systemctl</command> status hawk.service</screen>
   </step>
    <step>
     <para>
      If the service is not running, start it with
     </para>
<screen>&prompt.root;<command>systemctl</command> start hawk.service</screen>
   <para>
      If you want &hawk; to start automatically at boot time, execute the
      following command:
     </para>
<screen>&prompt.root;<command>systemctl</command> enable hawk.service</screen>
    </step>
   </procedure>
   
   <note>
    <title>User Authentication</title>
    <para>&hawk; users must be members of the <systemitem class="groupname"
     >haclient</systemitem> group. The installation creates a Linux user named <systemitem
      class="username">hacluster</systemitem> and adds him to the <systemitem
       class="groupname">haclient</systemitem> group. When using the
     <command>ha-cluster-init </command>script for setup, a default password is set for the
     <systemitem class="username">hacluster</systemitem> user.</para>
    <para>Before starting &hawk;, set or change the password for the <systemitem>hacluster</systemitem>
     user. Alternatively, create a new user which is a member of the <systemitem class="groupname"
      >haclient</systemitem> group. </para>
    <para>
     Do this on every node you will connect to with &hawk;.
    </para>
   </note>
   
   <procedure id="pro.ha.hawk.login">
    <title>Logging In to the &hawk; Web Interface</title>
    <para>The &hawk; Web interface uses the HTTPS protocol and port <literal>7630</literal>.</para>
     <step>
     <para>
      On any machine, start a Web browser and make sure that JavaScript and
      cookies are enabled.
     </para>
    </step>
    <step>
     <para>
      As URL, enter the IP address or hostname of any cluster node running the
      &hawk; Web service. Alternatively, enter the address of any <literal>IPaddr(2)</literal>
      resource that the cluster operator may have configured:
     </para>
<screen>https://<replaceable>HOSTNAME_OR_IP_ADDRESS</replaceable>:7630/</screen>
     <note>
      <title>Certificate Warning</title>
      <para>If a certificate warning appears when you try to access the URL for the first time, a
       self-signed certificate is in use. Self-signed certificates are not considered trustworthy by
       default. </para>
      <para>Ask your cluster operator for the certificate details to verify the certificate.</para>
      <para> To proceed anyway, you can add an exception in the browser to bypass the warning. 
      </para>
      <para>For information on how to replace the self-signed certificate with a certificate signed
       by an official Certificate Authority, refer to <xref linkend="vle.ha.hawk.certificate"/>.
      </para>
     </note>
    </step>
    <step>
     <para>
      On the &hawk; login screen, enter the <guimenu>Username</guimenu> and
      <guimenu>Password</guimenu> of the
      <systemitem class="username">hacluster</systemitem> user (or of any
      other user that is a member of the
      <systemitem class="groupname"
       >haclient</systemitem> group). 
     </para>
    </step>
    <step>
     <para>Click <guimenu>Log In</guimenu>.</para>
     <para> The <guimenu>Cluster Status</guimenu> screen appears, displaying the status of your
      cluster nodes and resources. The information shown is similar to the output of
      <command>crm status</command> in the &crmshell;. </para>
    </step>
   </procedure>
  </sect2>

  <sect2 id="sec.ha.config.hawk.intro.main">
   <title>Main Screen: Cluster Status</title>
   <remark>taroth 2014-07-31: todo: this sections needs a serious overhaul and restructuring as a
    lot of new functions and views have been added to Hawk during the last releases - however, it
    makes more sense to postpone this until the next general UI overhaul for Hawk, so
    let's live with the current state for one more release... ;(</remark>
   <para><remark>taroth 2014-07-30: todo - https://fate.suse.com/316303: HAWK resource summary on group level</remark>
    After logging in, &hawk; displays the <guimenu>Cluster Status</guimenu>
    screen. It shows a summary with the most important global cluster
    parameters and the status of your cluster nodes and resources. The
    following color code is used for status display of nodes and resources:
   </para>
   <itemizedlist id="il.ha.config.hawk.colors">
    <title>&hawk; Color Code</title>
    <listitem>
     <para> Green: OK. For example, the resource is running or the node is online. </para>
    </listitem>
    <listitem>
     <para>
      Red: Bad, unclean. For example, the resource has failed or the node
      was not shut down cleanly.
     </para>
    </listitem>
    <listitem>
     <para> Yellow: In transition. For example, the node is currently being shut down or a resource
      is currently being started or stopped. If you click a pending resource to view its details,
      &hawk; also displays the state to which the resource is currently changing
       (<literal>Starting</literal>, <literal>Stopping</literal>, <literal>Moving</literal>,
       <literal>Promoting</literal>, or <literal>Demoting</literal>). </para>
     <!--https://bugzilla.novell.com/show_bug.cgi?id=883529: 
      [doc] mention record-pending needs to be set for hawk to display resources in transitional state -->
     <note>
      <title>Displaying Transitional State for Resources</title>
      <para>The transitional state for resources is only shown if the operation property
        <varname>record-pending</varname> is set to <literal>true</literal>. If you have set up your
       cluster with the <command>ha-cluster-init</command> script, this property is turned on
       globally by default. To enable it manually, either use the &hawk; <guimenu>Cluster
        Configuration</guimenu> screen to add and enable the property below <guimenu>Operation
        Defaults</guimenu> or use the following command:</para>
      <screen>crm configure op_defaults record-pending=true</screen>
     </note>
    </listitem>
    <listitem>
     <para>
      Gray: Not running, but the cluster expects it to be running. For
      example, nodes that the administrator has stopped or put into
      <literal>standby</literal> mode. Also nodes that are offline are
      displayed in gray (if they have been shut down cleanly).
     </para>
    </listitem>
   </itemizedlist>
   <para>
    In addition to the color code, &hawk; also displays self-explanatory
    icons for the state of nodes, resources, tickets and for error messages
    in all views of the <guimenu>Cluster Status</guimenu> screen.
   </para>
   <para>
    If a resource has failed, an error message with the details is shown in
    red at the top of the screen. To analyze the causes for the failure,
    click the error message. This automatically takes you to &hawk;'s
    <guimenu>History Explorer</guimenu> and triggers the collection of data
    for a time span of 20 minutes (10 minutes before and 10 minutes after
    the failure occurred). For more details, refer to
    <xref
     linkend="pro.ha.config.hawk.history.explorer"/>.
   </para>
   <figure pgwide="0">
    <title>&hawk;&mdash;Cluster Status (Summary View)</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="hawk-cluster-status-main.png" width="90%" format="PNG"
      />
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="hawk-cluster-status-main.png" width="80%" format="PNG"
      />
     </imageobject>
    </mediaobject>
   </figure>
   <para>
    The <guimenu>Cluster Status</guimenu> screen refreshes itself in near
    real-time. Choose between the following views, which you can access with
    the three icons in the upper right corner:
   </para>
<!--fate#309100-->
   <variablelist>
    <title>&hawk; Cluster Status Views</title>
    <varlistentry>
     <term>Summary View</term>
     <listitem>
      <para>
       Shows the most important global cluster parameters and the status of
       your cluster nodes and resources at the same time. If your setup
       includes &geo; clusters (multi-site clusters), the summary view also shows tickets. 
       To view details about all elements belonging to a certain category (tickets, nodes, or
       resources), click the category title, which is marked as a link.
       Otherwise click the individual elements for details.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Tree View</term>
     <listitem>
      <para>
       <!--taroth 2013-04-29: bnc#809988: Tickets are only displayed in default view-->
       Presents an expandable view of the most important global cluster parameters and the status of
       your cluster nodes and resources. Click the arrows to expand or collapse the elements
       belonging to the respective category. In contrast to the <guimenu>Summary View</guimenu> this
       view not only shows the IDs and status of resources but also the type (for example,
       primitive, clone, or group). </para>
      <!--https://fate.suse.com/316303: HAWK resource summary on group level-->
      <para>For groups, it is also possible to switch to a view where resources of the same type
       (within a group) are presented together. Press the <literal>ab</literal> icon in the
       resources category to toggle between the normal view where the resources are displayed
       individually and the view where they are coalesced by type. For example, if you have 3
       resources of the type <literal>ocf:pacemaker:Dummy</literal> in one group, and only one of
       them is running, the view-by-type view shows an entry like <literal>1/3 ocf:pacemaker:Dummy
         <replaceable>NODENAME</replaceable> on a grey background, to indicate only 1 of the three
        has already started.</literal>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Table View</term>
     <listitem>
      <para>
       This view is especially useful for larger clusters, because it shows
       in a concise way which resources are currently running on which node.
       Inactive nodes or resources are also displayed.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    The top-level row of the main screen shows the username with which you
    are logged in. It also allows you to <guimenu>Log Out</guimenu> of the
    Web interface, and to access the following <guimenu>Tools</guimenu> from
    the wrench icon next to the username:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <guimenu>Simulator</guimenu>. For details, refer to
      <xref
       linkend="sec.ha.config.hawk.simulator"/>.
     </para>
    </listitem>
<!--fate#313718 (SP3)-->
    <listitem>
     <para>
      <guimenu>Cluster Diagram</guimenu>. Select this entry for a graphical
      representation of the nodes and the resources configured in the CIB.
      The diagram also shows the ordering and colocation between resources
      and node assignments (scores).
     </para>
     <figure id="fig.ha.cluster.diagram" pgwide="0">
      <title>&hawk;&mdash;Cluster Diagram</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="hawk-cluster-diagram.png" width="100%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="hawk-cluster-diagram.png" width="100%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
    </listitem>
    <listitem>
     <para>
      <guimenu>Cluster Report</guimenu> (<command>crm_report</command>). For
      details, refer to
      <xref
       linkend="sec.ha.config.hawk.crm_report"/>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    To perform basic operator tasks on nodes and resources (like starting or
    stopping resources, bringing nodes online, or viewing details), click
    the wrench icon next to the respective node or resource to access a
    context menu.
<!--fate#314388 (SP3)-->
    For any clone, group or master/slave child resource on any of the status
    screens, select the <guimenu>Parent</guimenu> menu item from the context
    menu. Clicking this will let you start, stop, etc. the top-level clone
    or group to which that primitive belongs.
   </para>
   <para>
    For more complex tasks like configuring resources, constraints, or
    global cluster options, use the navigation bar on the left hand side.
    From there, you can also view the cluster history.
   </para>
   <note>
    <title>Available Functions in &hawk;</title>
    <para>
     By default, users logged in as &rootuser; or
     <systemitem
      class="username">hacluster</systemitem> have full
     read-write access to all cluster configuration tasks. However,
     <xref linkend="cha.ha.acl"
      xrefstyle="select:title"/> can be used
     to define fine-grained access permissions.
    </para>
    <para>
     If ACLs are enabled in the CRM, the available functions in &hawk;
     depend on the user role and access permissions assigned to you. In
     addition, the following functions in &hawk; can only be executed by the
     user <systemitem class="username">hacluster</systemitem>:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Generating a <literal>crm_report</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       Using the history explorer.
      </para>
     </listitem>
     <listitem>
      <para>
       Viewing recent events for nodes or resources.
      </para>
     </listitem>
    </itemizedlist>
   </note>
  </sect2>
 </sect1>
 <sect1 id="sec.ha.config.hawk.global">
  
  <title>Configuring Global Cluster Options</title>

  <para>
   Global cluster options control how the cluster behaves when confronted
   with certain situations. They are grouped into sets and can be viewed and
   modified with cluster management tools like &hawk;, and
   <command>crm</command> shell. The predefined values can be kept in most
   cases. However, to make key functions of your cluster work correctly, you
   need to adjust the following parameters after basic cluster setup:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <xref linkend="sec.ha.config.basics.global.quorum" xrefstyle="select:title"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.ha.config.basics.global.stonith" xrefstyle="select:title"/>
    </para>
   </listitem>
  </itemizedlist>

  <procedure id="pro.ha.config.hawk.global">
   <title>Modifying Global Cluster Options</title>
   <step>
    <para>
     Start a Web browser and log in to the cluster as described in
     <xref
      linkend="sec.ha.config.hawk.intro.connect"/>.
    </para>
   </step>
   <step>
    <para>
     In the left navigation bar, select <guimenu>Cluster
     Properties</guimenu> to view the global cluster options and their
     current values. &hawk; displays the most important parameters with
     regards to <guimenu>CRM Configuration</guimenu>, <guimenu>Resource
     Defaults</guimenu>, and <guimenu>Operation Defaults</guimenu>.
     <remark>taroth 2013-03-12: I'm also wondering if it would make sense to simply display the
      default values as a text to the right of the field? this would help to reset the values to the
      defaults in case I misconfigured them... if the input fields only reflect the current value, I
      will never now that the default value has been after I changed the value once... tserong
      2013-04-15: Good idea, I've made a note to do that (although I don't know if I'll get it in
      for this release or not, maybe don't mention it, it'll be obvious anyway...) The main crm
      config properties, we have online help for, because I can extract it from pacemaker somehow
      (by querying the PE, or whatever). Unfortunately this metadata isn't exposed anywhere for
      rsc_defaults and op_defaults (or, if it is, I'm not aware of it).</remark>
    </para>
    <figure pgwide="0">
     <title>&hawk;&mdash;Cluster Configuration</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="hawk-cluster-props.png" width="80%" format="PNG"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="hawk-cluster-props.png" width="80%" format="PNG"/>
      </imageobject>
     </mediaobject>
    </figure>
   </step>
   <step>
    <para>
     Depending on your cluster requirements, adjust the <guimenu>CRM
     Configuration</guimenu>:
    </para>
    <substeps>
     <step>
      <para>
       Set <guimenu>no-quorum-policy</guimenu> to the appropriate value.
      </para>
     </step>
     <step>
      <para>
       If you need to disable fencing for any reasons, deselect
       <guimenu>stonith-enabled</guimenu>.
      </para>
      <important>
       <title>No Support Without &stonith;</title>
       <para>
        A cluster without &stonith; is not supported.
       </para>
      </important>
     </step>
     <step>
      <para>
       To remove a property from the CRM configuration, click the minus icon
       next to the property. If a property is deleted, the cluster will
       behave as if that property had the default value. For details of the
       default values, refer to
       <ulink
        url="http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html/Pacemaker_Explained/s-resource-options.html"
       />.
      </para>
     </step>
     <step>
      <para>
       To add a new property for the CRM configuration, choose one from the
       drop-down list and click the plus icon.
      </para>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     If you need to change <guimenu>Resource Defaults</guimenu> or
     <guimenu>Operation Defaults</guimenu>, proceed as follows:
    </para>
    <substeps>
     <step>
      <para>
       To change the value of defaults that are already displayed, just edit
       the value in the respective input field.
      </para>
     </step>
     <step>
      <para>
       To add a new resource default or operation default, choose one from
       the empty drop-down list, click the plus icon and enter a value. If
       there are default values defined, &hawk; proposes them automatically.
      </para>
     </step>
     <step>
      <para>
       To remove a resource or operation default, click the minus icon next
       to the parameter. If no values are specified for <guimenu>Resource
       Defaults</guimenu> and <guimenu>Operation Defaults</guimenu>, the
       cluster uses the default values that are documented in
       <xref
        linkend="sec.ha.config.basics.meta.attr"/> and
       <xref
        linkend="sec.ha.config.basics.operations"/>.
      </para>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Confirm your changes.
    </para>
   </step>
  </procedure>

<!-- taroth 2012-01-09: switching back to *default* options is not possible with
Hawk, the Revert button will switch back to the former config as long as you
haven't applied the changes yet
-->
 </sect1>

 <xi:include  href="ha_hawk_rsc_config_i.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
 <xi:include  href="ha_hawk_rsc_manage_i.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
 
 <sect1 id="sec.ha.config.hawk.dashboard">
<!--fate#310306 (SP3)-->

  <title>Monitoring Multiple Clusters</title>

  <para>
   Use &hawk; as a single point of administration for monitoring multiple
   clusters. &hawk;'s <guimenu>Cluster Dashboard</guimenu> allows you to
   view a summary of multiple clusters, with each summary listing the number
   of nodes, resources, tickets (if you use &geo; clusters), and their
   state. The summary also shows if any failures have appeared in the
   respective cluster.
  </para>

  <para>
   The cluster information displayed in the <guimenu>Cluster
   Dashboard</guimenu> is stored in a persistent cookie. This means you need
   to decide which &hawk; instance you want to view the <guimenu>Cluster
   Dashboard</guimenu> on, and always use that one. The machine you are
   running &hawk; on does not even have to be part of any cluster for that
   purpose&mdash;it can be a separate, unrelated system.
  </para>

  <procedure id="pro.ha.config.hawk.dashboard">
   <title>Monitoring Multiple Clusters with &hawk;</title>
   <itemizedlist>
    <title>Prerequisites</title>
    <listitem>
     <para>
      All clusters to be monitored from &hawk;'s <guimenu>Cluster
      Dashboard</guimenu> must be running &productname; SP3. It is not
      possible to monitor clusters that are running earlier versions of
      &productname;.
     </para>
    </listitem>
    <listitem>
     <para>
      If you did not replace the self-signed certificate for &hawk; on every
      cluster node with your own certificate (or a certificate signed by an
      official Certificate Authority), you must log in to &hawk; on
      <emphasis>every</emphasis> node in <emphasis>every</emphasis> cluster
      at least once. Verify the certificate (or add an exception in the
      browser to bypass the warning).
     </para>
    </listitem>
    <listitem>
     <para>
      If using Mozilla Firefox, you must change its preferences to
      <guimenu>Accept third-party cookies</guimenu>. Otherwise cookies from
      monitored clusters will not be set, thus preventing login to the
      clusters you are trying to monitor.
     </para>
    </listitem>
   </itemizedlist>
   <step>
    <para>
     Start the &hawk; Web service on a machine you want to use for
     monitoring multiple clusters.
    </para>
   </step>
   <step>
    <para>
     Start a Web browser and point it at the IP address or hostname of the
     machine that runs &hawk;:
    </para>
<screen>https://<replaceable>IPaddress</replaceable>:7630/</screen>
   </step>
   <step>
    <para>
     On the &hawk; login screen, click the <guimenu>Dashboard</guimenu> link
     in the right upper corner.
    </para>
    <para>
     The <guimenu>Add Cluster</guimenu> dialog appears.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="hawk-dashboard-add-cluster.png" width="100%" format="PNG"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="hawk-dashboard-add-cluster.png" width="80%" format="PNG"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
   </step>
   <step>
    <para>
     Enter a custom <guimenu>Cluster Name</guimenu> with which to identify
     the cluster the <guimenu>Cluster Dashboard</guimenu>.
    </para>
   </step>
   <step>
    <para>
     Enter the <guimenu>Host Name</guimenu> of one of the cluster nodes and
     confirm your changes.
    </para>
    <para>
     The <guimenu>Cluster Dashboard</guimenu> opens and shows a summary of
     the cluster you just added.
    </para>
   </step>
   <step>
    <para>
     To add more clusters to the dashboard, click the plus icon and enter
     the details for the next cluster.
    </para>
    <figure>
     <title>&hawk;&mdash;Cluster Dashboard</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="hawk-dashboard-multiple-clusters.png" width="50%" format="PNG"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="hawk-dashboard-multiple-clusters.png" width="30%" format="PNG"/>
      </imageobject>
     </mediaobject>
    </figure>
   </step>
   <step>
    <para>
     To remove a cluster from the dashboard, click the <literal>x</literal>
     icon next to the cluster's summary.
    </para>
   </step>
   <step>
    <para>
     To view more details about a cluster, click somewhere into the
     cluster's box on the dashboard.
    </para>
    <para>
     This opens a new browser window or new browser tab. If you are not
     currently logged in to the cluster, this takes you to the &hawk; login
     screen. After having logged in, &hawk; shows the <guimenu>Cluster
     Status</guimenu> of that cluster in the summary view. From here, you
     can administrate the cluster with &hawk; as usual.
    </para>
   </step>
   <step>
    <para>
     As the <guimenu>Cluster Dashboard</guimenu> stays open in a separate
     browser window or tab, you can easily switch between the dashboard and
     the administration of individual clusters in with &hawk;.
    </para>
   </step>
  </procedure>

  <para>
   Any status changes for nodes or resources are reflected almost
   immediately within the <guimenu>Cluster Dashboard</guimenu>.
  </para>

  <note>
   <title>Node Not Accessible</title>
   <para>
    The <guimenu>Cluster Dashboard</guimenu> only polls one node in each
    cluster for status. If the node being polled goes down, the dashboard
    will cycle to poll another node. In that case, &hawk; briefly displays a
    warning message about that node being inaccessible. The message will
    disappear after &hawk; has found another node to contact.
   </para>
  </note>

<!--from bnc#808703:  
   Hawk's status screen is for viewing detailed status of one cluster (which is
   why you can't add other clusters to monitor when you're on the status screen).
   
   The dashboard is for showing summary details of many clusters, any of which you
   can click to get to the (more detailed) status screen showing that cluster
   only.
   
   You don't need to log in to hawk to visit the dashboard screen.  But you do
   need to be logged in to any clusters that are being viewed in the dashboard
   (since beta3 the dashboard will prompt for login details for each monitored
   cluster if you're not already logged in).  This is probably where the confusion
   starts.  That and the fact that any Hawk instance can also show a dashboard...
   
   It might help to look at it this way.  Assume you have two clusters (c0 and
   c1), and happen to have a separate unrelated system running Hawk, which you
   only use for its dashboard functionality (in fact there doesn't even need to be
   a cluster running on that system at all).  If you view the dashboard on that
   system, you don't need to log into hawk on that node, as you're not interested
   in that system itself - you just want to use its dashboard to monitor clusters
   c0 and c1.-->
 </sect1>
 <sect1 id="sec.ha.config.hawk.trouble">
  <title>Troubleshooting</title>

  <variablelist>
   <varlistentry>
    <term>&hawk; Log Files</term>
    <listitem>
     <para>
      Find the &hawk; log files in <filename>/srv/www/hawk/log</filename>.
      Check these files in case you cannot access &hawk;.
     </para>
     <para> If you have trouble starting or stopping a resource with &hawk;, check the Pacemaker
      log messages. <remark>taroth 2014-06-24: todo: JOURNALCTL - check with devs!</remark>By
      default, Pacemaker logs to <filename>/var/log/messages</filename>. </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Authentication Fails</term>
    <listitem>
     <para>
      If you cannot log in to &hawk; with a new user that is a member of the
      <systemitem class="groupname">haclient</systemitem> group (or if you
      experience delays until &hawk; accepts logins from this user), stop
      the <systemitem class="daemon">nscd</systemitem> daemon with
      <command>systemctl</command> <literal>stop nscd.service</literal>
      and try again.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry id="vle.ha.hawk.certificate">
    <term>Replacing the Self-Signed Certificate</term>
    <listitem>
     <para>
      To avoid the warning about the self-signed certificate on first &hawk;
      startup, replace the automatically created certificate with your own
      certificate or a certificate that was signed by an official
      Certificate Authority (CA).
     </para>
     <para>
      The certificate is stored in
      <filename>/etc/lighttpd/certs/hawk-combined.pem</filename> and
      contains both key and certificate. After you have created or received
      your new key and certificate, combine them by executing the following
      command:
     </para>
<screen>cat <replaceable>keyfile</replaceable>&nbsp;<replaceable>certificatefile</replaceable> > /etc/lighttpd/certs/hawk-combined.pem</screen>
     <para>
      Change the permissions to make the file only accessible by &rootuser;:
     </para>
<screen>chown root.root /etc/lighttpd/certs/hawk-combined.pem
chmod 600 /etc/lighttpd/certs/hawk-combined.pem</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Login to &hawk; Fails After Using History Explorer/crm_report </term>
    <listitem>
     <para>
<!--taroth 2011-11-18: filed https://bugzilla.novell.com/show_bug.cgi?
      id=731282 - if that can be fixed in the software, remove this 
      troubleshooting topic - taroth 2012-01-11: some progress with the bug
      but maybe still too early to remove the topic completely-->
      Depending on the period of time you defined in the <guimenu>History
      Explorer</guimenu> or <guimenu>crm_report</guimenu> and the events that
      took place in the cluster during this time, &hawk; might collect an
      extensive amount of information stored in log files in the
      <filename>/tmp</filename> directory. This might consume the remaining
      free disk space on your node. In case &hawk; should not respond after
      using the <guimenu>History Explorer</guimenu> or
      <guimenu>crm_report</guimenu>, check the hard disk of your cluster node
      and remove the respective log files.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><guimenu>Cluster Dashboard</guimenu>: Unable to connect to host</term>
    <listitem>
     <para>
      If adding clusters to &hawk;'s dashboard fails, check the
      prerequisites listed in
      <xref linkend="pro.ha.config.hawk.dashboard"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><guimenu>Cluster Dashboard</guimenu>: Node Not Accessible</term>
    <listitem>
     <para>
      The <guimenu>Cluster Dashboard</guimenu> only polls one node in each
      cluster for status. If the node being polled goes down, the dashboard
      will cycle to poll another node. In that case, &hawk; briefly displays
      a warning message about that node being inaccessible. The message will
      disappear after &hawk; has found another node to contact to.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
</chapter>
