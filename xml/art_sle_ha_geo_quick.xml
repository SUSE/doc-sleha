<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
  type="text/xml" 
  title="Profiling step"?>
<!DOCTYPE article
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!--taroth 2014-12-18: todo for next release: fix IDs in xincludes-->
<?provo dirname="geo_quick/"?>
<article version="5.0" xml:lang="en" xml:id="art.ha.geo.quick"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:dm="urn:x-suse:ns:docmanager"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>&geoquick;</title>
 <subtitle>&productname; &productnumber;</subtitle>
 <info>
  <productnumber>&productnumber;</productnumber>
   <productname>&productname;</productname>
   <date><?dbtimestamp?></date>
   <abstract>
    <para>
     &abstract-geoquick;
     This document guides you through the basic setup of a &geo; cluster,
     using the &geo; clustering bootstrap scripts provided by the
      <systemitem xmlns='http://docbook.org/ns/docbook'
        class='resource'>ha-cluster-bootstrap</systemitem> package.
      </para>
     </abstract>
      <dm:docmanager>
        <dm:bugtracker>
          <dm:url>https://bugzilla.suse.com/enter_bug.cgi</dm:url>
          <dm:product>SUSE Linux Enterprise High Availability Extension 12 SP3</dm:product>
          <dm:component>GEO Clustering</dm:component>
        </dm:bugtracker>
        <dm:translation>yes</dm:translation>
      </dm:docmanager>
 </info>
  <sect1 xml:id="sec.ha.geo.quick.concept">
    <title>Conceptual Overview</title>
    <para>
      &geo; clusters based on &productname; can be considered
      <quote>overlay</quote> clusters where each cluster site corresponds to a
      cluster node in a traditional cluster. The overlay cluster is managed by
      the booth cluster ticket manager (in the following called booth).
      Each of the parties involved in a &geo; cluster runs
      a service, the &boothd;. It connects to the booth daemons running at the
      other sites and exchanges connectivity details. For making cluster
      resources highly available across sites, booth relies on cluster objects
      called tickets. A ticket grants the right to run certain resources on a
      specific cluster site. Booth guarantees that every ticket is granted to no
      more than one site at a time.
    </para>
    <para>
    If the communication between two booth instances breaks down, it might be
    due to a network breakdown between the cluster sites <emphasis>or</emphasis>
    to an outage of one cluster site. In this case, you need an additional instance
    (an arbitrator) to reach consensus about decisions such as failover of resources
    across sites. Arbitrators are single machines (outside of the clusters) that
    run a booth instance in a special mode. Each &geo; cluster can have one or
    multiple arbitrators. They are especially important for &geo; cluster
    setups with an even number of sites.
    </para>
   <para>
    <remark>toms 2017-07-04: for the future: maybe also add example IP addresses
    to graphics (node IPs, VIPs for cluster sites) (but first, we need to define
    a consistent example setup)
    </remark>
   </para>
    <figure xml:id="fig.ha.geo.quick.example.geosetup">
      <title>Two-Site Cluster (2x2 Nodes + Arbitrator)</title>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="ha_geocluster.svg" width="80%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="ha_geocluster.png" width="85%" format="PNG"/>
        </imageobject>
      </mediaobject>
    </figure>
    <para>
      For more details on components and ticket management for &geo; clusters,
      see .<remark>FIXME - taroth 2017-06-27: add link to
      conceptual overview in Geo  Guide</remark>
    </para>
  </sect1>
  <sect1 xml:id="sec.ha.geo.quick.scenario">
    <title>Usage Scenario</title>
    <para>
      The procedures in this document will lead to an example setup of a
      &geo; cluster with two cluster sites (<literal>&cluster1;</literal>
     and <literal>&cluster2;</literal>) and one arbitrator.
    </para>
   <variablelist>
    <title>Requirements</title>
    <varlistentry>
     <term>Two Existing Clusters</term>
     <listitem>
     <para>You have at least two existing clusters that you want to combine into
      a &geo; cluster. (If you need to set up two clusters first, follow the
      instructions in the <citetitle>&instquick;</citetitle>.
      The document is available from <link
       xlink:href="https://www.suse.com/documentation"></link>).
     </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Meaningful Cluster Names</term>
    <listitem>
     <para>Each cluster has a meaningful cluster name that reflects its location.
      For this scenario, we assume the following cluster locations and names:
      <literal>&cluster1;</literal> and <literal>&cluster2;</literal>.
     </para>
     <para>
      The cluster names for each site are defined in the respective &corosync.conf;
      files:
     </para>
     <screen>totem {
      [...]
      cluster_name: &cluster1;
      }
     </screen>
     <para>Set the cluster name during the initial setup of a cluster (with
      <command>ha-cluster-init --name <replaceable>CLUSTERNAME</replaceable></command>), or manually
      (by editing &corosync.conf;). Alternatively, set it with the
      &yast; cluster module (by switching to the <guimenu>Communication Channels</guimenu>
      category and defining a <guimenu>Cluster Name</guimenu>).
      For the changes to take effect, restart the &pace; service afterwards.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Arbitrator</term>
    <listitem>
     <para>You have installed a third machine that is not part of any existing
      clusters and is to be used as arbitrator.</para>
    </listitem>
   </varlistentry>
  </variablelist>
   <para>
    For detailed requirements on each item, see <xref linkend="sec.ha.geo.quick.req"/>.
   </para>
  </sect1>
  <sect1 xml:id="sec.ha.geo.quick.req">
    <title>Requirements</title>
     <itemizedlist>
      <title>Software Requirements</title>
      <listitem>
        <para>
          All machines (cluster nodes and arbitrators) that will be part of the
          &geo; cluster have the following software installed:
        </para>
       <itemizedlist>
        <listitem>
        <para>
          &slsreg; &productnumber;
        </para>
        </listitem>
        <listitem>
         <para>
          &productname; &productnumber;
         </para>
        </listitem>
        <listitem>
          <para>
           &hageo; &productnumber;
           <!--<remark>taroth 2014-08-20: booth package would be enough (GEO pattern only consists of the booth
             package) but to make it clear where to get the package from, phrasing like this</remark>-->
          </para>
         </listitem>
       </itemizedlist>
   </listitem>
    </itemizedlist>
     <itemizedlist>
      <title>Network Requirements</title>
      <listitem>
        <para>
         <remark>taroth 2017-07-04: @DEV/QA: is the following correct (private
          network routed to other site)? the IPs mentioned here should be the
          same as the VIPs used for each cluster site, is that right? and does
          it make sense to use similar network numbers like below? would that
          reflect reality for different cluster sites or rather not?</remark>
          Each cluster site has a private network routed to the other site:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              &cluster1;: <literal>192.168.201.x</literal>
            </para>
          </listitem>
          <listitem>
            <para>
              &cluster2;: <literal>192.168.202.x</literal>
            </para>
          </listitem>
        </itemizedlist>
      </listitem>
      <listitem>
        <para>
          The sites must be reachable on one UDP and TCP port per booth instance.
          That means any firewalls or IPsec tunnels in between must be configured
          accordingly.
        </para>
      </listitem>
      <listitem>
        <para>
          Other setup decision may require to open more ports (for example, for
          DRBD or database replication).
        </para>
      </listitem>
    </itemizedlist>
    <itemizedlist>
      <title>Other Requirements and Recommendations</title>
      <listitem>
        <para>
          All cluster nodes on all sites should synchronize to an NTP server
          outside the cluster. For more information, see the
          <citetitle>&admin;</citetitle> for &sls; &productnumber;,
          available at <link xlink:href="http://www.suse.com/documentation/"/>. Refer to the chapter <citetitle>Time
            Synchronization with NTP</citetitle>.
        </para>
        <para>
          If nodes are not synchronized, log files and cluster reports are very
          hard to analyze.
        </para>
      </listitem>
      <listitem>
        <para>The cluster on each site has a meaningful name, for example:
          <literal>&cluster1;</literal> and
          <literal>&cluster2;</literal>.
        </para>
      </listitem>
    </itemizedlist>
  </sect1>
  <sect1 xml:id="sec.ha.geo.scripts">
    <title>Overview of the &geo; Bootstrap Scripts</title>
    <para>
      All commands from the <package>ha-cluster-bootstrap</package> package
      execute bootstrap scripts that require only a minimum of time and manual
      intervention.
    </para>
    <itemizedlist>
      <listitem>
        <para>
          With <command>ha-cluster-geo-init</command>, turn a cluster into the first
          site of a &geo; cluster. The script creates &booth.conf; (by taking
          some parameters like the names of the clusters, the arbitrator, and one or
          multiple tickets). It also configures the cluster resources needed for
          booth on the current cluster site.
        </para>
       <para>
        For details, see <xref linkend="sec.ha.geo.quick.ha-cluster-geo-init"/>.
       </para>
      </listitem>
      <listitem>
        <para>
          With <command>ha-cluster-geo-join</command>, add the current cluster to an
          existing &geo; cluster. The script copies the booth configuration from an
          existing cluster site and writes it to &booth.conf;. On the current
          cluster site, it configures the cluster resources needed for booth.
        </para>
       <para>
        For details, see <xref linkend="sec.ha.geo.quick.ha-cluster-geo-join"/>.
       </para>
      </listitem>
      <listitem>
        <para>
          With <command>ha-cluster-geo-init-arbitrator</command>, turn the current
         machine into an arbitrator for the &geo; cluster. The script copies the
         booth configuration from an existing cluster site and writes it to &booth.conf;.
        </para>
       <para>
        For details, see <xref linkend="sec.ha.geo.quick.ha-cluster-geo-init-arbitrator"/>.
       </para>
      </listitem>
    </itemizedlist>
    <!--taroth 2017-07-03: the following is not really true by now, the man pages
     are rather basic ATM:
     <para>Each script comes with a man page covering the range of functions, the
      script's options, and an overview of the files the script can create and modify.
    </para>-->
  </sect1>
  <sect1 xml:id="sec.ha.geo.quick.inst">
    <title>Installation as Extension</title>
    <para>
      For setting up a &geo; cluster you need the packages included in
      the following installation patterns:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          <literal>&ha;</literal>
        </para>
      </listitem>
      <listitem>
        <para>
          <literal>&geo; Clustering for &ha;</literal>
        </para>
      </listitem>
    </itemizedlist>
    <para>
      Both patterns are only available if you have registered your system at
      &scc; (or a local registration server) and have added the respective
      product channels or installation media as an extension. For information on how
      to install extensions, see the <citetitle>&sle; &productnumber;
        &deploy;</citetitle>, available at <link xlink:href="http://www.suse.com/documentation/"/>. Refer to
      chapter <citetitle>Installing Modules, Extensions, and Third Party Add-On Products</citetitle>.
      <!--taroth: need to use hard-coded link here as the target is not included in the same set-->
    </para>
    <procedure xml:id="pro.ha.geo.inst">
      <title>Installing the Packages</title>
      <step>
        <para>
          To install the packages from both patterns via command line, use
          Zypper:
        </para>
        <screen>&prompt.root;<command>zypper</command> install -t pattern ha_sles ha_geo</screen>
      </step>
      <step xml:id="step.ha.geo.inst.yast">
        <para>
          Alternatively, use &yast; for a graphical installation:
        </para>
        <substeps performance="required">
          <step>
            <para>
              Start &yast; as &rootuser; user and select <menuchoice>
                <guimenu>Software</guimenu> <guimenu>Software Management</guimenu>
              </menuchoice>.
            </para>
          </step>
          <step>
            <para>
              Click <menuchoice> <guimenu>View</guimenu>
                <guimenu>Patterns</guimenu> </menuchoice> and activate the following
              patterns:
            </para>
            <itemizedlist>
              <listitem>
                <para>
                  <literal>&ha;</literal>
                </para>
              </listitem>
              <listitem>
                <para>
                  <literal>&geo; Clustering for &ha;</literal>
                </para>
              </listitem>
            </itemizedlist>
          </step>
          <step>
            <para>
              Click <guimenu>Accept</guimenu> to start installing the packages.
            </para>
          </step>
        </substeps>
      </step>
    </procedure>
    <important>
      <title>Installing Software Packages on all Parties</title>
      <para>
        The software packages needed for &ha; and &geo; clusters are
        <emphasis>not</emphasis> automatically copied to the cluster nodes.
      </para>
      <itemizedlist>
        <listitem>
          <para>
            Install &sls; &productnumber; and the <literal>&ha;</literal>
            and <literal>&geo; Clustering for &ha;</literal> patterns on
            <emphasis>all</emphasis> machines that will be part of your &geo;
            cluster.
          </para>
        </listitem>
        <listitem>
          <para>
            Instead of manually installing the packages on all machines that
            will be part of your cluster, use &ay; to clone existing nodes.
            Find more information in the <citetitle>&haguide;</citetitle> for
            &productname; &productnumber;, available from
            <link xlink:href="http://www.suse.com/documentation/"/>. Refer to the
            chapter <citetitle>Installation the &hasi;</citetitle>, section
            <citetitle>Mass Installation and Deployment with &ay;</citetitle>.
          </para>
          <para>
           <remark>taroth 2017-06-29: @DEV/QA, is the following still true?</remark>
            However, the &geo; clustering extension must be installed
           <emphasis>manually</emphasis> on all machines
            that will be part of the &geo; cluster. &ay; support for &hageo; is
            not yet available.
          </para>
        </listitem>
      </itemizedlist>
    </important>
  </sect1>
 <sect1 xml:id="sec.ha.geo.quick.ha-cluster-geo-init">
  <title>Setting Up the First Site of a &geo; Cluster</title>
  <para>
   Use the <command>ha-cluster-geo-init</command> script to turn an existing
   cluster into the first site of a &geo; cluster.
  </para>
   <procedure xml:id="pro.ha.geo.quick.ha-cluster-geo-init">
   <title>Setting Up the First Site (<systemitem>&cluster1;</systemitem>) with
    <command>ha-cluster-geo-init</command></title>
   <step>
    <para>
     Define a virtual IP per cluster site that can be used to access the
     site. <remark>toms 2017-07-04: maybe add xref to overview/sys req where
     IPs are mentioned?</remark>
     You do not need to configure the virtual IPs as cluster resources yet.
     This will be done by the bootstrap scripts.</para>
   </step>
   <step>
    <para>
     Define the name of at least one ticket that will grant the right to run
     certain resources on a cluster site. Use a meaningful name that reflects the
     resources that will depend on the ticket. The bootstrap scripts only need the
     ticket name&mdash;you can define the remaining details (ticket dependencies
     of the resources) later on. <remark>taroth 2017-07-04: todo - add link</remark>
    </para>
   </step>
   <step>
    <para>
     Log in to a node of an existing cluster (for example, on node
     <literal>&node1;</literal> of the cluster <literal>&cluster1;</literal>).
    </para>
   </step>
   <step xml:id="step.ha-cluster-geo-init">
    <para>
     Run the <command>ha-cluster-geo-init</command>. For example, use the
     following options:
    </para>
    <screen>&prompt.root;<command>ha-cluster-geo-init</command> \
  --clusters<co xml:id="co.geo.init.clusters"/> "amsterdam=10.161.13.176 berlin=10.160.4.81" \
  --tickets<co xml:id="co.geo.init.ticket"/> ticket-nfs \
  --arbitrator<co xml:id="co.geo.init.arbitrator"/> cynthia</screen>
    <calloutlist>
     <callout arearefs="co.geo.init.clusters">
      &geo-join-clusters;
      <para>
       The names of the cluster sites (as defined in &corosync.conf;) and the virtual
       IP addresses you want to use for each cluster site. In this case, we have
       two cluster sites (<literal>&cluster1;</literal> and
       <literal>&cluster2;</literal>) with a virtual IP address each.
      </para>
     </callout>
     <callout arearefs="co.geo.init.ticket">
      <para>
       The name of one or multiple tickets. In this case, the ticket's name is
       <literal>ticket-nfs</literal>.
      </para>
     </callout>
     <callout arearefs="co.geo.init.arbitrator">
     <para>
       The host name or IP address of a machine outside of the clusters. In this
       case, the arbitrator's host name is <literal>cynthia</literal>.
       </para>
     </callout>
    </calloutlist>
   </step>
  </procedure>
  <para>The bootstrap script creates the booth configuration file and synchronizes it
   across the cluster sites. It also creates the basic cluster
   resources needed for booth (see <xref linkend="sec.ha.geo.scripts"/>).
  For example, <xref linkend="step.ha-cluster-geo-init" xrefstyle="seletc:label"/>
   of <xref linkend="pro.ha.geo.quick.ha-cluster-geo-init" xrefstyle="select:label"/>
   results in the following booth configuration and cluster resources:</para>
  <example xml:id="ex.geo.init.booth.conf">
   <title>Booth Configuration Created By <command>ha-cluster-geo-init</command></title>
   <screen># The booth configuration file is "/etc/booth/booth.conf". You need to
# prepare the same booth configuration file on each arbitrator and
# each node in the cluster sites where the booth daemon can be launched.

# "transport" means which transport layer booth daemon will use.
# Currently only "UDP" is supported.
transport="UDP"
port="9929"

arbitrator="cynthia"
site="10.161.13.176"
site="10.160.4.81"
authfile="/etc/booth/authkey"
ticket="ticket-nfs"
expire="600"</screen>
  </example>
  <example xml:id="ex.geo.init.rsc.conf">
   <title>Cluster Resources Created By <command>ha-cluster-geo-init</command></title>
   <screen>primitive<co xml:id="co.geo.quick.rsc.booth-ip"/> booth-ip IPaddr2 \
  params rule #cluster-name eq amsterdam ip=10.161.13.176\
  params rule #cluster-name eq berlin ip=10.160.4.81
primitive<co xml:id="co.geo.quick.rsc.booth-site"/> booth-site ocf:pacemaker:booth-site \
  meta resource-stickiness=INFINITY \
  params config=booth \
  op monitor interval=10s
group<co xml:id="co.geo.quick.rsc.g-booth"/> g-booth booth-ip booth-site \
meta target-role=Stopped<co xml:id="co.geo.quick.rsc.stopped"/></screen>
   <calloutlist>
    <callout arearefs="co.geo.quick.rsc.booth-ip">
     <para>A virtual IP address for each cluster site. It is required by the booth
      daemons who need a persistent IP address on each cluster site.
     </para>
    </callout>
    <callout arearefs="co.geo.quick.rsc.booth-site">
     <para>
      A primitive resource for the booth daemon. It communicates with the
      booth daemons on the other cluster sites.
     </para>
    </callout>
    <callout arearefs="co.geo.quick.rsc.g-booth">
     <para>A cluster resource group for both primitives.</para>
    </callout>
    <callout arearefs="co.geo.quick.rsc.stopped">
     <para>The cluster resource group is not started by default. After verifying
     the configuration of your cluster resources (and adding the resources you
     need to complete your setup), you need to start the resource group. See
      <xref linkend="vl.ha.geo.quick.next.req"/> for details.
     </para>
    </callout>
   </calloutlist>
  </example>
 </sect1>
 <sect1 xml:id="sec.ha.geo.quick.ha-cluster-geo-join">
  <title>Adding Another Site to a &geo; Cluster</title>
  <para>After you have initialized the first site of your &geo; cluster, add the
   second cluster with the <literal>ha-cluster-geo-join</literal> bootstrap script,
   as described in <xref linkend="pro.ha.geo.quick.ha-cluster-geo-join"
   xrefstyle="select:label"/>. The script needs SSH access to an already configured
   cluster site and will add the current cluster to the &geo; cluster.
  </para>
  <procedure xml:id="pro.ha.geo.quick.ha-cluster-geo-join">
   <title>Adding the Second Site (<literal>&cluster2;</literal>) with
    <command>ha-cluster-geo-join</command></title>
   <step>
    <para>
     Log in to a node of the cluster site you want to add (for example, on node
     <literal>&node3;</literal> of the cluster <literal>&cluster2;</literal>).
    </para>
   </step>
   <step xml:id="step.ha-cluster-geo-join">
    <para>
     Run the <command>ha-cluster-geo-init</command> command. For example:
    </para>
    <screen>&prompt.root;<command>ha-cluster-geo-init</command> \
  --cluster-node<co xml:id="co.geo.join.cluster-node"/> 10.161.13.176\
  --clusters<co xml:id="co.geo.join.clusters"/> "amsterdam=10.161.13.176 berlin=10.160.4.81" \
     </screen>
    <calloutlist>
     <callout arearefs="co.geo.join.cluster-node">
      <para>
       Specifies where to copy the booth configuration from. Use the IP address
       or host name of a node in an already configured &geo; cluster site.
       Alternatively, use the IP address or host name of an already configured
       arbitrator for your &geo; cluster, or the virtual IP address of an already
       existing cluster site.
      </para>
     </callout>
     <callout arearefs="co.geo.join.clusters">
      &geo-join-clusters;
     </callout>
    </calloutlist>
   </step>
  </procedure>
  <para>The <command>ha-cluster-geo-init</command> script copies the booth
  configuration from <xref linkend="co.geo.join.cluster-node" xrefstyle="select:label"/>, see
   <xref linkend="ex.geo.init.booth.conf" xrefstyle="select:label"/>. In addition, it creates the
   cluster resources need for booth (see <xref linkend="ex.geo.init.rsc.conf"
   xrefstyle="select:label"/>).
  </para>
 </sect1>
 <sect1 xml:id="sec.ha.geo.quick.ha-cluster-geo-init-arbitrator">
  <title>Adding the Arbitrator</title>
  <para>After you have set up all sites of your &geo; cluster with
   <command>ha-cluster-geo-init</command> and <command>ha-cluster-geo-join</command>,
   set up the arbitrator with <command>ha-cluster-geo-init-arbitrator</command>.
  </para>
  <procedure xml:id="pro.ha.geo.quick.ha-cluster-geo-init-arbitrator">
   <title>Setting Up the Arbitrator with <command>ha-cluster-geo-init-arbitrator</command></title>
  <step>
   <para>Log in to the machine you want to use as arbitrator.</para>
  </step>
  <step>
   <para>
    Run the following command with the <option>--cluster-node</option> option.
    It specifies where to copy the booth configuration from. For example:
   </para>
   <screen>&prompt.root;<command>ha-cluster-geo-init-arbitrator</command> --cluster-node<co
   xml:id="co.geo.init.arbitrator.cluster-node"/> 10.161.13.176</screen>
   <calloutlist>
    <callout arearefs="co.geo.init.arbitrator.cluster-node">
     <para>
      The IP address or host name of a node in an already configured &geo;
      cluster site. Alternatively, use the virtual IP address of an already
      existing cluster site.
     </para>
    </callout>
   </calloutlist>
  </step>
  </procedure>
  <para>The <command>ha-cluster-geo-init-arbitrator</command> script copies the booth
   configuration from <xref linkend="co.geo.init.arbitrator.cluster-node"/>, see
   <xref linkend="ex.geo.init.booth.conf" xrefstyle="select:label"/>. It also
   enables and starts the booth service on the arbitrator. Thus, the arbitrator
   is ready to communicate with the booth instances on the cluster sites as soon
   as the booth services are running there, too.</para>
 </sect1>
 <sect1 xml:id="sec.ha.geo.quick.trouble">
  <title>Testing the Setup and Troubleshooting</title>
  <para>
   All bootstrap scripts log to <filename>/var/log/ha-cluster-bootstrap.log</filename>.
   If you do not see any error messages from the &geo; clustering bootstrap scripts,
   your initial setup should be correct. If not, check the log file for any details
   of the bootstrap process. Any options set during the bootstrap process can be
   modified later.
  </para>
  <para>To check the basic setup, use &hawk;.<remark>taroth 2017-07-03: todo -
  if there is enough time, explain how to check with hawk cluster dashboard view</remark>
   <remark>toms 2017-07-04: maybe also mention cluster health check for individual
    cluster sites?</remark>
  </para>
 </sect1>
 <sect1 xml:id="se.ha.geo.quick.next">
  <title>Restrictions and Next Steps</title>
  <para>
   The &geo; clustering bootstrap scripts provide a quick way to set up a basic
   &geo; cluster that can be used for testing purposes. However, to move the
   resulting &geo; cluster into a functioning &geo; cluster that can be used in
   production environments, more steps are required (see <xref
    linkend="vl.ha.geo.quick.next.req"/>).
  </para>

  <variablelist xml:id="vl.ha.geo.quick.next.req">
   <title>Required Steps to Complete the &geo; Cluster Setup</title>
   <varlistentry xml:id="vle.ha.geo.quick.booth.service.sites">
    <term>Starting the Booth Services on Cluster Sites</term>
    <listitem>
     <para>
      While the &geo; clustering bootstrap scripts enable and start the booth services
      on the arbitrator with <command>systemctl</command>, the arbitrator
      booth service cannot communicate with the booth services on the cluster
      sites yet, because they are not started by default.
     </para>
     <para>
      The booth service for each cluster site is managed by the booth
      resource group <literal>g-booth</literal> (see
      <xref linkend="ex.geo.init.rsc.conf"/>).
      To start one instance of the booth service per site, start the
      respective booth resource group on each cluster site. This enables all
      booth instances to communicate with each other.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Configuring Ticket Dependencies and Ordering Constraints</term>
    <listitem>
     <para>
      <remark>taroth 2017-07-04: FIXME - add some content from Procedure 6:
      Configuring Ticket Dependencies of Resources
      (https://www.suse.com/documentation/sle-ha-geo-12/singlehtml/art_ha_geo_quick/art_ha_geo_quick.html#pro.ha.geo.setup.rsc.constraints)
      and from Procedure 8: Adding an Ordering Constraint
      (https://www.suse.com/documentation/sle-ha-geo-12/singlehtml/art_ha_geo_quick/art_ha_geo_quick.html#pro.ha.geo.setup.rsc.order)
     </remark>
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Initially Granting a Ticket to a Site</term>
    <listitem>
     <para>
      <remark>taroth 2017-07-04: FIXME - either add some content from 11.1 From Command Line
       (https://www.suse.com/documentation/sle-ha-geo-12/singlehtml/art_ha_geo_quick/art_ha_geo_quick.html#sec.ha.geo.manage.cli)
       or explain how to grant a ticket with Hawk
      </remark>
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
  <para>
   <remark>taroth 2017-07-04: todo - add (list) of optional steps like the following...</remark>
   The bootstrap scripts create the same booth resources on both cluster sites,
   and the same booth configuration files on all sites, including the arbitrator.
   However, if you change the booth configuration or the configuration of the
   booth-related cluster resources on one site, you need to synchronize the changes
   to the other sites <remark>taroth 2017-07-03: todo - add pointers to Geo Guide</remark>.
  </para>
 </sect1>
<xi:include href="common_legal.xml"/>
</article>
